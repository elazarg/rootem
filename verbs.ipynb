{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import verbs\n",
    "import neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerbDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_filename, batch_size=128, validation_size=10000):\n",
    "        super().__init__()\n",
    "        WORD_MAXLEN = 11\n",
    "        self.validation_size = validation_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "\n",
    "        train_data_x, train_data_y = verbs.load_dataset(train_filename, word_maxlen=WORD_MAXLEN)\n",
    "\n",
    "        self.data_train_full = torch.utils.data.TensorDataset(torch.tensor(train_data_x, dtype=torch.int64),\n",
    "                                                              *[torch.tensor(y, dtype=torch.int64) for y in train_data_y])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # No state assignment here\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.data_train, self.data_val = torch.utils.data.random_split(self.data_train_full, [self.validation_size, len(self.data_train_full) - self.validation_size])\n",
    "            self.dims = tuple(self.data_train[0][0].shape)\n",
    "\n",
    "        if stage == 'test':\n",
    "            #or stage is None:\n",
    "            assert False  # self.dims = tuple(self.data_test[0][0].shape)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EMBEDDING = 2000\n",
    "\n",
    "class IndependentModel(neural.UdModel):\n",
    "\n",
    "    def __init__(self, label_map, units=400, learning_rate=1e-3, weight_decay=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.units = units\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=units)\n",
    "        \n",
    "        self.lstm = neural.SumBiLSTM(units)\n",
    "        \n",
    "        self.tasks = nn.ModuleDict([(label_name, nn.Linear(in_features=units, out_features=class_size))\n",
    "                                     for label_name, class_size in label_map.items()])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (BATCH_SIZE, WORD_MAXLEN)\n",
    "\n",
    "        x = x.permute([1, 0])\n",
    "        # x: (WORD_MAXLEN, BATCH_SIZE)\n",
    "        \n",
    "        embeds = self.embed(x)\n",
    "        # embeds: (WORD_MAXLEN, BATCH_SIZE, UNITS)\n",
    "        \n",
    "        _, char_hidden = self.lstm(embeds)\n",
    "        # char_hidden: (BATCH_SIZE, UNITS)\n",
    "        \n",
    "        return {name: linear(char_hidden)\n",
    "                for name, linear in self.tasks.items()}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "        return optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {name: verbs.Verb.class_size(name) for name in [\n",
    "    'Binyan',\n",
    "    'Tense',\n",
    "    'Voice',\n",
    "    'Gender',\n",
    "    'Plural',\n",
    "    'R1',\n",
    "    'R2',\n",
    "    'R3',\n",
    "    'R4',\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VerbDataModule(\n",
    "    f'synthetic/all_pref_combined_shufroot.tsv',\n",
    "    batch_size=32\n",
    ")\n",
    "dataset.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/1lspjsl5\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/1lspjsl5</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | embed | Embedding       | 800 K \n",
      "1 | lstm  | SumSharedBiLSTM | 2 M   \n",
      "2 | tasks | ModuleDict      | 54 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3d155741514b2bbba4c7ac3a292798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = IndependentModel(label_map, units=400, learning_rate=1e-3, weight_decay=7e-4)\n",
    "wandb_logger = pl.loggers.WandbLogger(project='rootem', group='verbs-lightning', name=f'shared_32')\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=5, logger=wandb_logger)\n",
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, *verbs):\n",
    "    model.eval()\n",
    "    verbs = encoding.wordlist2numpy(verbs * 128)\n",
    "    verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "    outputs = {k: v[0] for k, v in model(verbs).items()}\n",
    "    res = {}\n",
    "    # FIX: assumes no overlaps\n",
    "    for combination, v in outputs.items():\n",
    "        if isinstance(combination, str):\n",
    "            combination = tuple([combination])\n",
    "        shape = encoding.combined_shape(combination)\n",
    "        combined_index = v.argmax().cpu().data.numpy()\n",
    "        indices = np.unravel_index(combined_index, shape)\n",
    "        for k, i in zip(combination, indices):\n",
    "            # assert k not in res, \"Overlapping classes are not handled\"\n",
    "            s = k\n",
    "            if k in res:\n",
    "                s += \"'\"\n",
    "            res[s] = encoding.from_category(k, i)\n",
    "    if all(r in res for r in ['R1', 'R2', 'R3', 'R4']):\n",
    "        res['R'] = ''.join(res[k] for k in ['R1', 'R2', 'R3', 'R4']).replace('.', '')\n",
    "    return '\\t'.join(f'{v:>6}' for k, v in res.items() if k not in ['R1', 'R2', 'R3', 'R4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s = 'השתזף שמרתי ירעדו נאכל הרבינו כשהתעצבנתם השגנו תרגלתי עופו פיהקתם צפינו הצפינו שרנו להתווכח תוכיחי קומו'\n",
    "\n",
    "model = torch.load(f\"models/pretrain.pt\")\n",
    "for k in s.split():\n",
    "    print(k, predict(model, k))\n",
    "print(\"חבל\", predict(model, \"חבל\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
