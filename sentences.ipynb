{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import utils\n",
    "import encoding\n",
    "import ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConlluDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_filename, test_filename, features, batch_size=64, validation_size=300):\n",
    "        # TODO: use dev set instead of splitting validation\n",
    "        super().__init__()\n",
    "        SENTENCE_MAXLEN = 30\n",
    "        WORD_MAXLEN = 11\n",
    "        self.validation_size = validation_size\n",
    "        self.batch_size = batch_size\n",
    "        self.features = features\n",
    "        \n",
    "        train_data_x, train_data_y = encoding.load_sentences(train_filename, features, SENTENCE_MAXLEN, WORD_MAXLEN)\n",
    "        self.data_train_full = torch.utils.data.TensorDataset(torch.Tensor(train_data_x), *[torch.Tensor(y).to(torch.int64) for y in train_data_y])\n",
    "        \n",
    "        test_data_x, test_data_y = encoding.load_sentences(test_filename, features, SENTENCE_MAXLEN, WORD_MAXLEN)\n",
    "        self.data_test = torch.utils.data.TensorDataset(torch.Tensor(test_data_x), *[torch.Tensor(y).to(torch.int64) for y in test_data_y])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # No state assignment here\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.data_train, self.data_val = torch.utils.data.random_split(self.data_train_full, [self.validation_size, len(self.data_train_full) - self.validation_size])\n",
    "            self.dims = tuple(self.data_train[0][0].shape)\n",
    "\n",
    "        if stage == 'test' or stage is None:\n",
    "            self.dims = tuple(self.data_test[0][0].shape)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.data_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EMBEDDING = 2000\n",
    "\n",
    "def masked_equals(y_hat, target):\n",
    "    pred = y_hat.argmax(1)\n",
    "    nonzeros = (target != 0)\n",
    "    return (pred[nonzeros] == target[nonzeros])\n",
    "\n",
    "\n",
    "class SumBiLSTM(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.lstm = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=False, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (..., UNITS)\n",
    "        \n",
    "        lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        # lstm_out: (..., UNITS * 2)\n",
    "        # hidden: (2, ..., UNITS)\n",
    "        # cell: (2, ..., UNITS)\n",
    "        \n",
    "        hidden = hidden[0] + hidden[1]\n",
    "        # hidden: (..., UNITS)\n",
    "        \n",
    "        left, right = torch.chunk(lstm_out, 2, dim=-1)\n",
    "        # left: (..., UNITS)\n",
    "        # right: (..., UNITS)\n",
    "        \n",
    "        lstm_out = torch.squeeze(left + right)\n",
    "        # lstm_out: (..., UNITS)\n",
    "        \n",
    "        return lstm_out, hidden\n",
    "\n",
    "\n",
    "class SumSharedBiLSTM(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.lstm = SumBiLSTM(units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        lstm_out1, hidden1 = self.lstm(x)\n",
    "        return lstm_out + lstm_out1, hidden + hidden1\n",
    "\n",
    "\n",
    "class IndependentModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, features, units=400, learning_rate=2e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.units = units\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=units)\n",
    "        \n",
    "        self.char_lstm = SumSharedBiLSTM(units)\n",
    "        \n",
    "        self.word_lstm = SumBiLSTM(units)\n",
    "        \n",
    "        self.tasks = nn.ModuleDict({class_name: nn.Linear(in_features=units, out_features=class_size)\n",
    "                                    for class_name, class_size in features.items()})\n",
    "\n",
    "    def forward(self, x):\n",
    "        BATCH_SIZE, SENT_MAXLEN, WORD_MAXLEN = x.shape\n",
    "        \n",
    "        x = x.to(torch.int64)\n",
    "        # x: (BATCH_SIZE, SENT_MAXLEN, WORD_MAXLEN)\n",
    "        \n",
    "        # Step 0: character embedding \n",
    "        \n",
    "        x = x.reshape(BATCH_SIZE * SENT_MAXLEN, WORD_MAXLEN)\n",
    "        # x: (BATCH_SIZE * SENT_MAXLEN, WORD_MAXLEN)\n",
    "\n",
    "        embeds = self.embed(x)\n",
    "        # embeds: (BATCH_SIZE * SENT_MAXLEN, WORD_MAXLEN, UNITS)\n",
    "        \n",
    "        embeds = embeds.permute([1, 0, 2])\n",
    "        # x: (WORD_MAXLEN, BATCH_SIZE * SENT_MAXLEN, UNITS)\n",
    "\n",
    "        \n",
    "        # STEP 1: character-level lstm -> word embedding\n",
    "        \n",
    "        _, char_hidden = self.char_lstm(embeds)\n",
    "        # char_hidden: (BATCH_SIZE * SENT_MAXLEN, UNITS)\n",
    "        \n",
    "        char_hidden = char_hidden.reshape(BATCH_SIZE, SENT_MAXLEN, -1)\n",
    "        # char_hidden: (BATCH_SIZE, SENT_MAXLEN, UNITS)\n",
    "        \n",
    "        char_hidden = char_hidden.permute([1, 0, 2])\n",
    "        # char_hidden: (SENT_MAXLEN, BATCH_SIZE, UNITS)\n",
    " \n",
    "\n",
    "        # STEP 2: sequence tagging using word-level lstm\n",
    "    \n",
    "        word_lstm_out, _ = self.word_lstm(char_hidden)\n",
    "        # word_lstm_out: (SENT_MAXLEN, BATCH_SIZE, UNITS)\n",
    "        \n",
    "        word_lstm_out = word_lstm_out.permute([1, 0, 2])\n",
    "        # word_lstm_out: (BATCH_SIZE, SENT_MAXLEN, UNITS)\n",
    "        \n",
    "        char_hidden = char_hidden.permute([1, 0, 2])\n",
    "        # char_hidden: (BATCH_SIZE, SENT_MAXLEN, UNITS)\n",
    "        \n",
    "        summed = word_lstm_out + char_hidden\n",
    "        # summed: (BATCH_SIZE, SENT_MAXLEN, UNITS)\n",
    "        \n",
    "        return {name: linear(summed).permute([0, 2, 1])\n",
    "                for name, linear in self.tasks.items()}\n",
    "\n",
    "    def compute_metrics(self, batch):\n",
    "        x, *ys = batch\n",
    "        ys_hat = self(x)\n",
    "        \n",
    "        m = {name: (y_hat, y) for (name, y_hat), y in zip(ys_hat.items(), ys)}\n",
    "        \n",
    "        loss = sum(F.cross_entropy(y_hat, y, ignore_index=0)\n",
    "                   for y_hat, y in m.values())\n",
    "        \n",
    "        accuracy = {name: masked_equals(y_hat, y).float().mean()    \n",
    "                    for name, (y_hat, y) in m.items()}\n",
    "        \n",
    "        accuracy['Root'] = ( masked_equals(*m['R1'])\n",
    "                           & masked_equals(*m['R2'])\n",
    "                           & masked_equals(*m['R3'])\n",
    "                           & masked_equals(*m['R4'])).float().mean() \n",
    "        \n",
    "        return loss, accuracy\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        loss, accuracy = self.compute_metrics(batch)\n",
    "        result = pl.TrainResult(minimize=loss)\n",
    "        result.log('train/loss', loss, prog_bar=True)\n",
    "        for k, v in accuracy.items():\n",
    "            result.log(f'train/{k}', v, prog_bar=True)\n",
    "        return result\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, accuracy = self.compute_metrics(batch)\n",
    "        result = pl.EvalResult()\n",
    "        result.log('val/loss', loss, prog_bar=True)\n",
    "        for k, v in accuracy.items():\n",
    "            result.log(f'val/{k}', v, prog_bar=True)\n",
    "        return result\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        return self(sentence).argmax(1)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, accuracy = self.compute_metrics(batch)\n",
    "        return {'test/loss': loss}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test/loss'] for x in outputs]).mean()\n",
    "        return {'avg_test_loss': avg_loss }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {name: ud.Token.class_size(name) for name in [\n",
    "#     'Abbr',\n",
    "    'Case',\n",
    "    'Cconj',\n",
    "    'Det',\n",
    "#     'Definite',\n",
    "    'Gender',\n",
    "#     'HebExistential',\n",
    "#     'HebSource',\n",
    "    'HebBinyan',\n",
    "#     'Mood',\n",
    "    'Number',\n",
    "    'Person',\n",
    "#     'Polarity',\n",
    "    'Pos',\n",
    "#     'Prefix',\n",
    "    'PronGender',\n",
    "    'PronNumber',\n",
    "    'PronPerson',\n",
    "    'PronType',\n",
    "#     'Reflex',\n",
    "    'R1',\n",
    "    'R2',\n",
    "    'R3',\n",
    "    'R4',\n",
    "    'Tense',\n",
    "#     'VerbForm',\n",
    "    'VerbType',\n",
    "    'Voice',\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConlluDataModule(\n",
    "    f'../Hebrew_UD/he_htb-ud-train.conllu',\n",
    "    f'../Hebrew_UD/he_htb-ud-dev.conllu',\n",
    "    batch_size=32,\n",
    "    features=features)\n",
    "dataset.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/3jf4l0qo\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/3jf4l0qo</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type            | Params\n",
      "----------------------------------------------\n",
      "0 | embed     | Embedding       | 800 K \n",
      "1 | char_lstm | SumSharedBiLSTM | 2 M   \n",
      "2 | word_lstm | SumBiLSTM       | 2 M   \n",
      "3 | tasks     | ModuleDict      | 76 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fc012c8ac4409ebc26e5b2d774755a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = IndependentModel(dataset.features, units=400, learning_rate=2e-3)\n",
    "wandb_logger = pl.loggers.WandbLogger(project='rootem', group='ud-fix1', name=f'module_dict')\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=20, logger=wandb_logger)\n",
    "trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'מילים כדורבנות התואמות בדיוק נמרץ את מה שהחתום מטה טען במשך שנים רבות'.split()\n",
    "text = torch.Tensor([encoding.wordlist2numpy(sent, word_maxlen=11)] * 2)  # .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [[ud.Token.decode_label(label, idx) for idx in value.argmax(1)[0]]\n",
    "        for label, value in model(text).items()]\n",
    "print('Token', *[f[:7] for f in features], sep='\\t')\n",
    "for item in zip(sent, *res):\n",
    "    print(*item, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, p, b, *rs in zip(sent, pos, binyan, r1, r2, r4):\n",
    "    print(s, p, b, ''.join(rs), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IndependentModel(300)\n",
    "trainer = pl.Trainer(gpus=1, auto_lr_find=True, max_epochs=10)\n",
    "lr_finder = trainer.lr_find(model, train_dataloader=dataset, min_lr=1e-5, early_stop_threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = lr_finder.plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_dataloaders=dataset.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trainer.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
