{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "from naive_model import NaiveModel\n",
    "import encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EMBEDDING = 2000\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "def to_device(d):\n",
    "    if hasattr(d, 'cuda'):\n",
    "        return d.cuda()\n",
    "    return {k: v.cuda() for k, v in d.items()}\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, units, combinations=encoding.NAMES):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=units)\n",
    "        \n",
    "        self.lstm_root = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.lstm_nonroot = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.tasks = {}\n",
    "        for combination in combinations:\n",
    "            out = nn.Linear(in_features=units, out_features=encoding.class_size(combination))\n",
    "            self.tasks[combination] = out\n",
    "            setattr(self, encoding.class_name(combination), out)\n",
    "\n",
    "    def combine(self, lstm_out):\n",
    "        lstm_out, (h_n, c_n) = lstm_out\n",
    "        left, right = torch.chunk(h_n, 2, dim=0)\n",
    "        return torch.squeeze(left + right)\n",
    "            \n",
    "    def isroot(self, combination):\n",
    "        return any(r in combination for r in ['R1', 'R2', 'R3', 'R4'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeds = self.embed(x)\n",
    "\n",
    "        root_merge = self.combine(self.lstm_root(embeds))\n",
    "        noroot_merge = self.combine(self.lstm_nonroot(embeds))\n",
    "\n",
    "        return {combination: f((root_merge - noroot_merge) if self.isroot(combination)\n",
    "                          else (root_merge + noroot_merge))\n",
    "                for combination, f in self.tasks.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sanity():\n",
    "    model = to_device(Model(100, combinations=[('B', 'T')]))\n",
    "    print(model)\n",
    "    with torch.no_grad():\n",
    "        verbs = encoding.wordlist2numpy([\"אתאקלם\", \"יכפיל\"])\n",
    "        labels = {'B': torch.Tensor([3, 5]), 'T': torch.Tensor([2, 4])}\n",
    "        verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "        tag_scores = model(verbs)\n",
    "        for combination in tag_scores:\n",
    "            print(combination)\n",
    "            v = tag_scores[combination]\n",
    "            print(f'{v=}')\n",
    "            print(f'{labels=}')\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# TEMP_PATH = 'model.pt'\n",
    "\n",
    "#                 best_lr = 8e-4\n",
    "#                 best_loss = 10\n",
    "                \n",
    "#                 torch.save({\n",
    "#                     'state_dict': model.state_dict(),\n",
    "#                     'optimizer': optimizer.state_dict(),\n",
    "#                 }, TEMP_PATH)\n",
    "                \n",
    "#                 for i in range(1):\n",
    "#                     checkpoint = torch.load(TEMP_PATH)\n",
    "#                     model.load_state_dict(checkpoint['state_dict'])\n",
    "#                     optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "def fit(model, train, test, *, epochs,  runsize, criterion, optimizer, phases, teacher, batch_size):\n",
    "    x_train, y_train = utils.batch_xy(train, batch_size)\n",
    "    x_test, y_test = utils.batch_xy(test, batch_size)\n",
    "    x = {'train': x_train, 'test': x_test}\n",
    "    y = {'train': y_train, 'test': y_test}\n",
    "\n",
    "    stats = utils.Stats(model.tasks.keys(), runsize)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        stats.epoch_start()\n",
    "        \n",
    "        for phase in phases:\n",
    "            model.train(mode=phase == 'train')\n",
    "\n",
    "            stats.phase_start(phase, batches_in_phase=len(x[phase]))\n",
    "\n",
    "            for inputs, labels in zip(x[phase], y[phase]):\n",
    "                stats.batch_start()\n",
    "\n",
    "                inputs = to_device(inputs)\n",
    "                labels = to_device(labels)\n",
    "\n",
    "                with utils.conditional_grad(phase=='train'):\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                if teacher is not None:\n",
    "                    pseudo_labels = teacher(inputs)\n",
    "                    losses = {k: criterion(outputs[k].double(), pseudo_labels[k]) for k in outputs}\n",
    "                else:\n",
    "                    losses = {combination: criterion(output.double(), labels[combination])\n",
    "                              for combination, output in outputs.items()}\n",
    "\n",
    "                if phase == 'train':\n",
    "                    stats.assert_reasonable_initial(losses, nn.CrossEntropyLoss)\n",
    "\n",
    "                loss = sum(losses.values())\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                stats.update(loss=loss.item(),\n",
    "                             batch_size=inputs.size(0),\n",
    "                             d={k: (outputs[k], labels[k]) for k in outputs})\n",
    "                \n",
    "                stats.batch_end()\n",
    "            stats.phase_end()\n",
    "        stats.epoch_end()\n",
    "    return stats\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, *verbs):\n",
    "    model.eval()\n",
    "    verbs = encoding.wordlist2numpy(verbs)\n",
    "    verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "    outputs = model(verbs)\n",
    "    res = {}\n",
    "    # FIX: assumes no overlaps\n",
    "    for combination, v in outputs.items():\n",
    "        combined_index = torch.argmax(v).cpu().data.numpy()\n",
    "        indices = np.unravel_index(combined_index, encoding.combined_shape(combination))\n",
    "        if isinstance(combination, str):\n",
    "            combination = tuple([combination])\n",
    "        for k, i in zip(combination, indices):\n",
    "            # assert k not in res, \"Overlapping classes are not handled\"\n",
    "            s = k\n",
    "            if k in res:\n",
    "                s += \"'\"\n",
    "            res[s] = encoding.from_category(k, i)\n",
    "    if all(r in res for r in ['R1', 'R2', 'R3', 'R4']):\n",
    "        res['R'] = ''.join(res[k] for k in ['R1', 'R2', 'R3', 'R4']).replace('.', '')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "arity = '3'\n",
    "gen = 'all'\n",
    "artifact_name = f'{gen}_{arity}_shufroot'\n",
    "filename = f'synthetic/{artifact_name}.tsv'  # all_verbs_shuffled\n",
    "test_size = 20000\n",
    "\n",
    "artifact = wandb.Artifact(artifact_name, type='dataset')\n",
    "artifact.add_file(filename)\n",
    "\n",
    "(train_x, pre_train_y), (test_x, pre_test_y) = encoding.load_dataset_split(filename, split=test_size)\n",
    "\n",
    "utils.shuffle_in_unison([train_x, *pre_train_y.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_config(filename):\n",
    "    return {\n",
    "        'model': NaiveModel.learn_from_file(filename),\n",
    "        'phases': ['test'],\n",
    "        'criterion': nn.CrossEntropyLoss(),\n",
    "        'optimizer': None\n",
    "    }\n",
    "\n",
    "def standard_config(model, lr):\n",
    "    return {\n",
    "        'model': model,\n",
    "        'criterion': nn.CrossEntropyLoss(),\n",
    "        'phases': ['train', 'test'],\n",
    "        'teacher': None\n",
    "    }\n",
    "\n",
    "def teacher_config(train, model, lr):\n",
    "    res = standard_config(model, lr)\n",
    "    res['teacher'] = NaiveModel.learn_from_data(train)\n",
    "    res['criterion'] = nn.BCEWithLogitsLoss()  # BCELoss: works, but total loss is nan\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_SILENT=true\n",
      "env: WANDB_MODE=run\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/3kmwfk3i\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/3kmwfk3i</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 512, 'batch_size': 32, 'units': 150, 'lr': 0.0003, 'optimizer': 'adam'}\n",
      " 1 20992/21412 B_acc: 0.822 T_acc: 0.928 V_acc: 0.693 G_acc: 0.794 P_acc: 0.980 R1_acc: 0.968 R2_acc: 0.821 R3_acc: 1.000 R4_acc: 0.981 Loss: 1.9948\n",
      " 1   625/  625 B_acc: 0.810 T_acc: 0.922 V_acc: 0.697 G_acc: 0.796 P_acc: 0.978 R1_acc: 0.942 R2_acc: 0.798 R3_acc: 1.000 R4_acc: 0.946 Loss: 2.3877\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/48mhpvmb\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/48mhpvmb</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 512, 'batch_size': 32, 'units': 150, 'lr': 0.001, 'optimizer': 'adam'}\n",
      " 1 20992/21412 B_acc: 0.821 T_acc: 0.929 V_acc: 0.694 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.970 R2_acc: 0.817 R3_acc: 1.000 R4_acc: 0.982 Loss: 1.9607\n",
      " 1   625/  625 B_acc: 0.813 T_acc: 0.919 V_acc: 0.698 G_acc: 0.794 P_acc: 0.978 R1_acc: 0.934 R2_acc: 0.774 R3_acc: 1.000 R4_acc: 0.944 Loss: 2.5145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/3cwrpz08\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/3cwrpz08</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 512, 'batch_size': 32, 'units': 150, 'lr': 0.003, 'optimizer': 'adam'}\n",
      " 1 20992/21412 B_acc: 0.821 T_acc: 0.926 V_acc: 0.691 G_acc: 0.789 P_acc: 0.979 R1_acc: 0.964 R2_acc: 0.812 R3_acc: 1.000 R4_acc: 0.977 Loss: 2.1055\n",
      " 1   625/  625 B_acc: 0.816 T_acc: 0.920 V_acc: 0.699 G_acc: 0.794 P_acc: 0.977 R1_acc: 0.929 R2_acc: 0.770 R3_acc: 1.000 R4_acc: 0.948 Loss: 2.6879\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/2jraaj1r\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/2jraaj1r</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 512, 'batch_size': 32, 'units': 150, 'lr': 0.005, 'optimizer': 'adam'}\n",
      " 1 20992/21412 B_acc: 0.812 T_acc: 0.923 V_acc: 0.690 G_acc: 0.788 P_acc: 0.977 R1_acc: 0.959 R2_acc: 0.799 R3_acc: 1.000 R4_acc: 0.974 Loss: 2.2782\n",
      " 1   625/  625 B_acc: 0.808 T_acc: 0.915 V_acc: 0.689 G_acc: 0.788 P_acc: 0.977 R1_acc: 0.938 R2_acc: 0.796 R3_acc: 1.000 R4_acc: 0.946 Loss: 2.6837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/xumvkzt4\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/xumvkzt4</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 256, 'batch_size': 64, 'units': 150, 'lr': 0.0003, 'optimizer': 'adam'}\n",
      " 1 10496/10706 B_acc: 0.817 T_acc: 0.926 V_acc: 0.694 G_acc: 0.794 P_acc: 0.978 R1_acc: 0.965 R2_acc: 0.814 R3_acc: 1.000 R4_acc: 0.979 Loss: 2.05961\n",
      " 1   312/  312 B_acc: 0.807 T_acc: 0.922 V_acc: 0.697 G_acc: 0.796 P_acc: 0.977 R1_acc: 0.948 R2_acc: 0.790 R3_acc: 1.000 R4_acc: 0.955 Loss: 2.3764\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/rtpi6j30\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/rtpi6j30</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 256, 'batch_size': 64, 'units': 150, 'lr': 0.001, 'optimizer': 'adam'}\n",
      " 1 10496/10706 B_acc: 0.822 T_acc: 0.928 V_acc: 0.694 G_acc: 0.794 P_acc: 0.979 R1_acc: 0.970 R2_acc: 0.820 R3_acc: 1.000 R4_acc: 0.983 Loss: 1.9604\n",
      " 1   312/  312 B_acc: 0.815 T_acc: 0.924 V_acc: 0.699 G_acc: 0.796 P_acc: 0.978 R1_acc: 0.942 R2_acc: 0.794 R3_acc: 1.000 R4_acc: 0.952 Loss: 2.4073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/2bbj63zd\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/2bbj63zd</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 256, 'batch_size': 64, 'units': 150, 'lr': 0.003, 'optimizer': 'adam'}\n",
      " 1 10496/10706 B_acc: 0.822 T_acc: 0.923 V_acc: 0.696 G_acc: 0.795 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.813 R3_acc: 1.000 R4_acc: 0.981 Loss: 2.0496\n",
      " 1   312/  312 B_acc: 0.810 T_acc: 0.921 V_acc: 0.699 G_acc: 0.795 P_acc: 0.978 R1_acc: 0.937 R2_acc: 0.788 R3_acc: 1.000 R4_acc: 0.944 Loss: 2.5773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/4749u32c\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/4749u32c</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 256, 'batch_size': 64, 'units': 150, 'lr': 0.005, 'optimizer': 'adam'}\n",
      " 1 10496/10706 B_acc: 0.817 T_acc: 0.922 V_acc: 0.691 G_acc: 0.791 P_acc: 0.976 R1_acc: 0.963 R2_acc: 0.806 R3_acc: 1.000 R4_acc: 0.974 Loss: 2.1819\n",
      " 1   312/  312 B_acc: 0.806 T_acc: 0.919 V_acc: 0.697 G_acc: 0.791 P_acc: 0.977 R1_acc: 0.936 R2_acc: 0.793 R3_acc: 1.000 R4_acc: 0.934 Loss: 2.6740\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/2pbt1mpv\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/2pbt1mpv</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 128, 'batch_size': 128, 'units': 150, 'lr': 0.0003, 'optimizer': 'adam'}\n",
      " 1  5248/ 5353 B_acc: 0.812 T_acc: 0.924 V_acc: 0.693 G_acc: 0.794 P_acc: 0.978 R1_acc: 0.961 R2_acc: 0.806 R3_acc: 1.000 R4_acc: 0.975 Loss: 2.15666\n",
      " 1   156/  156 B_acc: 0.803 T_acc: 0.918 V_acc: 0.697 G_acc: 0.792 P_acc: 0.975 R1_acc: 0.949 R2_acc: 0.775 R3_acc: 1.000 R4_acc: 0.953 Loss: 2.4489\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/1qp02cav\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/1qp02cav</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 128, 'batch_size': 128, 'units': 150, 'lr': 0.001, 'optimizer': 'adam'}\n",
      " 1  5248/ 5353 B_acc: 0.820 T_acc: 0.925 V_acc: 0.697 G_acc: 0.795 P_acc: 0.980 R1_acc: 0.969 R2_acc: 0.817 R3_acc: 1.000 R4_acc: 0.982 Loss: 1.9765\n",
      " 1   156/  156 B_acc: 0.808 T_acc: 0.922 V_acc: 0.699 G_acc: 0.798 P_acc: 0.975 R1_acc: 0.945 R2_acc: 0.782 R3_acc: 1.000 R4_acc: 0.957 Loss: 2.3830\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/1sevr7cb\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/1sevr7cb</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 128, 'batch_size': 128, 'units': 150, 'lr': 0.003, 'optimizer': 'adam'}\n",
      " 1  5248/ 5353 B_acc: 0.825 T_acc: 0.927 V_acc: 0.693 G_acc: 0.794 P_acc: 0.979 R1_acc: 0.968 R2_acc: 0.814 R3_acc: 1.000 R4_acc: 0.980 Loss: 2.0143\n",
      " 1   156/  156 B_acc: 0.811 T_acc: 0.923 V_acc: 0.699 G_acc: 0.794 P_acc: 0.979 R1_acc: 0.945 R2_acc: 0.774 R3_acc: 1.000 R4_acc: 0.946 Loss: 2.5422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/km9scucr\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/km9scucr</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 128, 'batch_size': 128, 'units': 150, 'lr': 0.005, 'optimizer': 'adam'}\n",
      " 1  5248/ 5353 B_acc: 0.821 T_acc: 0.925 V_acc: 0.692 G_acc: 0.794 P_acc: 0.979 R1_acc: 0.966 R2_acc: 0.810 R3_acc: 1.000 R4_acc: 0.978 Loss: 2.0900\n",
      " 1   156/  156 B_acc: 0.808 T_acc: 0.921 V_acc: 0.697 G_acc: 0.793 P_acc: 0.976 R1_acc: 0.948 R2_acc: 0.790 R3_acc: 1.000 R4_acc: 0.949 Loss: 2.5587\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/e3qq0v7e\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/e3qq0v7e</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 64, 'batch_size': 256, 'units': 150, 'lr': 0.0003, 'optimizer': 'adam'}\n",
      " 1  2624/ 2676 B_acc: 0.811 T_acc: 0.922 V_acc: 0.692 G_acc: 0.793 P_acc: 0.976 R1_acc: 0.954 R2_acc: 0.797 R3_acc: 1.000 R4_acc: 0.973 Loss: 2.32630\n",
      " 1    78/   78 B_acc: 0.793 T_acc: 0.917 V_acc: 0.695 G_acc: 0.792 P_acc: 0.976 R1_acc: 0.941 R2_acc: 0.782 R3_acc: 1.000 R4_acc: 0.954 Loss: 2.5738\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/1khvfjyw\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/1khvfjyw</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 64, 'batch_size': 256, 'units': 150, 'lr': 0.001, 'optimizer': 'adam'}\n",
      " 1  2624/ 2676 B_acc: 0.819 T_acc: 0.925 V_acc: 0.695 G_acc: 0.794 P_acc: 0.980 R1_acc: 0.967 R2_acc: 0.813 R3_acc: 1.000 R4_acc: 0.979 Loss: 2.03110\n",
      " 1    78/   78 B_acc: 0.811 T_acc: 0.922 V_acc: 0.698 G_acc: 0.796 P_acc: 0.975 R1_acc: 0.945 R2_acc: 0.795 R3_acc: 1.000 R4_acc: 0.960 Loss: 2.3441\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/1t23bvmp\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/1t23bvmp</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 64, 'batch_size': 256, 'units': 150, 'lr': 0.003, 'optimizer': 'adam'}\n",
      " 1  2624/ 2676 B_acc: 0.820 T_acc: 0.926 V_acc: 0.695 G_acc: 0.793 P_acc: 0.979 R1_acc: 0.968 R2_acc: 0.814 R3_acc: 1.000 R4_acc: 0.980 Loss: 2.0058\n",
      " 1    78/   78 B_acc: 0.812 T_acc: 0.918 V_acc: 0.696 G_acc: 0.794 P_acc: 0.977 R1_acc: 0.935 R2_acc: 0.772 R3_acc: 1.000 R4_acc: 0.953 Loss: 2.5196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/5cv8hevs\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/5cv8hevs</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 64, 'batch_size': 256, 'units': 150, 'lr': 0.005, 'optimizer': 'adam'}\n",
      " 1  2624/ 2676 B_acc: 0.823 T_acc: 0.926 V_acc: 0.691 G_acc: 0.794 P_acc: 0.981 R1_acc: 0.969 R2_acc: 0.815 R3_acc: 1.000 R4_acc: 0.979 Loss: 2.0278\n",
      " 1    78/   78 B_acc: 0.809 T_acc: 0.918 V_acc: 0.698 G_acc: 0.794 P_acc: 0.978 R1_acc: 0.941 R2_acc: 0.769 R3_acc: 1.000 R4_acc: 0.954 Loss: 2.5581\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/xnq55nff\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/xnq55nff</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 32, 'batch_size': 512, 'units': 150, 'lr': 0.0003, 'optimizer': 'adam'}\n",
      " 1  1312/ 1338 B_acc: 0.796 T_acc: 0.919 V_acc: 0.685 G_acc: 0.790 P_acc: 0.975 R1_acc: 0.940 R2_acc: 0.772 R3_acc: 1.000 R4_acc: 0.959 Loss: 2.64987\n",
      " 1    39/   39 B_acc: 0.785 T_acc: 0.912 V_acc: 0.691 G_acc: 0.792 P_acc: 0.973 R1_acc: 0.927 R2_acc: 0.744 R3_acc: 1.000 R4_acc: 0.930 Loss: 2.8993\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/1yxp25v1\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/1yxp25v1</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 32, 'batch_size': 512, 'units': 150, 'lr': 0.001, 'optimizer': 'adam'}\n",
      " 1  1312/ 1338 B_acc: 0.816 T_acc: 0.924 V_acc: 0.695 G_acc: 0.795 P_acc: 0.979 R1_acc: 0.965 R2_acc: 0.810 R3_acc: 1.000 R4_acc: 0.977 Loss: 2.11007\n",
      " 1    39/   39 B_acc: 0.812 T_acc: 0.918 V_acc: 0.697 G_acc: 0.794 P_acc: 0.976 R1_acc: 0.947 R2_acc: 0.779 R3_acc: 1.000 R4_acc: 0.957 Loss: 2.4012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/1swervcy\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/1swervcy</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 32, 'batch_size': 512, 'units': 150, 'lr': 0.003, 'optimizer': 'adam'}\n",
      " 1  1312/ 1338 B_acc: 0.823 T_acc: 0.926 V_acc: 0.692 G_acc: 0.795 P_acc: 0.979 R1_acc: 0.968 R2_acc: 0.812 R3_acc: 1.000 R4_acc: 0.981 Loss: 2.02732\n",
      " 1    39/   39 B_acc: 0.809 T_acc: 0.921 V_acc: 0.698 G_acc: 0.795 P_acc: 0.978 R1_acc: 0.938 R2_acc: 0.794 R3_acc: 1.000 R4_acc: 0.953 Loss: 2.4805\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/3899srqz\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/3899srqz</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'runsize': 32, 'batch_size': 512, 'units': 150, 'lr': 0.005, 'optimizer': 'adam'}\n",
      " 1  1312/ 1338 B_acc: 0.820 T_acc: 0.925 V_acc: 0.691 G_acc: 0.795 P_acc: 0.980 R1_acc: 0.968 R2_acc: 0.814 R3_acc: 1.000 R4_acc: 0.981 Loss: 2.0325\n",
      " 1    39/   39 B_acc: 0.807 T_acc: 0.921 V_acc: 0.698 G_acc: 0.790 P_acc: 0.978 R1_acc: 0.946 R2_acc: 0.773 R3_acc: 1.000 R4_acc: 0.955 Loss: 2.4832\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_SILENT true\n",
    "%env WANDB_MODE run\n",
    "\n",
    "config = {\n",
    "    'epochs': 1,\n",
    "    'test_size': test_size,\n",
    "}\n",
    "\n",
    "def experiment(units, lr, batch_size):\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    combinations = list(encoding.CLASSES)\n",
    "    \n",
    "    train_y = utils.ravel_multi_index(pre_train_y, combinations)\n",
    "    test_y = utils.ravel_multi_index(pre_test_y, combinations)\n",
    "    train = (train_x, train_y)\n",
    "    test = (test_x, test_y)\n",
    "    \n",
    "    config.update({\n",
    "        'runsize': 2 * 8192 // batch_size,\n",
    "        'batch_size': batch_size,\n",
    "        'units': units,\n",
    "        'lr': lr,\n",
    "        'optimizer': 'adam'\n",
    "    })\n",
    "    \n",
    "    model = to_device(Model(units=units, combinations=combinations))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    names_str = '+'.join(encoding.class_name(combination) for combination in combinations)\n",
    "    run = wandb.init(project=\"rootem\",\n",
    "                     group=f'separate-lstm',  # f'lr_units_grid_search-{arity}-{wandb.util.generate_id()}',\n",
    "                     name=f'sub_add-{units}-{lr:.0e}-{batch_size}',  # f'{gen}-{arity}-{lr:.0e}',# f'{arity}-batch_{BATCH_SIZE}', # f'all-{arity}-lr_{lr:.0e}-units_{units}',\n",
    "                     tags=[gen, arity, 'synthetic', 'shuffle-root', 'no_prefix', 'shuffle'],\n",
    "                     config=config)\n",
    "    with run:\n",
    "        run.use_artifact(artifact)\n",
    "\n",
    "        wandb.config.update(config, allow_val_change=True)\n",
    "\n",
    "        print(config)\n",
    "\n",
    "        if isinstance(model, nn.Module):\n",
    "            wandb.watch(model)\n",
    "\n",
    "        stats = fit(train=train,\n",
    "            test=test,\n",
    "            epochs=config['epochs'],\n",
    "            runsize=config['runsize'],\n",
    "            optimizer=optimizer,\n",
    "            batch_size=batch_size,\n",
    "            **standard_config(model, lr)\n",
    "        )\n",
    "        wandb.save(f\"simple_{arity}.h5\")\n",
    "\n",
    "    return model, stats\n",
    "\n",
    "units = 150\n",
    "for batch_size in [32, 64, 128, 256, 512]:\n",
    "    for lr in [3e-4, 1e-3, 3e-3, 5e-3]:\n",
    "        model, stats = experiment(units, lr, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_words(model):\n",
    "    print(predict(model, 'הבריל'))\n",
    "    print(predict(model, 'חגוו'))\n",
    "    print(predict(model, 'עגו'))\n",
    "    print(predict(model, 'צירלל'))\n",
    "    print(predict(model, \"השטקרפתי\"))\n",
    "    print(predict(model, \"ישסו\"))\n",
    "print_words(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input(\"$ \")\n",
    "input(\"$ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BATCH_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-64c32e4446cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
