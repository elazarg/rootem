{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "import seaborn as sn\n",
    "\n",
    "import utils\n",
    "from naive_model import NaiveModel\n",
    "from encoding import *\n",
    "\n",
    "NUM_EMBEDDING = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "def to_device(d):\n",
    "    if hasattr(d, 'cuda'):\n",
    "        return d.cuda()\n",
    "    return {k: v.cuda() for k, v in d.items()}\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=units)\n",
    "        self.lstm1 = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.binyan = nn.Linear(in_features=units, out_features=len(BINYAN))\n",
    "        self.tense = nn.Linear(in_features=units, out_features=len(TENSE))\n",
    "        self.voice = nn.Linear(in_features=units, out_features=len(VOICE))\n",
    "        self.gender = nn.Linear(in_features=units, out_features=len(GENDER))\n",
    "        self.plural = nn.Linear(in_features=units, out_features=len(PLURAL))\n",
    "\n",
    "        self.r1 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r2 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r3 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r4 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "\n",
    "        self.features = {\n",
    "            'B': self.binyan,\n",
    "            'T': self.tense,\n",
    "            'V': self.voice,\n",
    "            'G': self.gender,\n",
    "            'P': self.plural,\n",
    "\n",
    "            'R1': self.r1,\n",
    "            'R2': self.r2,\n",
    "            'R3': self.r3,\n",
    "            'R4': self.r4,\n",
    "        }\n",
    "        wandb.watch(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embed(x)\n",
    "\n",
    "        lstm_out, (h_n, c_n) = self.lstm1(embeds)\n",
    "        left, right = torch.chunk(h_n, 2, dim=0)\n",
    "        merge = torch.squeeze(left + right)\n",
    "\n",
    "        outputs = { k: f(merge) for k, f in self.features.items() }\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def sanity():\n",
    "    model = create_model(100)\n",
    "    with torch.no_grad():\n",
    "        verbs = wordlist2numpy([\"כשאתאקלם\"])\n",
    "        verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "        tag_scores = model(verbs)\n",
    "        for k in NAMES:\n",
    "            print(k)\n",
    "            v = nn.Softmax()(tag_scores[k]).cpu().detach().numpy()\n",
    "            print(v)\n",
    "            print(f'{np.mean(v)=}')\n",
    "            print(f'{-np.log(1/len(v))=}')\n",
    "            print()\n",
    "\n",
    "# sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concrete\n",
    "\n",
    "def load_dataset(file_pat):\n",
    "    *features_train, verbs_train = concrete.load_dataset(f'{file_pat}_train.tsv')\n",
    "    *features_test, verbs_test = concrete.load_dataset(f'{file_pat}_test.tsv')\n",
    "    return ((wordlist2numpy(verbs_train), list_of_lists_to_category(features_train)),\n",
    "            (wordlist2numpy(verbs_test), list_of_lists_to_category(features_test)))\n",
    "\n",
    "def load_dataset_split(filename, split):\n",
    "    *features_train, verbs_train = concrete.load_dataset(filename)\n",
    "    features_test = [t[-split:] for t in features_train]\n",
    "    verbs_test = verbs_train[-split:]\n",
    "    del verbs_train[-split:]\n",
    "    for t in features_train:\n",
    "        del t[-split:]\n",
    "    return ((wordlist2numpy(verbs_train), list_of_lists_to_category(features_train)),\n",
    "            (wordlist2numpy(verbs_test ), list_of_lists_to_category(features_test )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def batch(a):\n",
    "    ub = a.shape[0] // BATCH_SIZE * BATCH_SIZE\n",
    "    return to_device(torch.from_numpy(a[:ub]).to(torch.int64)).split(BATCH_SIZE)\n",
    "\n",
    "def batch_all_ys(ys):\n",
    "    res = []\n",
    "    m = {k: batch(ys[k]) for k in NAMES}\n",
    "    nbatches = len(m['B'])\n",
    "    for i in range(nbatches):\n",
    "        res.append({k: m[k][i] for k in NAMES})\n",
    "    return res\n",
    "\n",
    "def fit(model, train, test, *, epochs,  runsize, criterion, optimizer, phases, teacher):\n",
    "    x_train, y_train = train\n",
    "    x_test, y_test = test\n",
    "    data = {\n",
    "        'train': (batch(x_train), batch_all_ys(y_train)),\n",
    "        'test':  (batch(x_test ), batch_all_ys(y_test ))\n",
    "    }\n",
    "\n",
    "    stats = utils.Stats(runsize)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        stats.epoch_start()\n",
    "        \n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            stats.phase_start(phase, batches_in_phase=len(data[phase][0]))\n",
    "\n",
    "            for inputs, labels in zip(*data[phase]):\n",
    "                stats.batch_start()\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                if teacher is not None:\n",
    "                    pseudo_labels = teacher(inputs)\n",
    "                    losses = {k: criterion(outputs[k].double(), pseudo_labels[k]) for k in outputs}\n",
    "                else:\n",
    "                    losses = {k: criterion(outputs[k].double(), labels[k]) for k in outputs}\n",
    "                \n",
    "                if phase == 'train' and isinstance(criterion, nn.CrossEntropyLoss):\n",
    "                    stats.assert_resonable_initial(losses)\n",
    "                \n",
    "                loss = sum(losses.values())\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                stats.update(loss=loss.item(),\n",
    "                             batch_size=inputs.size(0),\n",
    "                             d={k: (outputs[k], labels[k].detach()) for k in outputs})\n",
    "                \n",
    "                stats.batch_end()\n",
    "            stats.phase_end()\n",
    "        stats.epoch_end()\n",
    "    return stats\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, *verbs):\n",
    "    model.eval()\n",
    "    verbs = wordlist2numpy(verbs)\n",
    "    verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "    outputs = model(verbs)\n",
    "    res = {k: from_category(k, torch.argmax(v))\n",
    "           for k, v in outputs.items()}\n",
    "    res['R'] = ''.join(res[k] for k in ['R1', 'R2', 'R3', 'R4']).replace('.', '')\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "arity = '3'\n",
    "gen = 'all'\n",
    "artifact_name = f'{gen}_{arity}_shuffled'\n",
    "filename = f'synthetic/{artifact_name}.tsv'  # all_verbs_shuffled\n",
    "test_size = 5000\n",
    "\n",
    "artifact = wandb.Artifact(artifact_name, type='dataset')\n",
    "artifact.add_file(filename)\n",
    "\n",
    "train, test = load_dataset_split(filename, split=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_config(filename):\n",
    "    return {\n",
    "        'model': NaiveModel.learn_from_file(filename),\n",
    "        'phases': ['test'],\n",
    "        'criterion': nn.CrossEntropyLoss(),\n",
    "        'optimizer': None\n",
    "    }\n",
    "\n",
    "def teacher_config(train):\n",
    "    res = standard_config()\n",
    "    res['teacher'] = NaiveModel.learn_from_data(train)\n",
    "    res['criterion'] = nn.BCEWithLogitsLoss()  # BCELoss: works, but total loss is nan\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/gugei21j\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/gugei21j</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'adam', 'batch_size': 64, 'epochs': 1, 'runsize': 128, 'test_size': 5000, 'units': 400, 'lr': 0.0008}\n",
      " 1 10880/10940 B_acc: 0.822 T_acc: 0.924 V_acc: 0.703 G_acc: 0.789 P_acc: 0.977 R1_acc: 0.973 R2_acc: 0.826 R3_acc: 1.000 R4_acc: 0.979 Loss: 1.9515\n",
      " 1    78/   78 B_acc: 0.835 T_acc: 0.927 V_acc: 0.698 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.972 R2_acc: 0.814 R3_acc: 1.000 R4_acc: 0.983 Loss: 1.9277\n"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_MODE'] = 'run'  # 'dryrun'\n",
    "\n",
    "config = {\n",
    "    'optimizer': 'adam',\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': 1,\n",
    "    'runsize': 8192 // BATCH_SIZE,\n",
    "    'test_size': test_size,\n",
    "}\n",
    "# group = f'lr_units_grid_search-{arity}-{wandb.util.generate_id()}'\n",
    "\n",
    "def experiment(lr):\n",
    "    units = 400\n",
    "\n",
    "    config.update({\n",
    "        'units': units,\n",
    "        'lr': lr,\n",
    "    })\n",
    "\n",
    "    run = wandb.init(project=\"rootem\",\n",
    "                     # group=group,\n",
    "                     name=f'{gen}-{arity}-{lr:.0e}',# f'{arity}-batch_{BATCH_SIZE}', # f'all-{arity}-lr_{lr:.0e}-units_{units}',\n",
    "                     tags=[gen, arity, 'synthetic', 'shuffle', 'no_prefix'],\n",
    "                     config=config)\n",
    "\n",
    "    run.use_artifact(artifact)\n",
    "\n",
    "    wandb.config.update(config, allow_val_change=True)\n",
    "\n",
    "    def standard_config():\n",
    "        model = to_device(Model(units=config['units']))\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        return {\n",
    "            'model': model,\n",
    "            'criterion': nn.CrossEntropyLoss(),\n",
    "            'optimizer': optimizer,\n",
    "            'phases': ['train', 'test'],\n",
    "            'teacher': None\n",
    "        }\n",
    "\n",
    "    print(config)\n",
    "    stats = fit(train=train,\n",
    "        test=test,\n",
    "        epochs=config['epochs'],\n",
    "        runsize=config['runsize'],\n",
    "        **standard_config()\n",
    "    )\n",
    "    wandb.save(f\"simple_{arity}.h5\")\n",
    "    return stats\n",
    "\n",
    "# lr = 8e-4, 10e-4, 20e-4, 30e-4, 40e-4, 50e-4, 60e-4]:\n",
    "stats = experiment(lr=8e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [x[::-1] for x in FEATURES['V']]\n",
    "ax = sn.heatmap(stats.confusion['V'], xticklabels=labels, yticklabels=labels, square=True, robust=True, linewidth=1.5, cmap=\"GnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, 'סבסו'))\n",
    "print(predict(model, 'מקדו'))\n",
    "print(predict(model, 'נמזר'))\n",
    "print(predict(model, 'כרדו'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, 'הבריל'))\n",
    "print(predict(model, 'חגוו'))\n",
    "print(predict(model, 'עגו'))\n",
    "print(predict(model, 'צירלל'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, \"השטקרפתי\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, \"ישסו\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import encoding\n",
    "import naive_model\n",
    "import utils\n",
    "encoding = importlib.reload(encoding)\n",
    "naive_model = importlib.reload(naive_model)\n",
    "utils = importlib.reload(utils)\n",
    "wandb = importlib.reload(wandb)\n",
    "Stats = utils.Stats\n",
    "NaiveModel = naive_model.NaiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "roc requires the scikit library, install with `pip install scikit-learn`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-238d66a4a627>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mFEATURES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHeatMap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\wandb\\plots\\heatmap.py\u001b[0m in \u001b[0;36mheatmap\u001b[1;34m(x_labels, y_labels, matrix_values, show_text)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \"\"\"\n\u001b[0;32m     25\u001b[0m         \u001b[0mnp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"numpy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequired\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"roc requires the numpy library, install with `pip install numpy`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mscikit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sklearn\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequired\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"roc requires the scikit library, install with `pip install scikit-learn`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         if (test_missing(x_labels=x_labels, y_labels=y_labels,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\wandb\\util.py\u001b[0m in \u001b[0;36mget_module\u001b[1;34m(name, required)\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrequired\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_not_importable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequired\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: roc requires the scikit library, install with `pip install scikit-learn`"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "labels = [x[::-1] for x in FEATURES['B']]\n",
    "wandb.plots.HeatMap(labels, labels, stats.confusion['B'])\n",
    "help(wandb.plots.heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
