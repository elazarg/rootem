{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import utils\n",
    "from stats import Stats\n",
    "from naive_model import NaiveModel\n",
    "from encoding import *\n",
    "\n",
    "NUM_EMBEDDING = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "def to_device(d):\n",
    "    if hasattr(d, 'cuda'):\n",
    "        return d.cuda()\n",
    "    return {k: v.cuda() for k, v in d.items()}\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=units)\n",
    "        self.lstm1 = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.binyan = nn.Linear(in_features=units, out_features=len(BINYAN))\n",
    "        self.tense = nn.Linear(in_features=units, out_features=len(TENSE))\n",
    "        self.voice = nn.Linear(in_features=units, out_features=len(VOICE))\n",
    "        self.gender = nn.Linear(in_features=units, out_features=len(GENDER))\n",
    "        self.plural = nn.Linear(in_features=units, out_features=len(PLURAL))\n",
    "\n",
    "        self.r1 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r2 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r3 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r4 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "\n",
    "        self.features = {\n",
    "            'B': self.binyan,\n",
    "            'T': self.tense,\n",
    "            'V': self.voice,\n",
    "            'G': self.gender,\n",
    "            'P': self.plural,\n",
    "\n",
    "            'R1': self.r1,\n",
    "            'R2': self.r2,\n",
    "            'R3': self.r3,\n",
    "            'R4': self.r4,\n",
    "        }\n",
    "        wandb.watch(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embed(x)\n",
    "\n",
    "        lstm_out, (h_n, c_n) = self.lstm1(embeds)\n",
    "        left, right = torch.chunk(h_n, 2, dim=0)\n",
    "        merge = torch.squeeze(left + right)\n",
    "\n",
    "        outputs = { k: f(merge) for k, f in self.features.items() }\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def sanity():\n",
    "    model = create_model(100)\n",
    "    with torch.no_grad():\n",
    "        verbs = wordlist2numpy([\"כשאתאקלם\"])\n",
    "        verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "        tag_scores = model(verbs)\n",
    "        for k in NAMES:\n",
    "            print(k)\n",
    "            v = nn.Softmax()(tag_scores[k]).cpu().detach().numpy()\n",
    "            print(v)\n",
    "            print(f'{np.mean(v)=}')\n",
    "            print(f'{-np.log(1/len(v))=}')\n",
    "            print()\n",
    "\n",
    "# sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concrete\n",
    "\n",
    "def load_dataset(file_pat):\n",
    "    *features_train, verbs_train = concrete.load_dataset(f'{file_pat}_train.tsv')\n",
    "    *features_test, verbs_test = concrete.load_dataset(f'{file_pat}_test.tsv')\n",
    "    return ((wordlist2numpy(verbs_train), list_of_lists_to_category(features_train)),\n",
    "            (wordlist2numpy(verbs_test), list_of_lists_to_category(features_test)))\n",
    "\n",
    "def load_dataset_split(filename, split):\n",
    "    *features_train, verbs_train = concrete.load_dataset(filename)\n",
    "    features_test = [t[-split:] for t in features_train]\n",
    "    verbs_test = verbs_train[-split:]\n",
    "    del verbs_train[-split:]\n",
    "    for t in features_train:\n",
    "        del t[-split:]\n",
    "    return ((wordlist2numpy(verbs_train), list_of_lists_to_category(features_train)),\n",
    "            (wordlist2numpy(verbs_test ), list_of_lists_to_category(features_test )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def batch(a):\n",
    "    ub = a.shape[0] // BATCH_SIZE * BATCH_SIZE\n",
    "    return to_device(torch.from_numpy(a[:ub]).to(torch.int64)).split(BATCH_SIZE)\n",
    "\n",
    "def batch_all_ys(ys):\n",
    "    res = []\n",
    "    m = {k: batch(ys[k]) for k in NAMES}\n",
    "    nbatches = len(m['B'])\n",
    "    for i in range(nbatches):\n",
    "        res.append({k: m[k][i] for k in NAMES})\n",
    "    return res\n",
    "\n",
    "def fit(model, train, test, *, epochs,  runsize, criterion, optimizer, phases, teacher):\n",
    "    x_train, y_train = train\n",
    "    x_test, y_test = train\n",
    "    data = {\n",
    "        'train': (batch(x_train), batch_all_ys(y_train)),\n",
    "        'test':  (batch(x_test ), batch_all_ys(y_test ))\n",
    "    }\n",
    "\n",
    "    stats = Stats(runsize)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        stats.epoch_start()\n",
    "        \n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            stats.phase_start(phase, batches_in_phase=len(data[phase][0]))\n",
    "\n",
    "            for inputs, labels in zip(*data[phase]):\n",
    "                stats.batch_start()\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                if teacher is not None:\n",
    "                    pseudo_labels = teacher(inputs)\n",
    "                    losses = {k: criterion(outputs[k].double(), pseudo_labels[k]) for k in outputs}\n",
    "                else:\n",
    "                    losses = {k: criterion(outputs[k].double(), labels[k]) for k in outputs}\n",
    "                \n",
    "                if phase == 'train' and isinstance(criterion, nn.CrossEntropyLoss):\n",
    "                    stats.assert_resonable_initial(losses)\n",
    "                \n",
    "                loss = sum(losses.values())\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                stats.update(loss=loss.item(),\n",
    "                             batch_size=inputs.size(0),\n",
    "                             d={k: (outputs[k], labels[k].detach()) for k in outputs})\n",
    "                \n",
    "                stats.batch_end()\n",
    "            stats.phase_end()\n",
    "        stats.epoch_end()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, *verbs):\n",
    "    model.eval()\n",
    "    verbs = wordlist2numpy(verbs)\n",
    "    verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "    outputs = model(verbs)\n",
    "    res = {k: from_category(k, torch.argmax(v))\n",
    "           for k, v in outputs.items()}\n",
    "    res['R'] = ''.join(res[k] for k in ['R1', 'R2', 'R3', 'R4']).replace('.', '')\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arity = 'combined'\n",
    "gen = 'all'\n",
    "artifact_name = f'{gen}_{arity}_shuffled'\n",
    "filename = f'synthetic/{artifact_name}.tsv'  # all_verbs_shuffled\n",
    "test_size = 5000\n",
    "\n",
    "artifact = wandb.Artifact(artifact_name, type='dataset')\n",
    "artifact.add_file(filename)\n",
    "\n",
    "train, test = load_dataset_split(filename, split=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_config(filename):\n",
    "    return {\n",
    "        'model': NaiveModel.learn_from_file(filename),\n",
    "        'phases': ['test'],\n",
    "        'criterion': nn.CrossEntropyLoss(),\n",
    "        'optimizer': None\n",
    "    }\n",
    "\n",
    "def teacher_config(train):\n",
    "    res = standard_config()\n",
    "    res['teacher'] = NaiveModel.learn_from_data(train)\n",
    "    res['criterion'] = nn.BCEWithLogitsLoss()  # BCELoss: works, but total loss is nan\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Using artifacts in dryrun mode is currently unsupported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'adam', 'batch_size': 64, 'epochs': 1, 'runsize': 8, 'test_size': 5000, 'units': 400, 'lr': 0.0008}\n",
      " 1 11840/11842 B_acc: 0.822 T_acc: 0.920 V_acc: 0.674 G_acc: 0.805 P_acc: 0.973 R1_acc: 0.967 R2_acc: 0.812 R3_acc: 0.992 R4_acc: 0.984 Loss: 2.00305B_acc: 0.635 T_acc: 0.844 V_acc: 0.551 G_acc: 0.754 P_acc: 0.939 R1_acc: 0.799 R2_acc: 0.422 R3_acc: 0.906 R4_acc: 0.756 Loss: 6.4536B_acc: 0.729 T_acc: 0.842 V_acc: 0.584 G_acc: 0.797 P_acc: 0.965 R1_acc: 0.879 R2_acc: 0.572 R3_acc: 0.949 R4_acc: 0.895 Loss: 4.7357 B_acc: 0.654 T_acc: 0.879 V_acc: 0.621 G_acc: 0.783 P_acc: 0.953 R1_acc: 0.859 R2_acc: 0.574 R3_acc: 0.959 R4_acc: 0.900 Loss: 4.6592B_acc: 0.750 T_acc: 0.861 V_acc: 0.641 G_acc: 0.768 P_acc: 0.953 R1_acc: 0.916 R2_acc: 0.645 R3_acc: 0.930 R4_acc: 0.918 Loss: 4.2853G_acc: 0.758 P_acc: 0.973 R1_acc: 0.898 R2_acc: 0.664 R3_acc: 0.953 R4_acc: 0.924 Loss: 4.1538B_acc: 0.711 T_acc: 0.885 V_acc: 0.678 G_acc: 0.809 P_acc: 0.973 R1_acc: 0.906 R2_acc: 0.635 R3_acc: 0.924 R4_acc: 0.924 Loss: 4.1022P_acc: 0.967 R1_acc: 0.924 R2_acc: 0.719 R3_acc: 0.949 R4_acc: 0.912 Loss: 3.6508B_acc: 0.740 T_acc: 0.895 V_acc: 0.670 G_acc: 0.766 P_acc: 0.969 R1_acc: 0.920 R2_acc: 0.709 R3_acc: 0.973 R4_acc: 0.936 Loss: 3.5359B_acc: 0.754 T_acc: 0.900 V_acc: 0.699 G_acc: 0.818 P_acc: 0.982 R1_acc: 0.916 R2_acc: 0.707 R3_acc: 0.951 R4_acc: 0.908 Loss: 3.4452B_acc: 0.777 T_acc: 0.891 V_acc: 0.676 G_acc: 0.746 P_acc: 0.977 R1_acc: 0.914 R2_acc: 0.746 R3_acc: 0.967 R4_acc: 0.943 Loss: 3.3124B_acc: 0.760 T_acc: 0.869 V_acc: 0.680 G_acc: 0.803 P_acc: 0.967 R1_acc: 0.922 R2_acc: 0.729 R3_acc: 0.980 R4_acc: 0.932 Loss: 3.3514B_acc: 0.805 T_acc: 0.900 V_acc: 0.693 G_acc: 0.787 P_acc: 0.973 R1_acc: 0.932 R2_acc: 0.707 R3_acc: 0.967 R4_acc: 0.947 Loss: 3.1038B_acc: 0.760 T_acc: 0.914 V_acc: 0.637 G_acc: 0.807 P_acc: 0.961 R1_acc: 0.930 R2_acc: 0.764 R3_acc: 0.969 R4_acc: 0.949 Loss: 3.2036B_acc: 0.773 T_acc: 0.895 V_acc: 0.670 G_acc: 0.785 P_acc: 0.977 R1_acc: 0.910 R2_acc: 0.762 R3_acc: 0.971 R4_acc: 0.938 Loss: 3.1883B_acc: 0.783 T_acc: 0.924 V_acc: 0.676 G_acc: 0.811 P_acc: 0.977 R1_acc: 0.932 R2_acc: 0.738 R3_acc: 0.967 R4_acc: 0.945 Loss: 3.1008P_acc: 0.982 R1_acc: 0.918 R2_acc: 0.723 R3_acc: 0.969 R4_acc: 0.934 Loss: 3.1552B_acc: 0.805 T_acc: 0.922 V_acc: 0.668 G_acc: 0.791 P_acc: 0.979 R1_acc: 0.939 R2_acc: 0.742 R3_acc: 0.969 R4_acc: 0.926 Loss: 3.0866B_acc: 0.818 T_acc: 0.900 V_acc: 0.691 G_acc: 0.783 P_acc: 0.975 R1_acc: 0.932 R2_acc: 0.732 R3_acc: 0.977 R4_acc: 0.963 Loss: 2.9541B_acc: 0.793 T_acc: 0.889 V_acc: 0.697 G_acc: 0.758 P_acc: 0.977 R1_acc: 0.934 R2_acc: 0.742 R3_acc: 0.965 R4_acc: 0.953 Loss: 2.9791 G_acc: 0.814 P_acc: 0.975 R1_acc: 0.922 R2_acc: 0.721 R3_acc: 0.973 R4_acc: 0.939 Loss: 3.0775B_acc: 0.773 T_acc: 0.924 V_acc: 0.709 G_acc: 0.775 P_acc: 0.973 R1_acc: 0.932 R2_acc: 0.760 R3_acc: 0.984 R4_acc: 0.957 Loss: 2.9014 B_acc: 0.779 T_acc: 0.912 V_acc: 0.711 G_acc: 0.783 P_acc: 0.971 R1_acc: 0.934 R2_acc: 0.758 R3_acc: 0.986 R4_acc: 0.951 Loss: 2.8560B_acc: 0.793 T_acc: 0.912 V_acc: 0.670 G_acc: 0.756 P_acc: 0.963 R1_acc: 0.934 R2_acc: 0.754 R3_acc: 0.982 R4_acc: 0.930 Loss: 3.0847B_acc: 0.775 T_acc: 0.912 V_acc: 0.674 G_acc: 0.816 P_acc: 0.973 R1_acc: 0.939 R2_acc: 0.805 R3_acc: 0.979 R4_acc: 0.969 Loss: 2.7913B_acc: 0.787 T_acc: 0.906 V_acc: 0.670 G_acc: 0.779 P_acc: 0.980 R1_acc: 0.932 R2_acc: 0.775 R3_acc: 0.979 R4_acc: 0.947 Loss: 2.9022B_acc: 0.801 T_acc: 0.914 V_acc: 0.691 G_acc: 0.799 P_acc: 0.973 R1_acc: 0.938 R2_acc: 0.797 R3_acc: 0.980 R4_acc: 0.957 Loss: 2.8276 B_acc: 0.773 T_acc: 0.900 V_acc: 0.693 G_acc: 0.812 P_acc: 0.969 R1_acc: 0.941 R2_acc: 0.764 R3_acc: 0.977 R4_acc: 0.943 Loss: 2.9329B_acc: 0.805 T_acc: 0.926 V_acc: 0.725 G_acc: 0.752 P_acc: 0.982 R1_acc: 0.941 R2_acc: 0.795 R3_acc: 0.969 R4_acc: 0.957 Loss: 2.7046T_acc: 0.922 V_acc: 0.645 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.961 R2_acc: 0.734 R3_acc: 0.975 R4_acc: 0.949 Loss: 2.8020 B_acc: 0.777 T_acc: 0.906 V_acc: 0.705 G_acc: 0.779 P_acc: 0.973 R1_acc: 0.951 R2_acc: 0.758 R3_acc: 0.988 R4_acc: 0.971 Loss: 2.7441B_acc: 0.787 T_acc: 0.906 V_acc: 0.715 G_acc: 0.793 P_acc: 0.982 R1_acc: 0.943 R2_acc: 0.773 R3_acc: 0.975 R4_acc: 0.943 Loss: 2.7668B_acc: 0.783 T_acc: 0.918 V_acc: 0.697 G_acc: 0.750 P_acc: 0.984 R1_acc: 0.949 R2_acc: 0.820 R3_acc: 0.990 R4_acc: 0.951 Loss: 2.6896 B_acc: 0.830 T_acc: 0.918 V_acc: 0.680 G_acc: 0.791 P_acc: 0.973 R1_acc: 0.943 R2_acc: 0.770 R3_acc: 0.986 R4_acc: 0.945 Loss: 2.6343 B_acc: 0.785 T_acc: 0.900 V_acc: 0.684 G_acc: 0.779 P_acc: 0.967 R1_acc: 0.939 R2_acc: 0.775 R3_acc: 0.969 R4_acc: 0.963 Loss: 2.9670R3_acc: 0.977 R4_acc: 0.967 Loss: 2.5965B_acc: 0.785 T_acc: 0.918 V_acc: 0.648 G_acc: 0.824 P_acc: 0.986 R1_acc: 0.949 R2_acc: 0.793 R3_acc: 0.975 R4_acc: 0.961 Loss: 2.6093G_acc: 0.777 P_acc: 0.973 R1_acc: 0.939 R2_acc: 0.770 R3_acc: 0.977 R4_acc: 0.965 Loss: 2.7812B_acc: 0.811 T_acc: 0.930 V_acc: 0.682 G_acc: 0.773 P_acc: 0.980 R1_acc: 0.943 R2_acc: 0.793 R3_acc: 0.977 R4_acc: 0.953 Loss: 2.6412B_acc: 0.826 T_acc: 0.928 V_acc: 0.684 G_acc: 0.762 P_acc: 0.969 R1_acc: 0.914 R2_acc: 0.779 R3_acc: 0.979 R4_acc: 0.953 Loss: 2.7349B_acc: 0.812 T_acc: 0.898 V_acc: 0.680 G_acc: 0.775 P_acc: 0.979 R1_acc: 0.947 R2_acc: 0.803 R3_acc: 0.988 R4_acc: 0.963 Loss: 2.6549B_acc: 0.812 T_acc: 0.922 V_acc: 0.668 G_acc: 0.775 P_acc: 0.980 R1_acc: 0.959 R2_acc: 0.789 R3_acc: 0.984 R4_acc: 0.965 Loss: 2.5438R4_acc: 0.955 Loss: 2.6030B_acc: 0.844 T_acc: 0.928 V_acc: 0.695 G_acc: 0.803 P_acc: 0.984 R1_acc: 0.939 R2_acc: 0.768 R3_acc: 0.980 R4_acc: 0.969 Loss: 2.5537B_acc: 0.805 T_acc: 0.916 V_acc: 0.693 G_acc: 0.764 P_acc: 0.980 R1_acc: 0.945 R2_acc: 0.805 R3_acc: 0.980 R4_acc: 0.975 Loss: 2.5876B_acc: 0.793 T_acc: 0.904 V_acc: 0.682 G_acc: 0.820 P_acc: 0.973 R1_acc: 0.949 R2_acc: 0.770 R3_acc: 0.982 R4_acc: 0.955 Loss: 2.7049R3_acc: 0.977 R4_acc: 0.963 Loss: 2.7638B_acc: 0.777 T_acc: 0.910 V_acc: 0.699 G_acc: 0.791 P_acc: 0.963 R1_acc: 0.943 R2_acc: 0.777 R3_acc: 0.986 R4_acc: 0.969 Loss: 2.6497B_acc: 0.803 T_acc: 0.908 V_acc: 0.670 G_acc: 0.781 P_acc: 0.969 R1_acc: 0.961 R2_acc: 0.789 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.4854B_acc: 0.844 T_acc: 0.918 V_acc: 0.662 G_acc: 0.803 P_acc: 0.979 R1_acc: 0.943 R2_acc: 0.771 R3_acc: 0.988 R4_acc: 0.969 Loss: 2.4885B_acc: 0.820 T_acc: 0.924 V_acc: 0.699 G_acc: 0.773 P_acc: 0.984 R1_acc: 0.953 R2_acc: 0.801 R3_acc: 0.990 R4_acc: 0.965 Loss: 2.3465B_acc: 0.818 T_acc: 0.938 V_acc: 0.717 G_acc: 0.805 P_acc: 0.984 R1_acc: 0.959 R2_acc: 0.801 R3_acc: 0.986 R4_acc: 0.973 Loss: 2.2990B_acc: 0.797 T_acc: 0.920 V_acc: 0.645 G_acc: 0.807 P_acc: 0.973 R1_acc: 0.949 R2_acc: 0.807 R3_acc: 0.982 R4_acc: 0.980 Loss: 2.4963B_acc: 0.781 T_acc: 0.922 V_acc: 0.686 G_acc: 0.789 P_acc: 0.977 R1_acc: 0.949 R2_acc: 0.799 R3_acc: 0.986 R4_acc: 0.971 Loss: 2.5276B_acc: 0.812 T_acc: 0.902 V_acc: 0.701 G_acc: 0.797 P_acc: 0.977 R1_acc: 0.941 R2_acc: 0.807 R3_acc: 0.969 R4_acc: 0.955 Loss: 2.6225T_acc: 0.922 V_acc: 0.686 G_acc: 0.781 P_acc: 0.975 R1_acc: 0.947 R2_acc: 0.822 R3_acc: 0.990 R4_acc: 0.961 Loss: 2.5012B_acc: 0.805 T_acc: 0.906 V_acc: 0.691 G_acc: 0.805 P_acc: 0.984 R1_acc: 0.963 R2_acc: 0.840 R3_acc: 0.984 R4_acc: 0.969 Loss: 2.3995B_acc: 0.854 T_acc: 0.930 V_acc: 0.711 G_acc: 0.793 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.807 R3_acc: 0.979 R4_acc: 0.980 Loss: 2.3051B_acc: 0.799 T_acc: 0.914 V_acc: 0.676 G_acc: 0.773 P_acc: 0.977 R1_acc: 0.939 R2_acc: 0.770 R3_acc: 0.982 R4_acc: 0.961 Loss: 2.7110B_acc: 0.820 T_acc: 0.920 V_acc: 0.697 G_acc: 0.801 P_acc: 0.992 R1_acc: 0.949 R2_acc: 0.824 R3_acc: 0.982 R4_acc: 0.971 Loss: 2.3895B_acc: 0.785 T_acc: 0.908 V_acc: 0.725 G_acc: 0.814 P_acc: 0.977 R1_acc: 0.936 R2_acc: 0.770 R3_acc: 0.986 R4_acc: 0.967 Loss: 2.5239B_acc: 0.822 T_acc: 0.906 V_acc: 0.678 G_acc: 0.764 P_acc: 0.971 R1_acc: 0.957 R2_acc: 0.803 R3_acc: 0.982 R4_acc: 0.971 Loss: 2.4716B_acc: 0.789 T_acc: 0.912 V_acc: 0.697 G_acc: 0.773 P_acc: 0.984 R1_acc: 0.967 R2_acc: 0.779 R3_acc: 0.986 R4_acc: 0.965 Loss: 2.4458B_acc: 0.830 T_acc: 0.895 V_acc: 0.688 G_acc: 0.803 P_acc: 0.971 R1_acc: 0.945 R2_acc: 0.805 R3_acc: 0.988 R4_acc: 0.965 Loss: 2.3686P_acc: 0.979 R1_acc: 0.947 R2_acc: 0.783 R3_acc: 0.988 R4_acc: 0.977 Loss: 2.3988B_acc: 0.801 T_acc: 0.924 V_acc: 0.713 G_acc: 0.801 P_acc: 0.980 R1_acc: 0.949 R2_acc: 0.801 R3_acc: 0.990 R4_acc: 0.971 Loss: 2.4067B_acc: 0.822 T_acc: 0.900 V_acc: 0.656 G_acc: 0.805 P_acc: 0.979 R1_acc: 0.955 R2_acc: 0.801 R3_acc: 0.980 R4_acc: 0.971 Loss: 2.4923B_acc: 0.799 T_acc: 0.916 V_acc: 0.707 G_acc: 0.777 P_acc: 0.984 R1_acc: 0.951 R2_acc: 0.781 R3_acc: 0.992 R4_acc: 0.969 Loss: 2.4789B_acc: 0.816 T_acc: 0.926 V_acc: 0.695 G_acc: 0.764 P_acc: 0.975 R1_acc: 0.957 R2_acc: 0.812 R3_acc: 0.990 R4_acc: 0.973 Loss: 2.4053G_acc: 0.807 P_acc: 0.986 R1_acc: 0.973 R2_acc: 0.805 R3_acc: 0.988 R4_acc: 0.969 Loss: 2.3745T_acc: 0.908 V_acc: 0.684 G_acc: 0.807 P_acc: 0.973 R1_acc: 0.949 R2_acc: 0.799 R3_acc: 0.990 R4_acc: 0.980 Loss: 2.3906B_acc: 0.812 T_acc: 0.918 V_acc: 0.686 G_acc: 0.809 P_acc: 0.975 R1_acc: 0.961 R2_acc: 0.799 R3_acc: 0.986 R4_acc: 0.980 Loss: 2.3932B_acc: 0.818 T_acc: 0.918 V_acc: 0.709 G_acc: 0.787 P_acc: 0.988 R1_acc: 0.973 R2_acc: 0.807 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.2957B_acc: 0.832 T_acc: 0.930 V_acc: 0.701 G_acc: 0.785 P_acc: 0.969 R1_acc: 0.951 R2_acc: 0.795 R3_acc: 0.986 R4_acc: 0.969 Loss: 2.3757B_acc: 0.807 T_acc: 0.924 V_acc: 0.713 G_acc: 0.799 P_acc: 0.980 R1_acc: 0.965 R2_acc: 0.809 R3_acc: 0.990 R4_acc: 0.980 Loss: 2.2567B_acc: 0.840 T_acc: 0.896 V_acc: 0.648 G_acc: 0.838 P_acc: 0.984 R1_acc: 0.947 R2_acc: 0.822 R3_acc: 0.990 R4_acc: 0.973 Loss: 2.2346B_acc: 0.832 T_acc: 0.920 V_acc: 0.693 G_acc: 0.801 P_acc: 0.984 R1_acc: 0.953 R2_acc: 0.793 R3_acc: 0.992 R4_acc: 0.959 Loss: 2.3658B_acc: 0.818 T_acc: 0.904 V_acc: 0.693 G_acc: 0.805 P_acc: 0.977 R1_acc: 0.957 R2_acc: 0.816 R3_acc: 0.990 R4_acc: 0.979 Loss: 2.3206B_acc: 0.848 T_acc: 0.949 V_acc: 0.734 G_acc: 0.789 P_acc: 0.973 R1_acc: 0.951 R2_acc: 0.828 R3_acc: 0.980 R4_acc: 0.980 Loss: 2.1567B_acc: 0.805 T_acc: 0.906 V_acc: 0.680 G_acc: 0.789 P_acc: 0.979 R1_acc: 0.938 R2_acc: 0.801 R3_acc: 0.992 R4_acc: 0.961 Loss: 2.4860B_acc: 0.828 T_acc: 0.934 V_acc: 0.691 G_acc: 0.787 P_acc: 0.982 R1_acc: 0.965 R2_acc: 0.816 R3_acc: 0.990 R4_acc: 0.982 Loss: 2.2633B_acc: 0.799 T_acc: 0.934 V_acc: 0.721 G_acc: 0.799 P_acc: 0.982 R1_acc: 0.965 R2_acc: 0.811 R3_acc: 0.992 R4_acc: 0.982 Loss: 2.2520B_acc: 0.805 T_acc: 0.910 V_acc: 0.695 G_acc: 0.801 P_acc: 0.986 R1_acc: 0.941 R2_acc: 0.811 R3_acc: 0.992 R4_acc: 0.963 Loss: 2.3737T_acc: 0.920 V_acc: 0.670 G_acc: 0.801 P_acc: 0.975 R1_acc: 0.957 R2_acc: 0.826 R3_acc: 0.992 R4_acc: 0.971 Loss: 2.2862B_acc: 0.824 T_acc: 0.920 V_acc: 0.684 G_acc: 0.787 P_acc: 0.988 R1_acc: 0.961 R2_acc: 0.812 R3_acc: 0.982 R4_acc: 0.975 Loss: 2.2763V_acc: 0.715 G_acc: 0.801 P_acc: 0.984 R1_acc: 0.957 R2_acc: 0.787 R3_acc: 0.986 R4_acc: 0.973 Loss: 2.2919R2_acc: 0.818 R3_acc: 0.994 R4_acc: 0.967 Loss: 2.3060R1_acc: 0.949 R2_acc: 0.809 R3_acc: 0.990 R4_acc: 0.973 Loss: 2.2985B_acc: 0.816 T_acc: 0.906 V_acc: 0.719 G_acc: 0.787 P_acc: 0.979 R1_acc: 0.949 R2_acc: 0.789 R3_acc: 0.988 R4_acc: 0.961 Loss: 2.3636B_acc: 0.834 T_acc: 0.922 V_acc: 0.693 G_acc: 0.768 P_acc: 0.980 R1_acc: 0.971 R2_acc: 0.809 R3_acc: 0.988 R4_acc: 0.975 Loss: 2.2531B_acc: 0.820 T_acc: 0.939 V_acc: 0.703 G_acc: 0.764 P_acc: 0.979 R1_acc: 0.959 R2_acc: 0.791 R3_acc: 0.994 R4_acc: 0.977 Loss: 2.2546B_acc: 0.832 T_acc: 0.926 V_acc: 0.711 G_acc: 0.807 P_acc: 0.982 R1_acc: 0.963 R2_acc: 0.834 R3_acc: 0.986 R4_acc: 0.982 Loss: 2.1894T_acc: 0.920 V_acc: 0.686 G_acc: 0.789 P_acc: 0.986 R1_acc: 0.977 R2_acc: 0.809 R3_acc: 0.988 R4_acc: 0.979 Loss: 2.1445B_acc: 0.836 T_acc: 0.922 V_acc: 0.678 G_acc: 0.770 P_acc: 0.975 R1_acc: 0.961 R2_acc: 0.812 R3_acc: 0.992 R4_acc: 0.967 Loss: 2.2056B_acc: 0.857 T_acc: 0.895 V_acc: 0.693 G_acc: 0.783 P_acc: 0.969 R1_acc: 0.951 R2_acc: 0.826 R3_acc: 0.994 R4_acc: 0.971 Loss: 2.2999B_acc: 0.799 T_acc: 0.924 V_acc: 0.695 G_acc: 0.766 P_acc: 0.982 R1_acc: 0.961 R2_acc: 0.816 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.3653B_acc: 0.824 T_acc: 0.916 V_acc: 0.713 G_acc: 0.803 P_acc: 0.971 R1_acc: 0.957 R2_acc: 0.797 R3_acc: 0.988 R4_acc: 0.973 Loss: 2.2765B_acc: 0.824 T_acc: 0.918 V_acc: 0.705 G_acc: 0.789 P_acc: 0.967 R1_acc: 0.961 R2_acc: 0.781 R3_acc: 0.990 R4_acc: 0.977 Loss: 2.2539B_acc: 0.812 T_acc: 0.910 V_acc: 0.719 G_acc: 0.791 P_acc: 0.984 R1_acc: 0.971 R2_acc: 0.828 R3_acc: 0.998 R4_acc: 0.971 Loss: 2.1806B_acc: 0.822 T_acc: 0.916 V_acc: 0.660 G_acc: 0.791 P_acc: 0.986 R1_acc: 0.959 R2_acc: 0.844 R3_acc: 0.986 R4_acc: 0.980 Loss: 2.1635 B_acc: 0.828 T_acc: 0.920 V_acc: 0.682 G_acc: 0.828 P_acc: 0.984 R1_acc: 0.957 R2_acc: 0.824 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.1791B_acc: 0.832 T_acc: 0.947 V_acc: 0.689 G_acc: 0.779 P_acc: 0.977 R1_acc: 0.967 R2_acc: 0.799 R3_acc: 0.986 R4_acc: 0.984 Loss: 2.1022 B_acc: 0.797 T_acc: 0.918 V_acc: 0.676 G_acc: 0.785 P_acc: 0.973 R1_acc: 0.959 R2_acc: 0.834 R3_acc: 0.992 R4_acc: 0.982 Loss: 2.2034B_acc: 0.852 T_acc: 0.943 V_acc: 0.699 G_acc: 0.818 P_acc: 0.979 R1_acc: 0.959 R2_acc: 0.824 R3_acc: 0.994 R4_acc: 0.979 Loss: 2.0826B_acc: 0.832 T_acc: 0.939 V_acc: 0.727 G_acc: 0.803 P_acc: 0.986 R1_acc: 0.980 R2_acc: 0.793 R3_acc: 0.990 R4_acc: 0.982 Loss: 2.0393 B_acc: 0.836 T_acc: 0.920 V_acc: 0.684 G_acc: 0.807 P_acc: 0.986 R1_acc: 0.980 R2_acc: 0.828 R3_acc: 0.992 R4_acc: 0.982 Loss: 2.0735B_acc: 0.848 T_acc: 0.920 V_acc: 0.711 G_acc: 0.830 P_acc: 0.973 R1_acc: 0.951 R2_acc: 0.830 R3_acc: 0.988 R4_acc: 0.977 Loss: 2.0788 B_acc: 0.850 T_acc: 0.926 V_acc: 0.732 G_acc: 0.779 P_acc: 0.971 R1_acc: 0.963 R2_acc: 0.793 R3_acc: 0.988 R4_acc: 0.982 Loss: 2.1578B_acc: 0.820 T_acc: 0.920 V_acc: 0.680 G_acc: 0.812 P_acc: 0.975 R1_acc: 0.969 R2_acc: 0.842 R3_acc: 0.992 R4_acc: 0.982 Loss: 2.1878B_acc: 0.852 T_acc: 0.934 V_acc: 0.670 G_acc: 0.803 P_acc: 0.984 R1_acc: 0.967 R2_acc: 0.812 R3_acc: 0.994 R4_acc: 0.971 Loss: 2.1667B_acc: 0.801 T_acc: 0.912 V_acc: 0.680 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.965 R2_acc: 0.811 R3_acc: 0.994 R4_acc: 0.977 Loss: 2.1769B_acc: 0.836 T_acc: 0.941 V_acc: 0.682 G_acc: 0.803 P_acc: 0.990 R1_acc: 0.973 R2_acc: 0.857 R3_acc: 0.986 R4_acc: 0.986 Loss: 1.9831B_acc: 0.812 T_acc: 0.918 V_acc: 0.703 G_acc: 0.803 P_acc: 0.980 R1_acc: 0.957 R2_acc: 0.830 R3_acc: 0.986 R4_acc: 0.980 Loss: 2.2266B_acc: 0.844 T_acc: 0.932 V_acc: 0.730 G_acc: 0.797 P_acc: 0.980 R1_acc: 0.949 R2_acc: 0.824 R3_acc: 0.996 R4_acc: 0.982 Loss: 2.1193B_acc: 0.852 T_acc: 0.936 V_acc: 0.693 G_acc: 0.803 P_acc: 0.982 R1_acc: 0.965 R2_acc: 0.805 R3_acc: 0.992 R4_acc: 0.971 Loss: 2.0942B_acc: 0.830 T_acc: 0.912 V_acc: 0.693 G_acc: 0.781 P_acc: 0.971 R1_acc: 0.969 R2_acc: 0.801 R3_acc: 0.994 R4_acc: 0.986 Loss: 2.1961B_acc: 0.820 T_acc: 0.910 V_acc: 0.689 G_acc: 0.758 P_acc: 0.982 R1_acc: 0.969 R2_acc: 0.820 R3_acc: 0.994 R4_acc: 0.971 Loss: 2.2576B_acc: 0.840 T_acc: 0.951 V_acc: 0.713 G_acc: 0.787 P_acc: 0.980 R1_acc: 0.971 R2_acc: 0.799 R3_acc: 0.998 R4_acc: 0.979 Loss: 2.0312B_acc: 0.805 T_acc: 0.934 V_acc: 0.693 G_acc: 0.809 P_acc: 0.992 R1_acc: 0.965 R2_acc: 0.842 R3_acc: 0.998 R4_acc: 0.986 Loss: 2.1435B_acc: 0.828 T_acc: 0.920 V_acc: 0.664 G_acc: 0.766 P_acc: 0.990 R1_acc: 0.955 R2_acc: 0.822 R3_acc: 0.986 R4_acc: 0.980 Loss: 2.2518B_acc: 0.822 T_acc: 0.912 V_acc: 0.713 G_acc: 0.816 P_acc: 0.979 R1_acc: 0.965 R2_acc: 0.832 R3_acc: 0.996 R4_acc: 0.986 Loss: 2.0886B_acc: 0.830 T_acc: 0.926 V_acc: 0.715 G_acc: 0.795 P_acc: 0.988 R1_acc: 0.965 R2_acc: 0.814 R3_acc: 0.990 R4_acc: 0.984 Loss: 2.0732B_acc: 0.814 T_acc: 0.922 V_acc: 0.660 G_acc: 0.779 P_acc: 0.973 R1_acc: 0.969 R2_acc: 0.850 R3_acc: 0.992 R4_acc: 0.982 Loss: 2.0904T_acc: 0.910 V_acc: 0.670 G_acc: 0.785 P_acc: 0.979 R1_acc: 0.963 R2_acc: 0.814 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.2247B_acc: 0.889 T_acc: 0.920 V_acc: 0.684 G_acc: 0.809 P_acc: 0.980 R1_acc: 0.957 R2_acc: 0.820 R3_acc: 0.992 R4_acc: 0.984 Loss: 2.0409B_acc: 0.850 T_acc: 0.922 V_acc: 0.709 G_acc: 0.801 P_acc: 0.973 R1_acc: 0.957 R2_acc: 0.809 R3_acc: 0.988 R4_acc: 0.984 Loss: 2.1915B_acc: 0.840 T_acc: 0.934 V_acc: 0.693 G_acc: 0.766 P_acc: 0.977 R1_acc: 0.967 R2_acc: 0.811 R3_acc: 0.992 R4_acc: 0.980 Loss: 2.1223B_acc: 0.830 T_acc: 0.928 V_acc: 0.697 G_acc: 0.803 P_acc: 0.986 R1_acc: 0.969 R2_acc: 0.834 R3_acc: 0.994 R4_acc: 0.980 Loss: 2.0822R4_acc: 0.967 Loss: 2.2662G_acc: 0.797 P_acc: 0.982 R1_acc: 0.969 R2_acc: 0.830 R3_acc: 0.998 R4_acc: 0.986 Loss: 2.0416T_acc: 0.908 V_acc: 0.695 G_acc: 0.793 P_acc: 0.971 R1_acc: 0.961 R2_acc: 0.799 R3_acc: 0.992 R4_acc: 0.961 Loss: 2.3398B_acc: 0.826 T_acc: 0.930 V_acc: 0.717 G_acc: 0.773 P_acc: 0.965 R1_acc: 0.969 R2_acc: 0.773 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.2380B_acc: 0.848 T_acc: 0.922 V_acc: 0.705 G_acc: 0.768 P_acc: 0.959 R1_acc: 0.971 R2_acc: 0.830 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.1011B_acc: 0.811 T_acc: 0.928 V_acc: 0.664 G_acc: 0.791 P_acc: 0.977 R1_acc: 0.971 R2_acc: 0.822 R3_acc: 0.992 R4_acc: 0.971 Loss: 2.1701B_acc: 0.844 T_acc: 0.930 V_acc: 0.701 G_acc: 0.807 P_acc: 0.980 R1_acc: 0.979 R2_acc: 0.830 R3_acc: 0.994 R4_acc: 0.971 Loss: 1.9780T_acc: 0.936 V_acc: 0.705 G_acc: 0.824 P_acc: 0.979 R1_acc: 0.969 R2_acc: 0.822 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9881B_acc: 0.787 T_acc: 0.914 V_acc: 0.682 G_acc: 0.799 P_acc: 0.982 R1_acc: 0.961 R2_acc: 0.801 R3_acc: 0.994 R4_acc: 0.979 Loss: 2.3081B_acc: 0.805 T_acc: 0.924 V_acc: 0.697 G_acc: 0.789 P_acc: 0.982 R1_acc: 0.957 R2_acc: 0.805 R3_acc: 0.988 R4_acc: 0.965 Loss: 2.2702B_acc: 0.838 T_acc: 0.943 V_acc: 0.678 G_acc: 0.773 P_acc: 0.986 R1_acc: 0.967 R2_acc: 0.822 R3_acc: 0.988 R4_acc: 0.977 Loss: 2.1387B_acc: 0.850 T_acc: 0.932 V_acc: 0.719 G_acc: 0.812 P_acc: 0.977 R1_acc: 0.965 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.975 Loss: 2.0183R1_acc: 0.965 R2_acc: 0.811 R3_acc: 0.986 R4_acc: 0.980 Loss: 2.1162B_acc: 0.822 T_acc: 0.898 V_acc: 0.689 G_acc: 0.768 P_acc: 0.982 R1_acc: 0.965 R2_acc: 0.797 R3_acc: 0.990 R4_acc: 0.984 Loss: 2.2137B_acc: 0.826 T_acc: 0.910 V_acc: 0.668 G_acc: 0.760 P_acc: 0.980 R1_acc: 0.979 R2_acc: 0.820 R3_acc: 0.994 R4_acc: 0.992 Loss: 2.0147B_acc: 0.848 T_acc: 0.945 V_acc: 0.752 G_acc: 0.789 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.818 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.0204 B_acc: 0.807 T_acc: 0.910 V_acc: 0.697 G_acc: 0.826 P_acc: 0.973 R1_acc: 0.965 R2_acc: 0.846 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0898B_acc: 0.857 T_acc: 0.914 V_acc: 0.703 G_acc: 0.764 P_acc: 0.979 R1_acc: 0.969 R2_acc: 0.861 R3_acc: 0.996 R4_acc: 0.980 Loss: 2.1178B_acc: 0.850 T_acc: 0.936 V_acc: 0.680 G_acc: 0.787 P_acc: 0.986 R1_acc: 0.945 R2_acc: 0.779 R3_acc: 0.988 R4_acc: 0.986 Loss: 2.2517B_acc: 0.824 T_acc: 0.928 V_acc: 0.701 G_acc: 0.807 P_acc: 0.980 R1_acc: 0.984 R2_acc: 0.859 R3_acc: 0.998 R4_acc: 0.990 Loss: 1.9257B_acc: 0.859 T_acc: 0.914 V_acc: 0.684 G_acc: 0.775 P_acc: 0.973 R1_acc: 0.959 R2_acc: 0.797 R3_acc: 0.992 R4_acc: 0.973 Loss: 2.2452B_acc: 0.822 T_acc: 0.910 V_acc: 0.691 G_acc: 0.812 P_acc: 0.967 R1_acc: 0.977 R2_acc: 0.834 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.1594V_acc: 0.707 G_acc: 0.766 P_acc: 0.975 R1_acc: 0.971 R2_acc: 0.834 R3_acc: 0.990 R4_acc: 0.982 Loss: 2.1387 B_acc: 0.812 T_acc: 0.928 V_acc: 0.707 G_acc: 0.760 P_acc: 0.965 R1_acc: 0.971 R2_acc: 0.812 R3_acc: 0.992 R4_acc: 0.971 Loss: 2.1869P_acc: 0.980 R1_acc: 0.961 R2_acc: 0.812 R3_acc: 0.996 R4_acc: 0.965 Loss: 2.2623R2_acc: 0.789 R3_acc: 0.990 R4_acc: 0.980 Loss: 2.0923B_acc: 0.840 T_acc: 0.908 V_acc: 0.656 G_acc: 0.822 P_acc: 0.967 R1_acc: 0.967 R2_acc: 0.832 R3_acc: 0.992 R4_acc: 0.980 Loss: 2.1254B_acc: 0.834 T_acc: 0.904 V_acc: 0.654 G_acc: 0.793 P_acc: 0.977 R1_acc: 0.963 R2_acc: 0.785 R3_acc: 0.998 R4_acc: 0.982 Loss: 2.2403B_acc: 0.863 T_acc: 0.918 V_acc: 0.684 G_acc: 0.809 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.826 R3_acc: 0.994 R4_acc: 0.973 Loss: 2.0035B_acc: 0.840 T_acc: 0.928 V_acc: 0.699 G_acc: 0.760 P_acc: 0.979 R1_acc: 0.959 R2_acc: 0.852 R3_acc: 0.996 R4_acc: 0.980 Loss: 2.1019B_acc: 0.824 T_acc: 0.928 V_acc: 0.717 G_acc: 0.793 P_acc: 0.979 R1_acc: 0.955 R2_acc: 0.791 R3_acc: 0.994 R4_acc: 0.971 Loss: 2.1440T_acc: 0.916 V_acc: 0.699 G_acc: 0.783 P_acc: 0.965 R1_acc: 0.982 R2_acc: 0.812 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.1549B_acc: 0.807 T_acc: 0.912 V_acc: 0.680 G_acc: 0.793 P_acc: 0.973 R1_acc: 0.971 R2_acc: 0.820 R3_acc: 0.996 R4_acc: 0.986 Loss: 2.1274B_acc: 0.805 T_acc: 0.928 V_acc: 0.715 G_acc: 0.826 P_acc: 0.984 R1_acc: 0.967 R2_acc: 0.816 R3_acc: 0.994 R4_acc: 0.979 Loss: 2.0946B_acc: 0.820 T_acc: 0.906 V_acc: 0.717 G_acc: 0.791 P_acc: 0.980 R1_acc: 0.967 R2_acc: 0.840 R3_acc: 0.996 R4_acc: 0.979 Loss: 2.0372B_acc: 0.852 T_acc: 0.918 V_acc: 0.668 G_acc: 0.822 P_acc: 0.982 R1_acc: 0.977 R2_acc: 0.826 R3_acc: 0.996 R4_acc: 0.984 Loss: 2.0039R2_acc: 0.824 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.9260B_acc: 0.832 T_acc: 0.932 V_acc: 0.732 G_acc: 0.793 P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.840 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9759B_acc: 0.830 T_acc: 0.932 V_acc: 0.715 G_acc: 0.779 P_acc: 0.973 R1_acc: 0.959 R2_acc: 0.832 R3_acc: 0.988 R4_acc: 0.980 Loss: 2.0716B_acc: 0.795 T_acc: 0.943 V_acc: 0.699 G_acc: 0.793 P_acc: 0.977 R1_acc: 0.975 R2_acc: 0.848 R3_acc: 0.998 R4_acc: 0.988 Loss: 1.9859B_acc: 0.812 T_acc: 0.938 V_acc: 0.682 G_acc: 0.789 P_acc: 0.980 R1_acc: 0.975 R2_acc: 0.820 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.1144B_acc: 0.840 T_acc: 0.936 V_acc: 0.750 G_acc: 0.793 P_acc: 0.982 R1_acc: 0.961 R2_acc: 0.838 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0753B_acc: 0.834 T_acc: 0.926 V_acc: 0.703 G_acc: 0.760 P_acc: 0.980 R1_acc: 0.967 R2_acc: 0.822 R3_acc: 0.998 R4_acc: 0.977 Loss: 2.0136B_acc: 0.820 T_acc: 0.920 V_acc: 0.701 G_acc: 0.760 P_acc: 0.986 R1_acc: 0.963 R2_acc: 0.807 R3_acc: 0.996 R4_acc: 0.975 Loss: 2.2655B_acc: 0.805 T_acc: 0.912 V_acc: 0.684 G_acc: 0.807 P_acc: 0.984 R1_acc: 0.977 R2_acc: 0.803 R3_acc: 0.998 R4_acc: 0.988 Loss: 2.0986B_acc: 0.838 T_acc: 0.932 V_acc: 0.705 G_acc: 0.807 P_acc: 0.980 R1_acc: 0.961 R2_acc: 0.820 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0831B_acc: 0.816 T_acc: 0.920 V_acc: 0.684 G_acc: 0.779 P_acc: 0.973 R1_acc: 0.955 R2_acc: 0.832 R3_acc: 0.988 R4_acc: 0.975 Loss: 2.2651B_acc: 0.850 T_acc: 0.926 V_acc: 0.684 G_acc: 0.811 P_acc: 0.977 R1_acc: 0.977 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.971 Loss: 2.0081T_acc: 0.938 V_acc: 0.676 G_acc: 0.807 P_acc: 0.982 R1_acc: 0.980 R2_acc: 0.824 R3_acc: 0.998 R4_acc: 0.980 Loss: 1.9658B_acc: 0.789 T_acc: 0.936 V_acc: 0.711 G_acc: 0.781 P_acc: 0.980 R1_acc: 0.957 R2_acc: 0.807 R3_acc: 0.996 R4_acc: 0.975 Loss: 2.2295B_acc: 0.836 T_acc: 0.922 V_acc: 0.713 G_acc: 0.787 P_acc: 0.971 R1_acc: 0.959 R2_acc: 0.832 R3_acc: 0.986 R4_acc: 0.979 Loss: 2.1272B_acc: 0.824 T_acc: 0.928 V_acc: 0.684 G_acc: 0.807 P_acc: 0.977 R1_acc: 0.969 R2_acc: 0.787 R3_acc: 1.000 R4_acc: 0.979 Loss: 2.1505B_acc: 0.855 T_acc: 0.928 V_acc: 0.713 G_acc: 0.793 P_acc: 0.988 R1_acc: 0.965 R2_acc: 0.848 R3_acc: 0.992 R4_acc: 0.982 Loss: 1.9504 B_acc: 0.854 T_acc: 0.936 V_acc: 0.699 G_acc: 0.787 P_acc: 0.980 R1_acc: 0.959 R2_acc: 0.822 R3_acc: 0.996 R4_acc: 0.973 Loss: 2.0739B_acc: 0.861 T_acc: 0.936 V_acc: 0.693 G_acc: 0.803 P_acc: 0.982 R1_acc: 0.977 R2_acc: 0.807 R3_acc: 0.992 R4_acc: 0.979 Loss: 1.9936B_acc: 0.824 T_acc: 0.932 V_acc: 0.689 G_acc: 0.781 P_acc: 0.986 R1_acc: 0.965 R2_acc: 0.834 R3_acc: 0.996 R4_acc: 0.988 Loss: 2.0088B_acc: 0.820 T_acc: 0.930 V_acc: 0.703 G_acc: 0.809 P_acc: 0.984 R1_acc: 0.977 R2_acc: 0.820 R3_acc: 0.990 R4_acc: 0.982 Loss: 2.0298B_acc: 0.822 T_acc: 0.936 V_acc: 0.676 G_acc: 0.809 P_acc: 0.988 R1_acc: 0.963 R2_acc: 0.818 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9922B_acc: 0.807 T_acc: 0.943 V_acc: 0.693 G_acc: 0.803 P_acc: 0.984 R1_acc: 0.975 R2_acc: 0.773 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0528B_acc: 0.814 T_acc: 0.922 V_acc: 0.732 G_acc: 0.779 P_acc: 0.980 R1_acc: 0.971 R2_acc: 0.818 R3_acc: 0.998 R4_acc: 0.979 Loss: 2.0317T_acc: 0.914 V_acc: 0.721 G_acc: 0.795 P_acc: 0.984 R1_acc: 0.963 R2_acc: 0.803 R3_acc: 0.994 R4_acc: 0.973 Loss: 2.1001V_acc: 0.674 G_acc: 0.773 P_acc: 0.959 R1_acc: 0.977 R2_acc: 0.857 R3_acc: 0.994 R4_acc: 0.969 Loss: 2.0309B_acc: 0.826 T_acc: 0.922 V_acc: 0.686 G_acc: 0.795 P_acc: 0.980 R1_acc: 0.971 R2_acc: 0.818 R3_acc: 0.992 R4_acc: 0.973 Loss: 2.0556B_acc: 0.820 T_acc: 0.918 V_acc: 0.666 G_acc: 0.797 P_acc: 0.986 R1_acc: 0.979 R2_acc: 0.828 R3_acc: 0.994 R4_acc: 0.980 Loss: 2.0918B_acc: 0.816 T_acc: 0.914 V_acc: 0.672 G_acc: 0.797 P_acc: 0.980 R1_acc: 0.963 R2_acc: 0.828 R3_acc: 0.996 R4_acc: 0.979 Loss: 2.0692B_acc: 0.836 T_acc: 0.926 V_acc: 0.713 G_acc: 0.758 P_acc: 0.975 R1_acc: 0.961 R2_acc: 0.822 R3_acc: 0.998 R4_acc: 0.986 Loss: 2.0239B_acc: 0.830 T_acc: 0.934 V_acc: 0.689 G_acc: 0.811 P_acc: 0.977 R1_acc: 0.975 R2_acc: 0.816 R3_acc: 0.982 R4_acc: 0.982 Loss: 2.0058B_acc: 0.805 T_acc: 0.934 V_acc: 0.705 G_acc: 0.777 P_acc: 0.977 R1_acc: 0.973 R2_acc: 0.814 R3_acc: 0.996 R4_acc: 0.969 Loss: 2.0783B_acc: 0.824 T_acc: 0.926 V_acc: 0.689 G_acc: 0.797 P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.805 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.1469T_acc: 0.918 V_acc: 0.674 G_acc: 0.801 P_acc: 0.988 R1_acc: 0.967 R2_acc: 0.822 R3_acc: 0.990 R4_acc: 0.975 Loss: 2.1190B_acc: 0.830 T_acc: 0.938 V_acc: 0.682 G_acc: 0.781 P_acc: 0.990 R1_acc: 0.961 R2_acc: 0.809 R3_acc: 0.986 R4_acc: 0.977 Loss: 2.0797B_acc: 0.830 T_acc: 0.910 V_acc: 0.691 G_acc: 0.814 P_acc: 0.980 R1_acc: 0.959 R2_acc: 0.807 R3_acc: 0.992 R4_acc: 0.973 Loss: 2.1406B_acc: 0.812 T_acc: 0.939 V_acc: 0.666 G_acc: 0.818 P_acc: 0.984 R1_acc: 0.967 R2_acc: 0.809 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0721B_acc: 0.816 T_acc: 0.902 V_acc: 0.680 G_acc: 0.760 P_acc: 0.979 R1_acc: 0.965 R2_acc: 0.818 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.3339B_acc: 0.812 T_acc: 0.932 V_acc: 0.678 G_acc: 0.793 P_acc: 0.971 R1_acc: 0.965 R2_acc: 0.826 R3_acc: 0.994 R4_acc: 0.980 Loss: 2.1447B_acc: 0.834 T_acc: 0.924 V_acc: 0.658 G_acc: 0.775 P_acc: 0.986 R1_acc: 0.977 R2_acc: 0.832 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.0557B_acc: 0.846 T_acc: 0.926 V_acc: 0.684 G_acc: 0.783 P_acc: 0.986 R1_acc: 0.980 R2_acc: 0.793 R3_acc: 0.992 R4_acc: 0.992 Loss: 2.0526B_acc: 0.834 T_acc: 0.912 V_acc: 0.660 G_acc: 0.820 P_acc: 0.980 R1_acc: 0.975 R2_acc: 0.844 R3_acc: 0.996 R4_acc: 0.977 Loss: 2.1303 B_acc: 0.816 T_acc: 0.934 V_acc: 0.721 G_acc: 0.775 P_acc: 0.982 R1_acc: 0.975 R2_acc: 0.832 R3_acc: 0.994 R4_acc: 0.984 Loss: 2.0081B_acc: 0.832 T_acc: 0.936 V_acc: 0.707 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.959 R2_acc: 0.805 R3_acc: 0.994 R4_acc: 0.971 Loss: 2.1118B_acc: 0.842 T_acc: 0.932 V_acc: 0.707 G_acc: 0.814 P_acc: 0.969 R1_acc: 0.971 R2_acc: 0.824 R3_acc: 0.996 R4_acc: 0.986 Loss: 1.9905B_acc: 0.854 T_acc: 0.920 V_acc: 0.709 G_acc: 0.744 P_acc: 0.967 R1_acc: 0.971 R2_acc: 0.830 R3_acc: 0.998 R4_acc: 0.982 Loss: 2.0744B_acc: 0.820 T_acc: 0.930 V_acc: 0.701 G_acc: 0.799 P_acc: 0.982 R1_acc: 0.984 R2_acc: 0.826 R3_acc: 0.994 R4_acc: 0.977 Loss: 1.9432T_acc: 0.938 V_acc: 0.686 G_acc: 0.809 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.807 R3_acc: 0.998 R4_acc: 0.986 Loss: 1.9831B_acc: 0.844 T_acc: 0.945 V_acc: 0.705 G_acc: 0.809 P_acc: 0.977 R1_acc: 0.961 R2_acc: 0.812 R3_acc: 0.990 R4_acc: 0.973 Loss: 2.0208B_acc: 0.863 T_acc: 0.918 V_acc: 0.662 G_acc: 0.797 P_acc: 0.986 R1_acc: 0.969 R2_acc: 0.814 R3_acc: 0.998 R4_acc: 0.984 Loss: 2.0265 B_acc: 0.812 T_acc: 0.938 V_acc: 0.686 G_acc: 0.801 P_acc: 0.982 R1_acc: 0.947 R2_acc: 0.775 R3_acc: 0.990 R4_acc: 0.980 Loss: 2.2453B_acc: 0.824 T_acc: 0.926 V_acc: 0.678 G_acc: 0.803 P_acc: 0.984 R1_acc: 0.969 R2_acc: 0.820 R3_acc: 0.992 R4_acc: 0.982 Loss: 2.0842B_acc: 0.812 T_acc: 0.916 V_acc: 0.658 G_acc: 0.797 P_acc: 0.979 R1_acc: 0.965 R2_acc: 0.830 R3_acc: 0.996 R4_acc: 0.982 Loss: 2.1335B_acc: 0.820 T_acc: 0.939 V_acc: 0.713 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.982 R2_acc: 0.799 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.9857B_acc: 0.824 T_acc: 0.930 V_acc: 0.723 G_acc: 0.783 P_acc: 0.975 R1_acc: 0.979 R2_acc: 0.805 R3_acc: 0.992 R4_acc: 0.971 Loss: 2.0550B_acc: 0.816 T_acc: 0.934 V_acc: 0.691 G_acc: 0.781 P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.836 R3_acc: 0.996 R4_acc: 0.982 Loss: 1.9529B_acc: 0.809 T_acc: 0.906 V_acc: 0.656 G_acc: 0.771 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.836 R3_acc: 0.996 R4_acc: 0.979 Loss: 2.1020B_acc: 0.832 T_acc: 0.922 V_acc: 0.725 G_acc: 0.803 P_acc: 0.979 R1_acc: 0.971 R2_acc: 0.854 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.0079B_acc: 0.836 T_acc: 0.922 V_acc: 0.688 G_acc: 0.803 P_acc: 0.982 R1_acc: 0.965 R2_acc: 0.777 R3_acc: 0.990 R4_acc: 0.979 Loss: 2.1679B_acc: 0.809 T_acc: 0.920 V_acc: 0.705 G_acc: 0.801 P_acc: 0.979 R1_acc: 0.969 R2_acc: 0.838 R3_acc: 0.998 R4_acc: 0.986 Loss: 2.0263B_acc: 0.812 T_acc: 0.930 V_acc: 0.713 G_acc: 0.830 P_acc: 0.979 R1_acc: 0.969 R2_acc: 0.816 R3_acc: 0.988 R4_acc: 0.979 Loss: 1.9910B_acc: 0.828 T_acc: 0.928 V_acc: 0.693 G_acc: 0.805 P_acc: 0.980 R1_acc: 0.971 R2_acc: 0.824 R3_acc: 0.994 R4_acc: 0.986 Loss: 2.0067B_acc: 0.840 T_acc: 0.916 V_acc: 0.684 G_acc: 0.781 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.826 R3_acc: 0.998 R4_acc: 0.967 Loss: 2.1092 B_acc: 0.859 T_acc: 0.934 V_acc: 0.725 G_acc: 0.797 P_acc: 0.980 R1_acc: 0.977 R2_acc: 0.824 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.8521B_acc: 0.846 T_acc: 0.930 V_acc: 0.711 G_acc: 0.768 P_acc: 0.980 R1_acc: 0.963 R2_acc: 0.840 R3_acc: 0.996 R4_acc: 0.984 Loss: 1.9738B_acc: 0.832 T_acc: 0.916 V_acc: 0.686 G_acc: 0.807 P_acc: 0.982 R1_acc: 0.969 R2_acc: 0.818 R3_acc: 0.990 R4_acc: 0.971 Loss: 2.0007B_acc: 0.809 T_acc: 0.938 V_acc: 0.693 G_acc: 0.783 P_acc: 0.980 R1_acc: 0.982 R2_acc: 0.842 R3_acc: 0.992 R4_acc: 0.982 Loss: 1.9935V_acc: 0.705 G_acc: 0.816 P_acc: 0.980 R1_acc: 0.971 R2_acc: 0.838 R3_acc: 0.994 R4_acc: 0.975 Loss: 1.9661B_acc: 0.838 T_acc: 0.922 V_acc: 0.723 G_acc: 0.799 P_acc: 0.975 R1_acc: 0.969 R2_acc: 0.797 R3_acc: 1.000 R4_acc: 0.986 Loss: 1.9868B_acc: 0.848 T_acc: 0.932 V_acc: 0.711 G_acc: 0.777 P_acc: 0.979 R1_acc: 0.965 R2_acc: 0.865 R3_acc: 0.994 R4_acc: 0.986 Loss: 1.9408B_acc: 0.867 T_acc: 0.918 V_acc: 0.680 G_acc: 0.814 P_acc: 0.977 R1_acc: 0.971 R2_acc: 0.818 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.9618 B_acc: 0.822 T_acc: 0.922 V_acc: 0.701 G_acc: 0.777 P_acc: 0.986 R1_acc: 0.953 R2_acc: 0.807 R3_acc: 0.996 R4_acc: 0.975 Loss: 2.1010B_acc: 0.838 T_acc: 0.920 V_acc: 0.709 G_acc: 0.779 P_acc: 0.977 R1_acc: 0.980 R2_acc: 0.854 R3_acc: 0.994 R4_acc: 0.986 Loss: 1.8911B_acc: 0.848 T_acc: 0.920 V_acc: 0.732 G_acc: 0.775 P_acc: 0.977 R1_acc: 0.965 R2_acc: 0.814 R3_acc: 0.988 R4_acc: 0.973 Loss: 2.1058T_acc: 0.963 V_acc: 0.715 G_acc: 0.793 P_acc: 0.990 R1_acc: 0.979 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.980 Loss: 1.9370B_acc: 0.826 T_acc: 0.924 V_acc: 0.682 G_acc: 0.803 P_acc: 0.975 R1_acc: 0.965 R2_acc: 0.820 R3_acc: 0.994 R4_acc: 0.986 Loss: 2.0839B_acc: 0.846 T_acc: 0.918 V_acc: 0.693 G_acc: 0.820 P_acc: 0.988 R1_acc: 0.969 R2_acc: 0.828 R3_acc: 0.994 R4_acc: 0.986 Loss: 1.9598 B_acc: 0.803 T_acc: 0.947 V_acc: 0.701 G_acc: 0.781 P_acc: 0.988 R1_acc: 0.961 R2_acc: 0.805 R3_acc: 0.996 R4_acc: 0.980 Loss: 2.0210B_acc: 0.828 T_acc: 0.934 V_acc: 0.711 G_acc: 0.783 P_acc: 0.984 R1_acc: 0.965 R2_acc: 0.830 R3_acc: 0.990 R4_acc: 0.977 Loss: 1.9740B_acc: 0.844 T_acc: 0.939 V_acc: 0.670 G_acc: 0.793 P_acc: 0.994 R1_acc: 0.971 R2_acc: 0.826 R3_acc: 0.992 R4_acc: 0.980 Loss: 1.9945 B_acc: 0.850 T_acc: 0.924 V_acc: 0.668 G_acc: 0.773 P_acc: 0.984 R1_acc: 0.965 R2_acc: 0.840 R3_acc: 0.990 R4_acc: 0.982 Loss: 2.0659B_acc: 0.816 T_acc: 0.934 V_acc: 0.705 G_acc: 0.752 P_acc: 0.986 R1_acc: 0.973 R2_acc: 0.861 R3_acc: 0.992 R4_acc: 0.980 Loss: 2.0117P_acc: 0.982 R1_acc: 0.973 R2_acc: 0.832 R3_acc: 0.992 R4_acc: 0.990 Loss: 1.8760B_acc: 0.852 T_acc: 0.936 V_acc: 0.674 G_acc: 0.793 P_acc: 0.990 R1_acc: 0.982 R2_acc: 0.826 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.8900B_acc: 0.871 T_acc: 0.932 V_acc: 0.738 G_acc: 0.836 P_acc: 0.986 R1_acc: 0.975 R2_acc: 0.811 R3_acc: 1.000 R4_acc: 0.980 Loss: 1.8534B_acc: 0.840 T_acc: 0.945 V_acc: 0.707 G_acc: 0.793 P_acc: 0.984 R1_acc: 0.975 R2_acc: 0.824 R3_acc: 0.994 R4_acc: 0.979 Loss: 1.9362B_acc: 0.824 T_acc: 0.932 V_acc: 0.697 G_acc: 0.791 P_acc: 0.969 R1_acc: 0.957 R2_acc: 0.822 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.0623B_acc: 0.816 T_acc: 0.938 V_acc: 0.674 G_acc: 0.758 P_acc: 0.971 R1_acc: 0.965 R2_acc: 0.824 R3_acc: 0.998 R4_acc: 0.986 Loss: 2.1330P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.863 R3_acc: 0.996 R4_acc: 0.984 Loss: 1.8765B_acc: 0.816 T_acc: 0.910 V_acc: 0.695 G_acc: 0.797 P_acc: 0.992 R1_acc: 0.975 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.975 Loss: 2.0629B_acc: 0.830 T_acc: 0.934 V_acc: 0.695 G_acc: 0.766 P_acc: 0.967 R1_acc: 0.961 R2_acc: 0.838 R3_acc: 0.994 R4_acc: 0.973 Loss: 2.0811B_acc: 0.838 T_acc: 0.920 V_acc: 0.682 G_acc: 0.811 P_acc: 0.986 R1_acc: 0.963 R2_acc: 0.818 R3_acc: 0.990 R4_acc: 0.969 Loss: 2.0684B_acc: 0.844 T_acc: 0.924 V_acc: 0.697 G_acc: 0.812 P_acc: 0.977 R1_acc: 0.973 R2_acc: 0.832 R3_acc: 0.992 R4_acc: 0.979 Loss: 1.9726B_acc: 0.820 T_acc: 0.920 V_acc: 0.672 G_acc: 0.799 P_acc: 0.969 R1_acc: 0.977 R2_acc: 0.807 R3_acc: 0.992 R4_acc: 0.969 Loss: 2.1969 B_acc: 0.830 T_acc: 0.918 V_acc: 0.689 G_acc: 0.811 P_acc: 0.971 R1_acc: 0.975 R2_acc: 0.822 R3_acc: 0.994 R4_acc: 0.982 Loss: 2.0091B_acc: 0.863 T_acc: 0.926 V_acc: 0.691 G_acc: 0.795 P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.852 R3_acc: 0.998 R4_acc: 0.992 Loss: 1.8687G_acc: 0.814 P_acc: 0.975 R1_acc: 0.973 R2_acc: 0.822 R3_acc: 0.994 R4_acc: 0.967 Loss: 2.1019B_acc: 0.852 T_acc: 0.938 V_acc: 0.697 G_acc: 0.773 P_acc: 0.975 R1_acc: 0.971 R2_acc: 0.846 R3_acc: 0.992 R4_acc: 0.988 Loss: 2.0209B_acc: 0.844 T_acc: 0.912 V_acc: 0.662 G_acc: 0.793 P_acc: 0.977 R1_acc: 0.979 R2_acc: 0.836 R3_acc: 1.000 R4_acc: 0.979 Loss: 1.9874B_acc: 0.828 T_acc: 0.941 V_acc: 0.721 G_acc: 0.797 P_acc: 0.984 R1_acc: 0.973 R2_acc: 0.836 R3_acc: 0.988 R4_acc: 0.984 Loss: 1.9142B_acc: 0.852 T_acc: 0.918 V_acc: 0.670 G_acc: 0.803 P_acc: 0.979 R1_acc: 0.961 R2_acc: 0.824 R3_acc: 0.990 R4_acc: 0.975 Loss: 2.0725B_acc: 0.859 T_acc: 0.924 V_acc: 0.686 G_acc: 0.807 P_acc: 0.975 R1_acc: 0.975 R2_acc: 0.834 R3_acc: 0.996 R4_acc: 0.979 Loss: 1.8891B_acc: 0.830 T_acc: 0.908 V_acc: 0.709 G_acc: 0.775 P_acc: 0.979 R1_acc: 0.982 R2_acc: 0.830 R3_acc: 0.990 R4_acc: 0.984 Loss: 2.0093B_acc: 0.809 T_acc: 0.916 V_acc: 0.711 G_acc: 0.805 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.838 R3_acc: 0.996 R4_acc: 0.975 Loss: 2.0547B_acc: 0.842 T_acc: 0.926 V_acc: 0.732 G_acc: 0.789 P_acc: 0.980 R1_acc: 0.967 R2_acc: 0.789 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0793 B_acc: 0.822 T_acc: 0.930 V_acc: 0.682 G_acc: 0.791 P_acc: 0.982 R1_acc: 0.967 R2_acc: 0.811 R3_acc: 0.988 R4_acc: 0.980 Loss: 2.0684B_acc: 0.832 T_acc: 0.922 V_acc: 0.652 G_acc: 0.820 P_acc: 0.979 R1_acc: 0.973 R2_acc: 0.840 R3_acc: 0.990 R4_acc: 0.980 Loss: 2.0483 B_acc: 0.836 T_acc: 0.898 V_acc: 0.695 G_acc: 0.775 P_acc: 0.973 R1_acc: 0.975 R2_acc: 0.850 R3_acc: 0.994 R4_acc: 0.967 Loss: 2.1167B_acc: 0.818 T_acc: 0.906 V_acc: 0.678 G_acc: 0.814 P_acc: 0.973 R1_acc: 0.965 R2_acc: 0.830 R3_acc: 0.990 R4_acc: 0.971 Loss: 2.1485B_acc: 0.814 T_acc: 0.928 V_acc: 0.713 G_acc: 0.795 P_acc: 0.979 R1_acc: 0.969 R2_acc: 0.816 R3_acc: 0.998 R4_acc: 0.979 Loss: 2.0456 B_acc: 0.842 T_acc: 0.928 V_acc: 0.699 G_acc: 0.758 P_acc: 0.988 R1_acc: 0.977 R2_acc: 0.818 R3_acc: 0.992 R4_acc: 0.979 Loss: 1.9620B_acc: 0.854 T_acc: 0.902 V_acc: 0.648 G_acc: 0.787 P_acc: 0.975 R1_acc: 0.971 R2_acc: 0.811 R3_acc: 0.990 R4_acc: 0.977 Loss: 2.2185B_acc: 0.861 T_acc: 0.930 V_acc: 0.676 G_acc: 0.822 P_acc: 0.977 R1_acc: 0.975 R2_acc: 0.834 R3_acc: 0.990 R4_acc: 0.975 Loss: 1.9515 B_acc: 0.811 T_acc: 0.926 V_acc: 0.654 G_acc: 0.838 P_acc: 0.982 R1_acc: 0.965 R2_acc: 0.824 R3_acc: 0.990 R4_acc: 0.969 Loss: 2.1064B_acc: 0.842 T_acc: 0.936 V_acc: 0.711 G_acc: 0.785 P_acc: 0.984 R1_acc: 0.971 R2_acc: 0.820 R3_acc: 0.992 R4_acc: 0.988 Loss: 1.9459B_acc: 0.859 T_acc: 0.902 V_acc: 0.670 G_acc: 0.791 P_acc: 0.971 R1_acc: 0.971 R2_acc: 0.850 R3_acc: 0.990 R4_acc: 0.973 Loss: 2.0709R3_acc: 0.994 R4_acc: 0.986 Loss: 1.9814B_acc: 0.814 T_acc: 0.930 V_acc: 0.678 G_acc: 0.783 P_acc: 0.979 R1_acc: 0.957 R2_acc: 0.814 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.1211B_acc: 0.826 T_acc: 0.926 V_acc: 0.697 G_acc: 0.803 P_acc: 0.984 R1_acc: 0.963 R2_acc: 0.826 R3_acc: 0.994 R4_acc: 0.980 Loss: 2.0079 B_acc: 0.855 T_acc: 0.943 V_acc: 0.709 G_acc: 0.799 P_acc: 0.990 R1_acc: 0.969 R2_acc: 0.820 R3_acc: 0.994 R4_acc: 0.986 Loss: 1.9311 B_acc: 0.852 T_acc: 0.934 V_acc: 0.705 G_acc: 0.789 P_acc: 0.982 R1_acc: 0.969 R2_acc: 0.834 R3_acc: 0.996 R4_acc: 0.986 Loss: 1.8507B_acc: 0.857 T_acc: 0.938 V_acc: 0.713 G_acc: 0.785 P_acc: 0.986 R1_acc: 0.980 R2_acc: 0.828 R3_acc: 0.994 R4_acc: 0.990 Loss: 1.8926B_acc: 0.812 T_acc: 0.910 V_acc: 0.688 G_acc: 0.807 P_acc: 0.988 R1_acc: 0.967 R2_acc: 0.854 R3_acc: 0.992 R4_acc: 0.982 Loss: 2.0452 B_acc: 0.846 T_acc: 0.924 V_acc: 0.662 G_acc: 0.799 P_acc: 0.973 R1_acc: 0.961 R2_acc: 0.828 R3_acc: 0.998 R4_acc: 0.963 Loss: 2.0847B_acc: 0.799 T_acc: 0.912 V_acc: 0.646 G_acc: 0.812 P_acc: 0.977 R1_acc: 0.953 R2_acc: 0.795 R3_acc: 0.996 R4_acc: 0.969 Loss: 2.3290B_acc: 0.840 T_acc: 0.934 V_acc: 0.697 G_acc: 0.811 P_acc: 0.988 R1_acc: 0.967 R2_acc: 0.826 R3_acc: 0.996 R4_acc: 0.988 Loss: 1.9233B_acc: 0.818 T_acc: 0.930 V_acc: 0.713 G_acc: 0.801 P_acc: 0.990 R1_acc: 0.967 R2_acc: 0.818 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.9974B_acc: 0.848 T_acc: 0.928 V_acc: 0.732 G_acc: 0.781 P_acc: 0.982 R1_acc: 0.975 R2_acc: 0.828 R3_acc: 0.988 R4_acc: 0.982 Loss: 1.8805B_acc: 0.854 T_acc: 0.938 V_acc: 0.693 G_acc: 0.764 P_acc: 0.982 R1_acc: 0.961 R2_acc: 0.795 R3_acc: 0.990 R4_acc: 0.984 Loss: 2.0583B_acc: 0.842 T_acc: 0.912 V_acc: 0.654 G_acc: 0.805 P_acc: 0.977 R1_acc: 0.980 R2_acc: 0.828 R3_acc: 0.994 R4_acc: 0.982 Loss: 2.0273R1_acc: 0.977 R2_acc: 0.812 R3_acc: 0.996 R4_acc: 0.986 Loss: 1.9933B_acc: 0.826 T_acc: 0.922 V_acc: 0.688 G_acc: 0.791 P_acc: 0.988 R1_acc: 0.979 R2_acc: 0.832 R3_acc: 0.996 R4_acc: 0.979 Loss: 1.9972B_acc: 0.814 T_acc: 0.932 V_acc: 0.646 G_acc: 0.822 P_acc: 0.986 R1_acc: 0.977 R2_acc: 0.850 R3_acc: 0.990 R4_acc: 0.977 Loss: 2.0302B_acc: 0.850 T_acc: 0.928 V_acc: 0.697 G_acc: 0.775 P_acc: 0.980 R1_acc: 0.975 R2_acc: 0.828 R3_acc: 0.990 R4_acc: 0.975 Loss: 1.9469B_acc: 0.838 T_acc: 0.924 V_acc: 0.709 G_acc: 0.781 P_acc: 0.971 R1_acc: 0.975 R2_acc: 0.828 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.0471B_acc: 0.844 T_acc: 0.914 V_acc: 0.693 G_acc: 0.812 P_acc: 0.986 R1_acc: 0.963 R2_acc: 0.818 R3_acc: 0.994 R4_acc: 0.984 Loss: 2.0367B_acc: 0.830 T_acc: 0.941 V_acc: 0.676 G_acc: 0.781 P_acc: 0.996 R1_acc: 0.965 R2_acc: 0.814 R3_acc: 0.992 R4_acc: 0.986 Loss: 2.0141B_acc: 0.838 T_acc: 0.949 V_acc: 0.705 G_acc: 0.771 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.840 R3_acc: 0.992 R4_acc: 0.982 Loss: 1.9382B_acc: 0.826 T_acc: 0.939 V_acc: 0.756 G_acc: 0.803 P_acc: 0.988 R1_acc: 0.971 R2_acc: 0.811 R3_acc: 0.990 R4_acc: 0.984 Loss: 1.8827B_acc: 0.828 T_acc: 0.924 V_acc: 0.713 G_acc: 0.811 P_acc: 0.977 R1_acc: 0.961 R2_acc: 0.818 R3_acc: 0.986 R4_acc: 0.980 Loss: 2.0633B_acc: 0.848 T_acc: 0.943 V_acc: 0.725 G_acc: 0.789 P_acc: 0.984 R1_acc: 0.969 R2_acc: 0.844 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.8650B_acc: 0.809 T_acc: 0.914 V_acc: 0.715 G_acc: 0.818 P_acc: 0.984 R1_acc: 0.982 R2_acc: 0.838 R3_acc: 0.994 R4_acc: 0.986 Loss: 1.9460B_acc: 0.820 T_acc: 0.922 V_acc: 0.686 G_acc: 0.814 P_acc: 0.980 R1_acc: 0.957 R2_acc: 0.812 R3_acc: 0.996 R4_acc: 0.975 Loss: 2.0342B_acc: 0.834 T_acc: 0.928 V_acc: 0.707 G_acc: 0.779 P_acc: 0.979 R1_acc: 0.959 R2_acc: 0.816 R3_acc: 0.994 R4_acc: 0.982 Loss: 2.0761B_acc: 0.820 T_acc: 0.941 V_acc: 0.684 G_acc: 0.789 P_acc: 0.992 R1_acc: 0.971 R2_acc: 0.805 R3_acc: 0.996 R4_acc: 0.982 Loss: 1.9884B_acc: 0.852 T_acc: 0.924 V_acc: 0.738 G_acc: 0.746 P_acc: 0.990 R1_acc: 0.973 R2_acc: 0.814 R3_acc: 0.996 R4_acc: 0.990 Loss: 1.9166B_acc: 0.836 T_acc: 0.912 V_acc: 0.715 G_acc: 0.768 P_acc: 0.977 R1_acc: 0.977 R2_acc: 0.816 R3_acc: 0.998 R4_acc: 0.980 Loss: 1.9611B_acc: 0.812 T_acc: 0.930 V_acc: 0.711 G_acc: 0.777 P_acc: 0.977 R1_acc: 0.973 R2_acc: 0.863 R3_acc: 0.992 R4_acc: 0.980 Loss: 1.9647B_acc: 0.818 T_acc: 0.924 V_acc: 0.684 G_acc: 0.785 P_acc: 0.986 R1_acc: 0.967 R2_acc: 0.850 R3_acc: 0.996 R4_acc: 0.982 Loss: 2.0411B_acc: 0.830 T_acc: 0.928 V_acc: 0.701 G_acc: 0.754 P_acc: 0.988 R1_acc: 0.979 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.977 Loss: 1.9589G_acc: 0.766 P_acc: 0.984 R1_acc: 0.982 R2_acc: 0.842 R3_acc: 0.992 R4_acc: 0.982 Loss: 1.8387B_acc: 0.801 T_acc: 0.939 V_acc: 0.707 G_acc: 0.789 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.811 R3_acc: 0.996 R4_acc: 0.975 Loss: 2.0491 B_acc: 0.832 T_acc: 0.939 V_acc: 0.684 G_acc: 0.795 P_acc: 0.982 R1_acc: 0.977 R2_acc: 0.844 R3_acc: 0.990 R4_acc: 0.988 Loss: 1.9605B_acc: 0.836 T_acc: 0.936 V_acc: 0.686 G_acc: 0.809 P_acc: 0.980 R1_acc: 0.975 R2_acc: 0.818 R3_acc: 0.998 R4_acc: 0.979 Loss: 1.9827B_acc: 0.807 T_acc: 0.922 V_acc: 0.688 G_acc: 0.756 P_acc: 0.986 R1_acc: 0.965 R2_acc: 0.816 R3_acc: 0.992 R4_acc: 0.980 Loss: 2.1070V_acc: 0.727 G_acc: 0.785 P_acc: 0.986 R1_acc: 0.971 R2_acc: 0.826 R3_acc: 0.998 R4_acc: 0.982 Loss: 1.8805B_acc: 0.836 T_acc: 0.924 V_acc: 0.676 G_acc: 0.791 P_acc: 0.982 R1_acc: 0.959 R2_acc: 0.830 R3_acc: 0.988 R4_acc: 0.977 Loss: 1.9925B_acc: 0.846 T_acc: 0.945 V_acc: 0.689 G_acc: 0.801 P_acc: 0.982 R1_acc: 0.986 R2_acc: 0.854 R3_acc: 0.996 R4_acc: 0.988 Loss: 1.8334B_acc: 0.822 T_acc: 0.918 V_acc: 0.678 G_acc: 0.771 P_acc: 0.975 R1_acc: 0.979 R2_acc: 0.811 R3_acc: 0.994 R4_acc: 0.980 Loss: 2.1813V_acc: 0.709 G_acc: 0.768 P_acc: 0.977 R1_acc: 0.963 R2_acc: 0.842 R3_acc: 0.996 R4_acc: 0.982 Loss: 1.9559V_acc: 0.689 G_acc: 0.799 P_acc: 0.988 R1_acc: 0.961 R2_acc: 0.807 R3_acc: 0.994 R4_acc: 0.986 Loss: 1.9878B_acc: 0.811 T_acc: 0.920 V_acc: 0.650 G_acc: 0.770 P_acc: 0.979 R1_acc: 0.969 R2_acc: 0.809 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0863B_acc: 0.838 T_acc: 0.924 V_acc: 0.699 G_acc: 0.795 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.811 R3_acc: 0.998 R4_acc: 0.979 Loss: 1.9610V_acc: 0.691 G_acc: 0.820 P_acc: 0.980 R1_acc: 0.967 R2_acc: 0.830 R3_acc: 0.992 R4_acc: 0.988 Loss: 1.9248G_acc: 0.781 P_acc: 0.988 R1_acc: 0.963 R2_acc: 0.854 R3_acc: 0.994 R4_acc: 0.975 Loss: 2.0362B_acc: 0.852 T_acc: 0.936 V_acc: 0.662 G_acc: 0.807 P_acc: 0.971 R1_acc: 0.967 R2_acc: 0.816 R3_acc: 0.994 R4_acc: 0.971 Loss: 2.1001B_acc: 0.828 T_acc: 0.924 V_acc: 0.672 G_acc: 0.777 P_acc: 0.980 R1_acc: 0.965 R2_acc: 0.822 R3_acc: 0.996 R4_acc: 0.988 Loss: 2.0692B_acc: 0.857 T_acc: 0.934 V_acc: 0.730 G_acc: 0.799 P_acc: 0.969 R1_acc: 0.979 R2_acc: 0.840 R3_acc: 0.990 R4_acc: 0.973 Loss: 1.8820B_acc: 0.826 T_acc: 0.924 V_acc: 0.717 G_acc: 0.803 P_acc: 0.977 R1_acc: 0.984 R2_acc: 0.816 R3_acc: 0.998 R4_acc: 0.977 Loss: 1.9146B_acc: 0.846 T_acc: 0.938 V_acc: 0.682 G_acc: 0.797 P_acc: 0.986 R1_acc: 0.963 R2_acc: 0.834 R3_acc: 0.998 R4_acc: 0.986 Loss: 1.9230B_acc: 0.850 T_acc: 0.943 V_acc: 0.719 G_acc: 0.775 P_acc: 0.980 R1_acc: 0.975 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.8588B_acc: 0.820 T_acc: 0.926 V_acc: 0.678 G_acc: 0.791 P_acc: 0.969 R1_acc: 0.977 R2_acc: 0.795 R3_acc: 0.994 R4_acc: 0.990 Loss: 1.9780B_acc: 0.861 T_acc: 0.932 V_acc: 0.660 G_acc: 0.816 P_acc: 0.984 R1_acc: 0.967 R2_acc: 0.793 R3_acc: 0.998 R4_acc: 0.990 Loss: 1.9437B_acc: 0.836 T_acc: 0.926 V_acc: 0.695 G_acc: 0.771 P_acc: 0.977 R1_acc: 0.967 R2_acc: 0.820 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.0375B_acc: 0.795 T_acc: 0.924 V_acc: 0.641 G_acc: 0.779 P_acc: 0.977 R1_acc: 0.959 R2_acc: 0.830 R3_acc: 0.996 R4_acc: 0.979 Loss: 2.1375B_acc: 0.855 T_acc: 0.926 V_acc: 0.662 G_acc: 0.822 P_acc: 0.969 R1_acc: 0.977 R2_acc: 0.822 R3_acc: 0.990 R4_acc: 0.979 Loss: 2.0684B_acc: 0.855 T_acc: 0.939 V_acc: 0.693 G_acc: 0.814 P_acc: 0.990 R1_acc: 0.971 R2_acc: 0.838 R3_acc: 0.990 R4_acc: 0.992 Loss: 1.8221T_acc: 0.924 V_acc: 0.697 G_acc: 0.816 P_acc: 0.986 R1_acc: 0.975 R2_acc: 0.832 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.8833B_acc: 0.842 T_acc: 0.926 V_acc: 0.688 G_acc: 0.791 P_acc: 0.988 R1_acc: 0.965 R2_acc: 0.846 R3_acc: 0.990 R4_acc: 0.984 Loss: 1.9199B_acc: 0.803 T_acc: 0.926 V_acc: 0.729 G_acc: 0.781 P_acc: 0.982 R1_acc: 0.963 R2_acc: 0.848 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.0840B_acc: 0.850 T_acc: 0.920 V_acc: 0.705 G_acc: 0.826 P_acc: 0.984 R1_acc: 0.965 R2_acc: 0.828 R3_acc: 0.992 R4_acc: 0.980 Loss: 1.8966B_acc: 0.838 T_acc: 0.939 V_acc: 0.701 G_acc: 0.760 P_acc: 0.980 R1_acc: 0.973 R2_acc: 0.812 R3_acc: 0.990 R4_acc: 0.982 Loss: 1.9525B_acc: 0.824 T_acc: 0.932 V_acc: 0.695 G_acc: 0.777 P_acc: 0.980 R1_acc: 0.957 R2_acc: 0.816 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.9988B_acc: 0.822 T_acc: 0.920 V_acc: 0.664 G_acc: 0.797 P_acc: 0.977 R1_acc: 0.967 R2_acc: 0.840 R3_acc: 0.986 R4_acc: 0.975 Loss: 2.0544B_acc: 0.830 T_acc: 0.922 V_acc: 0.715 G_acc: 0.805 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.834 R3_acc: 0.990 R4_acc: 0.975 Loss: 1.9896B_acc: 0.826 T_acc: 0.928 V_acc: 0.719 G_acc: 0.762 P_acc: 0.980 R1_acc: 0.959 R2_acc: 0.811 R3_acc: 1.000 R4_acc: 0.982 Loss: 2.0083B_acc: 0.832 T_acc: 0.930 V_acc: 0.686 G_acc: 0.805 P_acc: 0.980 R1_acc: 0.973 R2_acc: 0.838 R3_acc: 0.984 R4_acc: 0.980 Loss: 1.9054B_acc: 0.822 T_acc: 0.920 V_acc: 0.689 G_acc: 0.801 P_acc: 0.984 R1_acc: 0.973 R2_acc: 0.832 R3_acc: 0.994 R4_acc: 0.973 Loss: 1.9893B_acc: 0.838 T_acc: 0.906 V_acc: 0.672 G_acc: 0.793 P_acc: 0.975 R1_acc: 0.961 R2_acc: 0.844 R3_acc: 0.992 R4_acc: 0.977 Loss: 2.0915B_acc: 0.859 T_acc: 0.926 V_acc: 0.688 G_acc: 0.775 P_acc: 0.992 R1_acc: 0.963 R2_acc: 0.832 R3_acc: 0.994 R4_acc: 0.979 Loss: 2.0033B_acc: 0.854 T_acc: 0.934 V_acc: 0.684 G_acc: 0.787 P_acc: 0.982 R1_acc: 0.969 R2_acc: 0.840 R3_acc: 0.998 R4_acc: 0.984 Loss: 1.8846B_acc: 0.811 T_acc: 0.916 V_acc: 0.699 G_acc: 0.758 P_acc: 0.965 R1_acc: 0.965 R2_acc: 0.826 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.1631B_acc: 0.842 T_acc: 0.922 V_acc: 0.686 G_acc: 0.822 P_acc: 0.971 R1_acc: 0.973 R2_acc: 0.838 R3_acc: 0.992 R4_acc: 0.982 Loss: 1.9979B_acc: 0.828 T_acc: 0.912 V_acc: 0.680 G_acc: 0.814 P_acc: 0.982 R1_acc: 0.967 R2_acc: 0.842 R3_acc: 0.994 R4_acc: 0.988 Loss: 1.9680B_acc: 0.824 T_acc: 0.926 V_acc: 0.674 G_acc: 0.795 P_acc: 0.977 R1_acc: 0.973 R2_acc: 0.824 R3_acc: 0.998 R4_acc: 0.988 Loss: 1.9034B_acc: 0.848 T_acc: 0.920 V_acc: 0.703 G_acc: 0.791 P_acc: 0.975 R1_acc: 0.975 R2_acc: 0.826 R3_acc: 0.990 R4_acc: 0.982 Loss: 2.0069B_acc: 0.844 T_acc: 0.920 V_acc: 0.656 G_acc: 0.793 P_acc: 0.986 R1_acc: 0.971 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.9719B_acc: 0.834 T_acc: 0.932 V_acc: 0.652 G_acc: 0.795 P_acc: 0.979 R1_acc: 0.961 R2_acc: 0.822 R3_acc: 0.988 R4_acc: 0.979 Loss: 2.0393B_acc: 0.814 T_acc: 0.910 V_acc: 0.719 G_acc: 0.809 P_acc: 0.973 R1_acc: 0.965 R2_acc: 0.838 R3_acc: 1.000 R4_acc: 0.979 Loss: 2.0881B_acc: 0.807 T_acc: 0.934 V_acc: 0.672 G_acc: 0.801 P_acc: 0.965 R1_acc: 0.971 R2_acc: 0.838 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.9850B_acc: 0.818 T_acc: 0.922 V_acc: 0.686 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.975 R2_acc: 0.807 R3_acc: 0.992 R4_acc: 0.967 Loss: 2.1010B_acc: 0.828 T_acc: 0.898 V_acc: 0.682 G_acc: 0.781 P_acc: 0.977 R1_acc: 0.973 R2_acc: 0.850 R3_acc: 0.996 R4_acc: 0.982 Loss: 2.0548 B_acc: 0.857 T_acc: 0.930 V_acc: 0.715 G_acc: 0.799 P_acc: 0.982 R1_acc: 0.982 R2_acc: 0.848 R3_acc: 0.988 R4_acc: 0.986 Loss: 1.8397 B_acc: 0.816 T_acc: 0.914 V_acc: 0.693 G_acc: 0.791 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.826 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.9667B_acc: 0.830 T_acc: 0.943 V_acc: 0.691 G_acc: 0.793 P_acc: 0.979 R1_acc: 0.963 R2_acc: 0.838 R3_acc: 0.990 R4_acc: 0.990 Loss: 1.9648B_acc: 0.834 T_acc: 0.938 V_acc: 0.721 G_acc: 0.809 P_acc: 0.977 R1_acc: 0.961 R2_acc: 0.805 R3_acc: 0.994 R4_acc: 0.977 Loss: 1.8812B_acc: 0.852 T_acc: 0.922 V_acc: 0.736 G_acc: 0.797 P_acc: 0.982 R1_acc: 0.979 R2_acc: 0.822 R3_acc: 1.000 R4_acc: 0.979 Loss: 1.8479T_acc: 0.945 V_acc: 0.740 G_acc: 0.777 P_acc: 0.988 R1_acc: 0.975 R2_acc: 0.824 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.8313B_acc: 0.838 T_acc: 0.893 V_acc: 0.689 G_acc: 0.791 P_acc: 0.979 R1_acc: 0.949 R2_acc: 0.842 R3_acc: 0.998 R4_acc: 0.984 Loss: 2.0925B_acc: 0.850 T_acc: 0.928 V_acc: 0.689 G_acc: 0.793 P_acc: 0.988 R1_acc: 0.969 R2_acc: 0.824 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9487B_acc: 0.842 T_acc: 0.908 V_acc: 0.674 G_acc: 0.770 P_acc: 0.979 R1_acc: 0.973 R2_acc: 0.816 R3_acc: 0.996 R4_acc: 0.971 Loss: 2.0124P_acc: 0.986 R1_acc: 0.979 R2_acc: 0.854 R3_acc: 0.998 R4_acc: 0.982 Loss: 1.9145B_acc: 0.852 T_acc: 0.930 V_acc: 0.721 G_acc: 0.791 P_acc: 0.977 R1_acc: 0.967 R2_acc: 0.834 R3_acc: 0.992 R4_acc: 0.979 Loss: 1.8619T_acc: 0.936 V_acc: 0.678 G_acc: 0.795 P_acc: 0.980 R1_acc: 0.977 R2_acc: 0.834 R3_acc: 0.996 R4_acc: 0.992 Loss: 1.8705B_acc: 0.832 T_acc: 0.920 V_acc: 0.707 G_acc: 0.809 P_acc: 0.975 R1_acc: 0.959 R2_acc: 0.826 R3_acc: 0.996 R4_acc: 0.971 Loss: 2.0536T_acc: 0.936 V_acc: 0.697 G_acc: 0.793 P_acc: 0.980 R1_acc: 0.959 R2_acc: 0.816 R3_acc: 0.996 R4_acc: 0.984 Loss: 2.0037B_acc: 0.842 T_acc: 0.945 V_acc: 0.713 G_acc: 0.793 P_acc: 0.988 R1_acc: 0.971 R2_acc: 0.828 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.8239R1_acc: 0.977 R2_acc: 0.850 R3_acc: 0.996 R4_acc: 0.990 Loss: 1.9712B_acc: 0.842 T_acc: 0.904 V_acc: 0.680 G_acc: 0.807 P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.838 R3_acc: 0.992 R4_acc: 0.980 Loss: 1.9716B_acc: 0.867 T_acc: 0.928 V_acc: 0.682 G_acc: 0.818 P_acc: 0.980 R1_acc: 0.988 R2_acc: 0.848 R3_acc: 0.996 R4_acc: 0.973 Loss: 1.8035B_acc: 0.812 T_acc: 0.922 V_acc: 0.719 G_acc: 0.785 P_acc: 0.992 R1_acc: 0.965 R2_acc: 0.852 R3_acc: 0.994 R4_acc: 0.992 Loss: 1.9336B_acc: 0.842 T_acc: 0.939 V_acc: 0.666 G_acc: 0.811 P_acc: 0.975 R1_acc: 0.973 R2_acc: 0.840 R3_acc: 0.992 R4_acc: 0.980 Loss: 1.9297B_acc: 0.846 T_acc: 0.934 V_acc: 0.734 G_acc: 0.807 P_acc: 0.977 R1_acc: 0.959 R2_acc: 0.848 R3_acc: 0.998 R4_acc: 0.973 Loss: 1.9012B_acc: 0.840 T_acc: 0.936 V_acc: 0.711 G_acc: 0.783 P_acc: 0.980 R1_acc: 0.977 R2_acc: 0.855 R3_acc: 1.000 R4_acc: 0.986 Loss: 1.8059B_acc: 0.844 T_acc: 0.945 V_acc: 0.682 G_acc: 0.791 P_acc: 0.986 R1_acc: 0.967 R2_acc: 0.799 R3_acc: 0.996 R4_acc: 0.977 Loss: 1.9646B_acc: 0.824 T_acc: 0.939 V_acc: 0.725 G_acc: 0.799 P_acc: 0.979 R1_acc: 0.967 R2_acc: 0.832 R3_acc: 0.986 R4_acc: 0.984 Loss: 1.9509 B_acc: 0.836 T_acc: 0.934 V_acc: 0.684 G_acc: 0.812 P_acc: 0.986 R1_acc: 0.982 R2_acc: 0.820 R3_acc: 0.998 R4_acc: 0.979 Loss: 1.9004 B_acc: 0.830 T_acc: 0.916 V_acc: 0.682 G_acc: 0.787 P_acc: 0.980 R1_acc: 0.963 R2_acc: 0.816 R3_acc: 0.988 R4_acc: 0.969 Loss: 2.0333B_acc: 0.848 T_acc: 0.928 V_acc: 0.699 G_acc: 0.801 P_acc: 0.975 R1_acc: 0.971 R2_acc: 0.822 R3_acc: 1.000 R4_acc: 0.980 Loss: 2.0035B_acc: 0.838 T_acc: 0.939 V_acc: 0.676 G_acc: 0.826 P_acc: 0.982 R1_acc: 0.979 R2_acc: 0.795 R3_acc: 0.994 R4_acc: 0.980 Loss: 1.9547B_acc: 0.848 T_acc: 0.934 V_acc: 0.719 G_acc: 0.770 P_acc: 0.977 R1_acc: 0.969 R2_acc: 0.793 R3_acc: 0.988 R4_acc: 0.980 Loss: 1.9231B_acc: 0.824 T_acc: 0.941 V_acc: 0.715 G_acc: 0.771 P_acc: 0.982 R1_acc: 0.975 R2_acc: 0.865 R3_acc: 0.996 R4_acc: 0.975 Loss: 1.8148B_acc: 0.834 T_acc: 0.938 V_acc: 0.682 G_acc: 0.801 P_acc: 0.980 R1_acc: 0.967 R2_acc: 0.834 R3_acc: 0.988 R4_acc: 0.990 Loss: 1.9090R2_acc: 0.795 R3_acc: 0.990 R4_acc: 0.971 Loss: 2.0112B_acc: 0.844 T_acc: 0.934 V_acc: 0.664 G_acc: 0.783 P_acc: 0.973 R1_acc: 0.965 R2_acc: 0.824 R3_acc: 0.996 R4_acc: 0.984 Loss: 2.0370B_acc: 0.867 T_acc: 0.939 V_acc: 0.707 G_acc: 0.779 P_acc: 0.986 R1_acc: 0.967 R2_acc: 0.848 R3_acc: 0.986 R4_acc: 0.980 Loss: 1.8945B_acc: 0.855 T_acc: 0.936 V_acc: 0.703 G_acc: 0.803 P_acc: 0.971 R1_acc: 0.977 R2_acc: 0.848 R3_acc: 0.998 R4_acc: 0.984 Loss: 1.8815B_acc: 0.830 T_acc: 0.936 V_acc: 0.672 G_acc: 0.789 P_acc: 0.992 R1_acc: 0.971 R2_acc: 0.836 R3_acc: 0.996 R4_acc: 0.988 Loss: 1.8927B_acc: 0.805 T_acc: 0.902 V_acc: 0.682 G_acc: 0.799 P_acc: 0.984 R1_acc: 0.959 R2_acc: 0.850 R3_acc: 0.992 R4_acc: 0.984 Loss: 2.0842B_acc: 0.838 T_acc: 0.918 V_acc: 0.695 G_acc: 0.797 P_acc: 0.979 R1_acc: 0.963 R2_acc: 0.826 R3_acc: 0.998 R4_acc: 0.990 Loss: 1.9406B_acc: 0.826 T_acc: 0.924 V_acc: 0.688 G_acc: 0.801 P_acc: 0.977 R1_acc: 0.971 R2_acc: 0.787 R3_acc: 0.990 R4_acc: 0.979 Loss: 2.0246B_acc: 0.830 T_acc: 0.926 V_acc: 0.666 G_acc: 0.768 P_acc: 0.990 R1_acc: 0.973 R2_acc: 0.834 R3_acc: 0.998 R4_acc: 0.979 Loss: 1.9059B_acc: 0.834 T_acc: 0.920 V_acc: 0.701 G_acc: 0.799 P_acc: 0.984 R1_acc: 0.979 R2_acc: 0.811 R3_acc: 0.990 R4_acc: 0.975 Loss: 1.9647B_acc: 0.816 T_acc: 0.912 V_acc: 0.672 G_acc: 0.766 P_acc: 0.986 R1_acc: 0.973 R2_acc: 0.838 R3_acc: 0.994 R4_acc: 0.979 Loss: 2.0530B_acc: 0.836 T_acc: 0.928 V_acc: 0.723 G_acc: 0.775 P_acc: 0.980 R1_acc: 0.967 R2_acc: 0.848 R3_acc: 0.988 R4_acc: 0.975 Loss: 1.9566B_acc: 0.852 T_acc: 0.920 V_acc: 0.693 G_acc: 0.766 P_acc: 0.977 R1_acc: 0.959 R2_acc: 0.824 R3_acc: 0.996 R4_acc: 0.967 Loss: 2.1090G_acc: 0.795 P_acc: 0.969 R1_acc: 0.949 R2_acc: 0.797 R3_acc: 0.994 R4_acc: 0.969 Loss: 2.1074R3_acc: 0.998 R4_acc: 0.992 Loss: 1.7674B_acc: 0.818 T_acc: 0.938 V_acc: 0.686 G_acc: 0.799 P_acc: 0.990 R1_acc: 0.971 R2_acc: 0.848 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.9377P_acc: 0.979 R1_acc: 0.965 R2_acc: 0.846 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9422B_acc: 0.820 T_acc: 0.930 V_acc: 0.711 G_acc: 0.799 P_acc: 0.988 R1_acc: 0.979 R2_acc: 0.814 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.8897B_acc: 0.844 T_acc: 0.926 V_acc: 0.678 G_acc: 0.801 P_acc: 0.988 R1_acc: 0.967 R2_acc: 0.801 R3_acc: 0.998 R4_acc: 0.980 Loss: 1.9082B_acc: 0.863 T_acc: 0.922 V_acc: 0.719 G_acc: 0.793 P_acc: 0.973 R1_acc: 0.967 R2_acc: 0.826 R3_acc: 0.996 R4_acc: 0.984 Loss: 1.9579B_acc: 0.828 T_acc: 0.926 V_acc: 0.709 G_acc: 0.803 P_acc: 0.980 R1_acc: 0.955 R2_acc: 0.840 R3_acc: 0.998 R4_acc: 0.977 Loss: 2.0007B_acc: 0.828 T_acc: 0.908 V_acc: 0.678 G_acc: 0.793 P_acc: 0.984 R1_acc: 0.965 R2_acc: 0.855 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.9847B_acc: 0.826 T_acc: 0.910 V_acc: 0.689 G_acc: 0.822 P_acc: 0.979 R1_acc: 0.973 R2_acc: 0.842 R3_acc: 0.994 R4_acc: 0.977 Loss: 1.9653B_acc: 0.816 T_acc: 0.941 V_acc: 0.656 G_acc: 0.779 P_acc: 0.977 R1_acc: 0.979 R2_acc: 0.838 R3_acc: 0.996 R4_acc: 0.979 Loss: 1.9479B_acc: 0.838 T_acc: 0.928 V_acc: 0.672 G_acc: 0.787 P_acc: 0.982 R1_acc: 0.975 R2_acc: 0.840 R3_acc: 0.994 R4_acc: 0.979 Loss: 1.9427B_acc: 0.869 T_acc: 0.939 V_acc: 0.697 G_acc: 0.756 P_acc: 0.982 R1_acc: 0.977 R2_acc: 0.807 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.9045B_acc: 0.838 T_acc: 0.930 V_acc: 0.711 G_acc: 0.803 P_acc: 0.984 R1_acc: 0.969 R2_acc: 0.844 R3_acc: 0.996 R4_acc: 0.988 Loss: 1.8125B_acc: 0.824 T_acc: 0.914 V_acc: 0.725 G_acc: 0.771 P_acc: 0.980 R1_acc: 0.961 R2_acc: 0.844 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.9754T_acc: 0.916 V_acc: 0.666 G_acc: 0.793 P_acc: 0.984 R1_acc: 0.975 R2_acc: 0.840 R3_acc: 0.992 R4_acc: 0.979 Loss: 1.9156B_acc: 0.857 T_acc: 0.930 V_acc: 0.699 G_acc: 0.783 P_acc: 0.984 R1_acc: 0.973 R2_acc: 0.822 R3_acc: 0.996 R4_acc: 0.977 Loss: 1.8840R3_acc: 0.990 R4_acc: 0.979 Loss: 1.9829B_acc: 0.836 T_acc: 0.914 V_acc: 0.707 G_acc: 0.805 P_acc: 0.979 R1_acc: 0.979 R2_acc: 0.830 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9018B_acc: 0.826 T_acc: 0.932 V_acc: 0.709 G_acc: 0.773 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.814 R3_acc: 0.994 R4_acc: 0.992 Loss: 1.9449B_acc: 0.857 T_acc: 0.924 V_acc: 0.705 G_acc: 0.814 P_acc: 0.984 R1_acc: 0.973 R2_acc: 0.822 R3_acc: 0.994 R4_acc: 0.973 Loss: 2.0001B_acc: 0.828 T_acc: 0.928 V_acc: 0.701 G_acc: 0.809 P_acc: 0.982 R1_acc: 0.965 R2_acc: 0.850 R3_acc: 0.992 R4_acc: 0.979 Loss: 1.8519B_acc: 0.846 T_acc: 0.930 V_acc: 0.691 G_acc: 0.795 P_acc: 0.977 R1_acc: 0.961 R2_acc: 0.854 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9178B_acc: 0.811 T_acc: 0.920 V_acc: 0.715 G_acc: 0.805 P_acc: 0.986 R1_acc: 0.973 R2_acc: 0.797 R3_acc: 0.994 R4_acc: 0.986 Loss: 1.9540B_acc: 0.820 T_acc: 0.938 V_acc: 0.684 G_acc: 0.824 P_acc: 0.975 R1_acc: 0.967 R2_acc: 0.824 R3_acc: 0.998 R4_acc: 0.973 Loss: 2.0040B_acc: 0.844 T_acc: 0.926 V_acc: 0.695 G_acc: 0.773 P_acc: 0.988 R1_acc: 0.967 R2_acc: 0.852 R3_acc: 0.998 R4_acc: 0.975 Loss: 1.9342B_acc: 0.797 T_acc: 0.900 V_acc: 0.691 G_acc: 0.797 P_acc: 0.959 R1_acc: 0.955 R2_acc: 0.809 R3_acc: 0.992 R4_acc: 0.973 Loss: 2.2223R3_acc: 0.984 R4_acc: 0.965 Loss: 2.0731B_acc: 0.824 T_acc: 0.941 V_acc: 0.666 G_acc: 0.807 P_acc: 0.982 R1_acc: 0.973 R2_acc: 0.834 R3_acc: 0.994 R4_acc: 0.979 Loss: 1.9440R4_acc: 0.979 Loss: 2.0187B_acc: 0.809 T_acc: 0.895 V_acc: 0.682 G_acc: 0.793 P_acc: 0.967 R1_acc: 0.965 R2_acc: 0.844 R3_acc: 0.992 R4_acc: 0.975 Loss: 2.1221R3_acc: 0.990 R4_acc: 0.979 Loss: 1.9626B_acc: 0.846 T_acc: 0.947 V_acc: 0.676 G_acc: 0.787 P_acc: 0.988 R1_acc: 0.980 R2_acc: 0.830 R3_acc: 0.996 R4_acc: 0.977 Loss: 1.8781B_acc: 0.832 T_acc: 0.938 V_acc: 0.703 G_acc: 0.783 P_acc: 0.986 R1_acc: 0.971 R2_acc: 0.832 R3_acc: 0.996 R4_acc: 0.977 Loss: 1.9377B_acc: 0.830 T_acc: 0.910 V_acc: 0.723 G_acc: 0.791 P_acc: 0.979 R1_acc: 0.982 R2_acc: 0.844 R3_acc: 0.992 R4_acc: 0.994 Loss: 1.8767B_acc: 0.820 T_acc: 0.914 V_acc: 0.666 G_acc: 0.836 P_acc: 0.980 R1_acc: 0.979 R2_acc: 0.812 R3_acc: 0.994 R4_acc: 0.973 Loss: 2.0218B_acc: 0.836 T_acc: 0.939 V_acc: 0.725 G_acc: 0.795 P_acc: 0.982 R1_acc: 0.961 R2_acc: 0.811 R3_acc: 1.000 R4_acc: 0.988 Loss: 1.9549B_acc: 0.832 T_acc: 0.932 V_acc: 0.688 G_acc: 0.797 P_acc: 0.977 R1_acc: 0.971 R2_acc: 0.797 R3_acc: 0.988 R4_acc: 0.986 Loss: 1.9497B_acc: 0.826 T_acc: 0.949 V_acc: 0.697 G_acc: 0.820 P_acc: 0.986 R1_acc: 0.965 R2_acc: 0.801 R3_acc: 0.996 R4_acc: 0.990 Loss: 1.8517B_acc: 0.828 T_acc: 0.928 V_acc: 0.703 G_acc: 0.816 P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.822 R3_acc: 0.990 R4_acc: 0.977 Loss: 1.9472B_acc: 0.826 T_acc: 0.920 V_acc: 0.682 G_acc: 0.805 P_acc: 0.990 R1_acc: 0.982 R2_acc: 0.830 R3_acc: 0.990 R4_acc: 0.990 Loss: 1.9340B_acc: 0.840 T_acc: 0.941 V_acc: 0.684 G_acc: 0.812 P_acc: 0.982 R1_acc: 0.973 R2_acc: 0.850 R3_acc: 0.996 R4_acc: 0.988 Loss: 1.7908B_acc: 0.840 T_acc: 0.943 V_acc: 0.703 G_acc: 0.793 P_acc: 0.990 R1_acc: 0.982 R2_acc: 0.801 R3_acc: 0.992 R4_acc: 0.977 Loss: 1.8170 B_acc: 0.822 T_acc: 0.916 V_acc: 0.707 G_acc: 0.811 P_acc: 0.961 R1_acc: 0.957 R2_acc: 0.828 R3_acc: 0.996 R4_acc: 0.963 Loss: 2.1319B_acc: 0.846 T_acc: 0.932 V_acc: 0.717 G_acc: 0.758 P_acc: 0.973 R1_acc: 0.969 R2_acc: 0.824 R3_acc: 0.992 R4_acc: 0.979 Loss: 2.0000R4_acc: 0.984 Loss: 1.9031B_acc: 0.822 T_acc: 0.922 V_acc: 0.656 G_acc: 0.746 P_acc: 0.975 R1_acc: 0.975 R2_acc: 0.822 R3_acc: 0.994 R4_acc: 0.973 Loss: 2.0497B_acc: 0.838 T_acc: 0.934 V_acc: 0.699 G_acc: 0.773 P_acc: 0.982 R1_acc: 0.982 R2_acc: 0.855 R3_acc: 0.992 R4_acc: 0.977 Loss: 1.8572B_acc: 0.840 T_acc: 0.924 V_acc: 0.701 G_acc: 0.801 P_acc: 0.982 R1_acc: 0.990 R2_acc: 0.828 R3_acc: 1.000 R4_acc: 0.990 Loss: 1.7657B_acc: 0.850 T_acc: 0.914 V_acc: 0.684 G_acc: 0.803 P_acc: 0.988 R1_acc: 0.969 R2_acc: 0.836 R3_acc: 0.988 R4_acc: 0.979 Loss: 2.0503B_acc: 0.820 T_acc: 0.945 V_acc: 0.723 G_acc: 0.785 P_acc: 0.979 R1_acc: 0.979 R2_acc: 0.850 R3_acc: 0.998 R4_acc: 0.986 Loss: 1.7759B_acc: 0.803 T_acc: 0.939 V_acc: 0.727 G_acc: 0.775 P_acc: 0.984 R1_acc: 0.965 R2_acc: 0.816 R3_acc: 0.996 R4_acc: 0.984 Loss: 1.9778R4_acc: 0.986 Loss: 1.8898B_acc: 0.844 T_acc: 0.926 V_acc: 0.672 G_acc: 0.812 P_acc: 0.977 R1_acc: 0.967 R2_acc: 0.848 R3_acc: 0.986 R4_acc: 0.988 Loss: 1.9727B_acc: 0.826 T_acc: 0.926 V_acc: 0.729 G_acc: 0.785 P_acc: 0.984 R1_acc: 0.965 R2_acc: 0.803 R3_acc: 1.000 R4_acc: 0.992 Loss: 1.9922B_acc: 0.807 T_acc: 0.936 V_acc: 0.695 G_acc: 0.793 P_acc: 0.975 R1_acc: 0.971 R2_acc: 0.834 R3_acc: 0.998 R4_acc: 0.982 Loss: 1.9133T_acc: 0.926 V_acc: 0.691 G_acc: 0.789 P_acc: 0.986 R1_acc: 0.979 R2_acc: 0.803 R3_acc: 0.996 R4_acc: 0.984 Loss: 1.9508 B_acc: 0.834 T_acc: 0.926 V_acc: 0.697 G_acc: 0.797 P_acc: 0.977 R1_acc: 0.967 R2_acc: 0.830 R3_acc: 0.994 R4_acc: 0.980 Loss: 1.9744B_acc: 0.822 T_acc: 0.920 V_acc: 0.680 G_acc: 0.822 P_acc: 0.980 R1_acc: 0.963 R2_acc: 0.834 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.9120B_acc: 0.834 T_acc: 0.930 V_acc: 0.691 G_acc: 0.812 P_acc: 0.982 R1_acc: 0.955 R2_acc: 0.814 R3_acc: 0.992 R4_acc: 0.984 Loss: 1.9592B_acc: 0.838 T_acc: 0.930 V_acc: 0.742 G_acc: 0.816 P_acc: 0.986 R1_acc: 0.965 R2_acc: 0.846 R3_acc: 0.998 R4_acc: 0.982 Loss: 1.8058B_acc: 0.836 T_acc: 0.928 V_acc: 0.680 G_acc: 0.791 P_acc: 0.986 R1_acc: 0.955 R2_acc: 0.799 R3_acc: 0.990 R4_acc: 0.990 Loss: 2.0025B_acc: 0.836 T_acc: 0.924 V_acc: 0.674 G_acc: 0.797 P_acc: 0.973 R1_acc: 0.973 R2_acc: 0.863 R3_acc: 0.994 R4_acc: 0.980 Loss: 1.9239B_acc: 0.832 T_acc: 0.920 V_acc: 0.693 G_acc: 0.795 P_acc: 0.982 R1_acc: 0.975 R2_acc: 0.830 R3_acc: 0.990 R4_acc: 0.975 Loss: 2.0865B_acc: 0.814 T_acc: 0.928 V_acc: 0.678 G_acc: 0.795 P_acc: 0.984 R1_acc: 0.957 R2_acc: 0.814 R3_acc: 0.998 R4_acc: 0.980 Loss: 1.9850 B_acc: 0.846 T_acc: 0.932 V_acc: 0.715 G_acc: 0.781 P_acc: 0.979 R1_acc: 0.959 R2_acc: 0.820 R3_acc: 0.996 R4_acc: 0.982 Loss: 1.9254B_acc: 0.838 T_acc: 0.918 V_acc: 0.672 G_acc: 0.803 P_acc: 0.982 R1_acc: 0.971 R2_acc: 0.852 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.9733V_acc: 0.695 G_acc: 0.777 P_acc: 0.984 R1_acc: 0.973 R2_acc: 0.848 R3_acc: 0.996 R4_acc: 0.980 Loss: 1.9200B_acc: 0.826 T_acc: 0.932 V_acc: 0.703 G_acc: 0.822 P_acc: 0.986 R1_acc: 0.977 R2_acc: 0.803 R3_acc: 0.994 R4_acc: 0.984 Loss: 1.8734B_acc: 0.840 T_acc: 0.910 V_acc: 0.693 G_acc: 0.799 P_acc: 0.980 R1_acc: 0.969 R2_acc: 0.848 R3_acc: 0.988 R4_acc: 0.980 Loss: 2.0250B_acc: 0.842 T_acc: 0.918 V_acc: 0.711 G_acc: 0.779 P_acc: 0.979 R1_acc: 0.975 R2_acc: 0.836 R3_acc: 0.994 R4_acc: 0.982 Loss: 1.9268B_acc: 0.844 T_acc: 0.939 V_acc: 0.676 G_acc: 0.797 P_acc: 0.986 R1_acc: 0.979 R2_acc: 0.807 R3_acc: 0.998 R4_acc: 0.980 Loss: 1.9017B_acc: 0.840 T_acc: 0.930 V_acc: 0.703 G_acc: 0.797 P_acc: 0.977 R1_acc: 0.973 R2_acc: 0.840 R3_acc: 0.998 R4_acc: 0.969 Loss: 1.8593B_acc: 0.855 T_acc: 0.939 V_acc: 0.713 G_acc: 0.801 P_acc: 0.984 R1_acc: 0.979 R2_acc: 0.814 R3_acc: 0.994 R4_acc: 0.988 Loss: 1.7685R3_acc: 0.994 R4_acc: 0.979 Loss: 2.0105R3_acc: 0.992 R4_acc: 0.988 Loss: 1.9114R4_acc: 0.979 Loss: 1.9986B_acc: 0.818 T_acc: 0.941 V_acc: 0.713 G_acc: 0.814 P_acc: 0.984 R1_acc: 0.977 R2_acc: 0.814 R3_acc: 0.990 R4_acc: 0.980 Loss: 1.8536B_acc: 0.844 T_acc: 0.934 V_acc: 0.691 G_acc: 0.807 P_acc: 0.973 R1_acc: 0.957 R2_acc: 0.832 R3_acc: 0.998 R4_acc: 0.988 Loss: 1.9084P_acc: 0.980 R1_acc: 0.971 R2_acc: 0.842 R3_acc: 0.990 R4_acc: 0.986 Loss: 1.8365V_acc: 0.699 G_acc: 0.809 P_acc: 0.969 R1_acc: 0.973 R2_acc: 0.838 R3_acc: 0.996 R4_acc: 0.986 Loss: 1.9027 B_acc: 0.834 T_acc: 0.922 V_acc: 0.689 G_acc: 0.779 P_acc: 0.980 R1_acc: 0.977 R2_acc: 0.846 R3_acc: 0.998 R4_acc: 0.986 Loss: 1.9334 B_acc: 0.818 T_acc: 0.918 V_acc: 0.693 G_acc: 0.812 P_acc: 0.979 R1_acc: 0.980 R2_acc: 0.861 R3_acc: 0.992 R4_acc: 0.994 Loss: 1.8328\n"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_MODE'] = 'dryrun'  # 'dryrun'\n",
    "\n",
    "config = {\n",
    "    'optimizer': 'adam',\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': 1,\n",
    "    'runsize': 8,\n",
    "    'test_size': test_size,\n",
    "}\n",
    "# group = f'lr_units_grid_search-{arity}-{wandb.util.generate_id()}'\n",
    "\n",
    "def experiment(lr):\n",
    "    units = 400\n",
    "\n",
    "    config.update({\n",
    "        'units': units,\n",
    "        'lr': lr,\n",
    "    })\n",
    "\n",
    "    run = wandb.init(project=\"rootem\",\n",
    "                     # group=group,\n",
    "                     name=f'{gen}-{arity}-{lr:.0e}',# f'{arity}-batch_{BATCH_SIZE}', # f'all-{arity}-lr_{lr:.0e}-units_{units}',\n",
    "                     tags=[gen, arity, 'synthetic', 'shuffle', 'no_prefix'],\n",
    "                     config=config)\n",
    "\n",
    "    run.use_artifact(artifact)\n",
    "\n",
    "    wandb.config.update(config, allow_val_change=True)\n",
    "\n",
    "    def standard_config():\n",
    "        model = to_device(Model(units=config['units']))\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        return {\n",
    "            'model': model,\n",
    "            'criterion': nn.CrossEntropyLoss(),\n",
    "            'optimizer': optimizer,\n",
    "            'phases': ['train', 'test'],\n",
    "            'teacher': None\n",
    "        }\n",
    "\n",
    "    print(config)\n",
    "    fit(train=train,\n",
    "        test=test,\n",
    "        epochs=config['epochs'],\n",
    "        runsize=config['runsize'],\n",
    "        **standard_config()\n",
    "    )\n",
    "    wandb.save(f\"simple_{arity}.h5\")\n",
    "\n",
    "for lr in [8e-4]:  # , 10e-4, 20e-4, 30e-4, 40e-4, 50e-4, 60e-4]:\n",
    "    experiment(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, 'סבסו'))\n",
    "print(predict(model, 'מקדו'))\n",
    "print(predict(model, 'נמזר'))\n",
    "print(predict(model, 'כרדו'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, 'הבריל'))\n",
    "print(predict(model, 'חגוו'))\n",
    "print(predict(model, 'עגו'))\n",
    "print(predict(model, 'צירלל'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, \"השטקרפתי\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict(model, \"ישסו\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import encoding\n",
    "import naive_model\n",
    "encoding = importlib.reload(encoding)\n",
    "naive_model = importlib.reload(naive_model)\n",
    "NaiveModel = naive_model.NaiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
