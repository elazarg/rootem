{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "\n",
    "NUM_EMBEDDING = 2000\n",
    "def word2numpy(txt):\n",
    "    return np.array([ord(c) for c in txt])\n",
    "\n",
    "def wordlist2numpy(lines):\n",
    "    return utils.pad_sequences([word2numpy(line) for line in lines],\n",
    "                               maxlen=12, dtype=int, value=0)\n",
    "\n",
    "RADICALS = ['.'] + list('אבגדהוזחטיכלמנסעפצקרשת') + [\"ג'\", \"ז'\", \"צ'\", 'שׂ']\n",
    "\n",
    "BINYAN = 'פעל נפעל פיעל פועל הפעיל הופעל התפעל'.split()\n",
    "TENSE = 'עבר הווה עתיד ציווי'.split()\n",
    "VOICE = 'ראשון שני שלישי'.split()\n",
    "GENDER = 'זכר נקבה'.split()\n",
    "PLURAL = 'יחיד רבים'.split()\n",
    "\n",
    "NAMES = ['B', 'T', 'V', 'G', 'P', 'R1', 'R2', 'R3', 'R4']\n",
    "FEATURES = {\n",
    "    'B': BINYAN,\n",
    "    'T': TENSE,\n",
    "    'V': VOICE,\n",
    "    'G': GENDER,\n",
    "    'P': PLURAL,\n",
    "    'R1': RADICALS,\n",
    "    'R2': RADICALS,\n",
    "    'R3': RADICALS,\n",
    "    'R4': RADICALS,\n",
    "}\n",
    "\n",
    "def to_category(name, b):\n",
    "    return FEATURES[name].index(b)\n",
    "\n",
    "def from_category(name, index):\n",
    "    return FEATURES[name][index]\n",
    "\n",
    "def list_to_category(name, bs):\n",
    "    return np.array([to_category(name, b) for b in bs])\n",
    "\n",
    "def list_from_category(name, indexes):\n",
    "    return [from_category(name, index) for index in indexes]\n",
    "\n",
    "def list_of_lists_to_category(items):\n",
    "    return { name: list_to_category(name, item)\n",
    "             for name, item in zip(NAMES, items) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "def to_device(d):\n",
    "    if hasattr(d, 'cuda'):\n",
    "        return d.cuda()\n",
    "    return {k: v.cuda() for k, v in d.items()}\n",
    "\n",
    "def create_model(UNITS):\n",
    "    class Model(nn.Module):\n",
    "        def __init__(self, UNITS):\n",
    "            super().__init__()\n",
    "            self.units = UNITS\n",
    "\n",
    "            self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=UNITS)\n",
    "            self.lstm1 = nn.LSTM(input_size=UNITS, hidden_size=UNITS, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "            # {k: nn.Linear(in_features=UNITS, out_features=len(v)) for k, v in features.items()}\n",
    "            self.binyan = nn.Linear(in_features=UNITS, out_features=len(BINYAN))\n",
    "            self.tense = nn.Linear(in_features=UNITS, out_features=len(TENSE))\n",
    "            self.voice = nn.Linear(in_features=UNITS, out_features=len(VOICE))\n",
    "            self.gender = nn.Linear(in_features=UNITS, out_features=len(GENDER))\n",
    "            self.plural = nn.Linear(in_features=UNITS, out_features=len(PLURAL))\n",
    "            \n",
    "            self.r1 = nn.Linear(in_features=UNITS, out_features=len(RADICALS))\n",
    "            self.r2 = nn.Linear(in_features=UNITS, out_features=len(RADICALS))\n",
    "            self.r3 = nn.Linear(in_features=UNITS, out_features=len(RADICALS))\n",
    "            self.r4 = nn.Linear(in_features=UNITS, out_features=len(RADICALS))\n",
    "\n",
    "            self.features = {\n",
    "                'B': self.binyan,\n",
    "                'T': self.tense,\n",
    "                'V': self.voice,\n",
    "                'G': self.gender,\n",
    "                'P': self.plural,\n",
    "                \n",
    "                'R1': self.r1,\n",
    "                'R2': self.r2,\n",
    "                'R3': self.r3,\n",
    "                'R4': self.r4,\n",
    "            }\n",
    "\n",
    "        def forward(self, x):\n",
    "            embeds = self.embed(x)\n",
    "\n",
    "            lstm_out, (h_n, c_n) = self.lstm1(embeds)\n",
    "            left, right = torch.chunk(h_n, 2, dim=0)\n",
    "            merge = torch.squeeze(left + right)\n",
    "\n",
    "            outputs = { k: f(merge) for k, f in self.features.items() }\n",
    "            return outputs\n",
    "\n",
    "    model = Model(UNITS=UNITS)\n",
    "\n",
    "    return to_device(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "wordlist = ['ידעתי', 'התאפס', 'יאבד']\n",
    "binyanlist = ['פעל', 'התפעל', 'פיעל']\n",
    "\n",
    "def sanity():\n",
    "    with torch.no_grad():\n",
    "        numpy_inp = wordlist2numpy(wordlist)\n",
    "        inputs = to_device(torch.from_numpy(numpy_inp).to(torch.int64))\n",
    "        tag_scores = model(inputs)\n",
    "        expected = list_to_category(BINYAN, binyanlist)\n",
    "        print(f'{tag_scores[\"B\"].shape=}')\n",
    "        print(f\"{np.argmax(tag_scores['B'].cpu(), axis=1).shape=}\")\n",
    "        print(f\"{expected.shape=}\")\n",
    "\n",
    "sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concrete\n",
    "\n",
    "def load_dataset(filename):\n",
    "    *features, verbs = concrete.load_dataset(filename)\n",
    "    return wordlist2numpy(verbs), list_of_lists_to_category(features)\n",
    "\n",
    "train = load_dataset('random_train.tsv')\n",
    "valid = load_dataset('random_validate.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "def batch(a):\n",
    "    ub = a.shape[0] // BATCH_SIZE * BATCH_SIZE\n",
    "    return torch.from_numpy(a[:ub]).to(torch.int64).split(BATCH_SIZE)\n",
    "\n",
    "def batch_all_ys(ys):\n",
    "    res = []\n",
    "    m = {k: batch(ys[k]) for k in NAMES}\n",
    "    nbatches = len(m['B'])\n",
    "    for i in range(nbatches):\n",
    "        res.append({k: m[k][i] for k in NAMES})\n",
    "    return res\n",
    "\n",
    "def accuracy(output, ybatch):\n",
    "    n = (ybatch != 0).sum()\n",
    "    c = np.argmax(output, axis=1)\n",
    "    return ((c == ybatch) & (c != 0)).sum() / n\n",
    "\n",
    "def fit(model, x_train, y_train, x_valid, y_valid, *, epochs, criterion, optimizer):\n",
    "    data = {\n",
    "        'train': (batch(x_train), batch_all_ys(y_train)),\n",
    "        'valid': (batch(x_valid), batch_all_ys(y_valid))\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            total = len(data[phase][0])\n",
    "\n",
    "            accs = {k: [] for k in NAMES}\n",
    "            losses = []\n",
    "\n",
    "            for i, (inputs, labels) in enumerate(zip(*data[phase])):\n",
    "                inputs = to_device(inputs)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(inputs)\n",
    "                    \n",
    "                outputs = to_device(outputs)\n",
    "                labels = to_device(labels)\n",
    "\n",
    "                loss = sum(criterion(outputs[k], labels[k]) for k in outputs)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                outputs = {k: v.cpu().data.numpy() for k, v in outputs.items()}\n",
    "                labels = {k: v.cpu().data.numpy() for k, v in labels.items()}\n",
    "\n",
    "                for k in outputs:\n",
    "                    accs[k].append(accuracy(outputs[k], labels[k]))\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                RUNSIZE = 100\n",
    "                if phase == 'valid' and i >= total-1 or i % RUNSIZE == RUNSIZE - 1:\n",
    "                    print(\"{:2} {:4}/{:4}\".format(epoch, i, total), end=' ')\n",
    "                    for k in accs:\n",
    "                        print(\"{}_acc: {:.4f}\".format(k, np.mean(accs[k])), end=' ')\n",
    "                    print(\"Loss: {:.4f}\".format(np.mean(losses)), end='\\r')\n",
    "                    accs = {k: [] for k in NAMES}\n",
    "                    losses = []\n",
    "            print()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, *verbs):\n",
    "    model.eval()\n",
    "    verbs = wordlist2numpy(verbs)\n",
    "    verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "    outputs = model(verbs)\n",
    "    res = {k: from_category(k, torch.argmax(v))\n",
    "           for k, v in outputs.items()}\n",
    "    res['R'] = ''.join(res[k] for k in ['R1', 'R2', 'R3', 'R4']).replace('.', '')\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embed): Embedding(2000, 100)\n",
      "  (lstm1): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (binyan): Linear(in_features=100, out_features=7, bias=True)\n",
      "  (tense): Linear(in_features=100, out_features=4, bias=True)\n",
      "  (voice): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (gender): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (plural): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (r1): Linear(in_features=100, out_features=27, bias=True)\n",
      "  (r2): Linear(in_features=100, out_features=27, bias=True)\n",
      "  (r3): Linear(in_features=100, out_features=27, bias=True)\n",
      "  (r4): Linear(in_features=100, out_features=27, bias=True)\n",
      ")\n",
      " 0 1499/1562 B_acc: 0.8249 T_acc: 0.9036 V_acc: 0.6375 G_acc: 0.7487 P_acc: 0.9803 R1_acc: 0.9198 R2_acc: 0.7978 R3_acc: 0.7497 R4_acc: 0.9384 Loss: 3.23142\n",
      " 0  155/ 156 B_acc: 0.8248 T_acc: 0.9299 V_acc: 0.6064 G_acc: 0.7594 P_acc: 0.9642 R1_acc: 0.9235 R2_acc: 0.7863 R3_acc: 0.7616 R4_acc: 0.9456 Loss: 3.1337\n",
      " 1 1499/1562 B_acc: 0.8563 T_acc: 0.9176 V_acc: 0.6586 G_acc: 0.7585 P_acc: 0.9797 R1_acc: 0.9495 R2_acc: 0.8619 R3_acc: 0.9048 R4_acc: 0.9628 Loss: 2.4138\n",
      " 1  155/ 156 B_acc: 0.8501 T_acc: 0.9421 V_acc: 0.6302 G_acc: 0.8113 P_acc: 0.9760 R1_acc: 0.9464 R2_acc: 0.8440 R3_acc: 0.8662 R4_acc: 0.9640 Loss: 2.4300\n",
      " 2 1499/1562 B_acc: 0.8673 T_acc: 0.9243 V_acc: 0.6678 G_acc: 0.7670 P_acc: 0.9810 R1_acc: 0.9628 R2_acc: 0.8800 R3_acc: 0.9393 R4_acc: 0.9703 Loss: 2.1368\n",
      " 2  155/ 156 B_acc: 0.8552 T_acc: 0.9428 V_acc: 0.6488 G_acc: 0.8469 P_acc: 0.9761 R1_acc: 0.9542 R2_acc: 0.8627 R3_acc: 0.9120 R4_acc: 0.9735 Loss: 2.2159\n"
     ]
    }
   ],
   "source": [
    "model = create_model(UNITS=100)\n",
    "\n",
    "print(model)\n",
    "fit(model,\n",
    "    *train,\n",
    "    *valid,\n",
    "    epochs=3,\n",
    "    criterion=nn.CrossEntropyLoss(),  # add ignore_index for root\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'פעל', 'T': 'ציווי', 'V': 'שני', 'G': 'זכר', 'P': 'רבים', 'R1': 'ס', 'R2': 'ב', 'R3': '.', 'R4': 'ס', 'R': 'סבס'}\n",
      "{'B': 'פיעל', 'T': 'ציווי', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'מ', 'R2': 'ד', 'R3': '.', 'R4': 'ד', 'R': 'מדד'}\n",
      "{'B': 'פיעל', 'T': 'עתיד', 'V': 'ראשון', 'G': 'זכר', 'P': 'רבים', 'R1': 'מ', 'R2': 'ז', 'R3': '.', 'R4': 'ר', 'R': 'מזר'}\n",
      "{'B': 'פעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'כ', 'R2': 'ד', 'R3': '.', 'R4': 'ד', 'R': 'כדד'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, 'סבסו'))\n",
    "print(predict(model, 'מקדו'))\n",
    "print(predict(model, 'נמזר'))\n",
    "print(predict(model, 'כרדו'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'הפעיל', 'T': 'עבר', 'V': 'שלישי', 'G': 'נקבה', 'P': 'יחיד', 'R1': 'ב', 'R2': 'ר', 'R3': '.', 'R4': 'ל', 'R': 'ברל'}\n",
      "{'B': 'פעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'ח', 'R2': 'ג', 'R3': '.', 'R4': 'י', 'R': 'חגי'}\n",
      "{'B': 'פעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'נקבה', 'P': 'רבים', 'R1': 'ע', 'R2': 'ג', 'R3': '.', 'R4': 'י', 'R': 'עגי'}\n",
      "{'B': 'פיעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'יחיד', 'R1': 'צ', 'R2': 'ר', 'R3': 'ל', 'R4': 'ל', 'R': 'צרלל'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, 'הבריל'))\n",
    "print(predict(model, 'חגוו'))\n",
    "print(predict(model, 'עגו'))\n",
    "print(predict(model, 'צירלל'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'התפעל', 'T': 'ציווי', 'V': 'שני', 'G': 'זכר', 'P': 'יחיד', 'R1': 'נ', 'R2': 'ג', 'R3': '.', 'R4': 'נ', 'R': 'נגנ'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, \"התנגן\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'הפעיל', 'T': 'הווה', 'V': 'שלישי', 'G': 'נקבה', 'P': 'יחיד', 'R1': 'ש', 'R2': 'ק', 'R3': '.', 'R4': 'י', 'R': 'שקי'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, \"משקה\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
