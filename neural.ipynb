{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "from naive_model import NaiveModel\n",
    "import encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EMBEDDING = 2000\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "def to_device(d):\n",
    "    if hasattr(d, 'cuda'):\n",
    "        return d.cuda()\n",
    "    return {k: v.cuda() for k, v in d.items()}\n",
    "\n",
    "class Model(nn.Module):\n",
    "    arch = 'lstm'\n",
    "    def __init__(self, units, combinations=encoding.NAMES):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=units)\n",
    "        \n",
    "        self.pre_lstm = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=False, bidirectional=True)\n",
    "        \n",
    "#         self.attention = nn.MultiheadAttention(units, num_heads=1)\n",
    "        \n",
    "#         self.post_lstm = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=False, bidirectional=True)\n",
    "\n",
    "        self.tasks = {}\n",
    "        for combination in combinations:\n",
    "            out = nn.Linear(in_features=units, out_features=encoding.class_size(combination))\n",
    "            self.tasks[combination] = out\n",
    "            setattr(self, encoding.class_name(combination), out)\n",
    "\n",
    "    def isroot(self, combination):\n",
    "        return any(r in combination for r in ['R1', 'R2', 'R3', 'R4'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeds = self.embed(x).permute([1, 0, 2])\n",
    "        \n",
    "        lstm_out, (h_n0, c_n) = self.pre_lstm(embeds)\n",
    "        \n",
    "#         left, right = torch.chunk(lstm_out, 2, dim=-1)\n",
    "#         lstm_out = torch.squeeze(left + right)\n",
    "\n",
    "#         attention, weights = self.attention(embeds, lstm_out, lstm_out)\n",
    "#         lstm_out, (h_n1, c_n) = self.post_lstm(attention + embeds)\n",
    "        \n",
    "#         h_n = h_n0 + h_n1\n",
    "        h_n = h_n0\n",
    "        return {combination: f(h_n[0] + h_n[1])\n",
    "                for combination, f in self.tasks.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sanity():\n",
    "    model = to_device(Model(100, combinations=[('B', 'T')]))\n",
    "    print(model)\n",
    "    with torch.no_grad():\n",
    "        verbs = encoding.wordlist2numpy([\"אתאקלם\", \"יכפיל\", \"בואס\"])\n",
    "        labels = {'B': torch.Tensor([3, 5]), 'T': torch.Tensor([2, 4])}\n",
    "        verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "        tag_scores = model(verbs)\n",
    "        print(f'{tag_scores[(\"B\", \"T\")].shape=}')\n",
    "        for combination in tag_scores:\n",
    "            print(combination)\n",
    "            v = tag_scores[combination]\n",
    "            # print(f'{v=}')\n",
    "            print(f'{labels=}')\n",
    "            print()\n",
    "# sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# TEMP_PATH = 'model.pt'\n",
    "\n",
    "#                 best_lr = 8e-4\n",
    "#                 best_loss = 10\n",
    "                \n",
    "#                 torch.save({\n",
    "#                     'state_dict': model.state_dict(),\n",
    "#                     'optimizer': optimizer.state_dict(),\n",
    "#                 }, TEMP_PATH)\n",
    "                \n",
    "#                 for i in range(1):\n",
    "#                     checkpoint = torch.load(TEMP_PATH)\n",
    "#                     model.load_state_dict(checkpoint['state_dict'])\n",
    "#                     optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "def fit(model, train, test, *, epochs,  runsize, criterion, optimizer, scheduler, batch_size, **_):\n",
    "    train_x, train_y = train\n",
    "    test_x, test_y = test\n",
    "    \n",
    "    assert_reasonable_initial = utils.Once(utils.assert_reasonable_initial)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_stats = utils.Stats(model.tasks.keys())\n",
    "        \n",
    "        nbatches = len(train_x)\n",
    "        for batch, (inputs, labels) in enumerate(zip(train_x, train_y), 1):\n",
    "            model.train()\n",
    "\n",
    "            inputs = to_device(inputs)\n",
    "            labels = to_device(labels)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            losses = {combination: criterion(output.double(), labels[combination])\n",
    "                      for combination, output in outputs.items()}\n",
    "\n",
    "            loss = sum(losses.values())\n",
    "            \n",
    "            assert_reasonable_initial(losses, nn.CrossEntropyLoss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            train_stats.update(loss=loss.item(),\n",
    "                               batch_size=inputs.size(0),\n",
    "                               d={k: (outputs[k], labels[k]) for k in outputs})\n",
    "\n",
    "            if batch % runsize == 0 or batch == nbatches:\n",
    "                model.eval()\n",
    "\n",
    "                test_stats = utils.Stats(model.tasks.keys())\n",
    "                for inputs, labels in zip(test_x, test_y):\n",
    "                    inputs = to_device(inputs)\n",
    "                    labels = to_device(labels)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                    losses = {combination: criterion(output.double(), labels[combination])\n",
    "                              for combination, output in outputs.items()}\n",
    "\n",
    "                    loss = sum(losses.values())\n",
    "\n",
    "                    test_stats.update(loss=loss.item(),\n",
    "                                      batch_size=inputs.size(0),\n",
    "                                      d={k: (outputs[k], labels[k]) for k in outputs})\n",
    "                    \n",
    "                utils.log(train_stats, test_stats, batch, nbatches, epoch)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, *verbs):\n",
    "    model.eval()\n",
    "    verbs = encoding.wordlist2numpy(verbs)\n",
    "    verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "    outputs = model(verbs)\n",
    "    res = {}\n",
    "    # FIX: assumes no overlaps\n",
    "    for combination, v in outputs.items():\n",
    "        combined_index = torch.argmax(v).cpu().data.numpy()\n",
    "        indices = np.unravel_index(combined_index, encoding.combined_shape(combination))\n",
    "        if isinstance(combination, str):\n",
    "            combination = tuple([combination])\n",
    "        for k, i in zip(combination, indices):\n",
    "            # assert k not in res, \"Overlapping classes are not handled\"\n",
    "            s = k\n",
    "            if k in res:\n",
    "                s += \"'\"\n",
    "            res[s] = encoding.from_category(k, i)\n",
    "    if all(r in res for r in ['R1', 'R2', 'R3', 'R4']):\n",
    "        res['R'] = ''.join(res[k] for k in ['R1', 'R2', 'R3', 'R4']).replace('.', '')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "arity = '3'\n",
    "gen = 'all_pref'\n",
    "artifact_name = f'{gen}_{arity}_shufroot'\n",
    "filename = f'synthetic/{artifact_name}.tsv'  # all_verbs_shuffled\n",
    "test_size = 20000\n",
    "\n",
    "artifact = wandb.Artifact(artifact_name, type='dataset')\n",
    "artifact.add_file(filename)\n",
    "\n",
    "(train_x, pre_train_y), (test_x, pre_test_y) = encoding.load_dataset_split(filename, split=test_size)\n",
    "\n",
    "utils.shuffle_in_unison([train_x, *pre_train_y.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_SILENT=true\n",
      "env: WANDB_MODE=run\n",
      "{'epochs': 1, 'test_size': 20000, 'batch_size': 128, 'units': 350, 'weight_decay': 0, 'dropout': 0.0, 'num_layers': 1, 'lr': 0.0001, 'max_lr': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/133cbqkx\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/133cbqkx</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'test_size': 20000, 'batch_size': 128, 'units': 350, 'weight_decay': 0, 'dropout': 0.0, 'num_layers': 1, 'lr': 0.0001, 'max_lr': 0.1} 0.970 train/Accuracy_R1: 0.937 train/Accuracy_R2: 0.765 train/Accuracy_R3: 1.000 train/Accuracy_R4: 0.948 train/Accuracy_R1xR2xR4: 0.712 val/Loss: 2.4035 val/Accuracy_B: 0.811 val/Accuracy_T: 0.921 val/Accuracy_V: 0.694 val/Accuracy_G: 0.794 val/Accuracy_P: 0.978 val/Accuracy_R1: 0.947 val/Accuracy_R2: 0.778 val/Accuracy_R3: 1.000 val/Accuracy_R4: 0.960 val/Accuracy_R1xR2xR4: 0.740 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/unvnd5fh\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/unvnd5fh</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0   896/ 5353 train/Loss: 6.3907 train/Accuracy_B: 0.605 train/Accuracy_T: 0.827 train/Accuracy_V: 0.597 train/Accuracy_G: 0.740 train/Accuracy_P: 0.923 train/Accuracy_R1: 0.815 train/Accuracy_R2: 0.501 train/Accuracy_R3: 0.999 train/Accuracy_R4: 0.786 train/Accuracy_R1xR2xR4: 0.348 val/Loss: 9.6489 val/Accuracy_B: 0.552 val/Accuracy_T: 0.808 val/Accuracy_V: 0.601 val/Accuracy_G: 0.753 val/Accuracy_P: 0.938 val/Accuracy_R1: 0.763 val/Accuracy_R2: 0.346 val/Accuracy_R3: 1.000 val/Accuracy_R4: 0.645 val/Accuracy_R1xR2xR4: 0.155 \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-12013dac1444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;34m'max_lr'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         }\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-12013dac1444>\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m(config, combinations, names_str)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         fit(train=train,\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9350b5d46561>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, train, test, epochs, runsize, criterion, optimizer, scheduler, batch_size, **_)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             losses = {combination: criterion(output.double(), labels[combination])\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5ceea6684bce>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#         h_n = h_n0 + h_n1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mh_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_n0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         return {combination: f(h_n[0] + h_n[1])\n\u001b[0m\u001b[0;32m     49\u001b[0m                 for combination, f in self.tasks.items()}\n",
      "\u001b[1;32m<ipython-input-3-5ceea6684bce>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#         h_n = h_n0 + h_n1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mh_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_n0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         return {combination: f(h_n[0] + h_n[1])\n\u001b[0m\u001b[0;32m     49\u001b[0m                 for combination, f in self.tasks.items()}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "%env WANDB_SILENT true\n",
    "\n",
    "def experiment(config, combinations=encoding.NAMES, names_str=''):\n",
    "    print(config)\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    train_y = utils.ravel_multi_index(pre_train_y, combinations)\n",
    "    test_y = utils.ravel_multi_index(pre_test_y, combinations)\n",
    "    \n",
    "    train = utils.batch_xy((train_x, train_y), config['batch_size'])\n",
    "    test = utils.batch_xy((test_x, test_y), config['batch_size'])\n",
    "    \n",
    "    model = to_device(Model(units=config['units'], combinations=combinations))  # NaiveModel.learn_from_file(filename)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config['max_lr'], anneal_strategy='linear',\n",
    "                                                    epochs=config['epochs'], steps_per_epoch=len(train[0]))\n",
    "    config.update({\n",
    "        'runsize': 2 * 8192 // config['batch_size'],\n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler,\n",
    "        'criterion': nn.CrossEntropyLoss(),\n",
    "        'model': model,\n",
    "    })\n",
    "    \n",
    "#     names_str = '+'.join(encoding.class_name(combination) for combination in combinations if combination not in encoding.NONROOTS)\n",
    "#     if len(combinations) <= 3:\n",
    "#         names_str += '_only'\n",
    "    run = wandb.init(project=\"rootem\",\n",
    "                     group=f'schedulers',  # f'lr_units_grid_search-{arity}-{wandb.util.generate_id()}',\n",
    "                     name=f\"onecycle-lr_{config['lr']:.0e}-maxlr_{config['max_lr']:.0e}\",  # {model.arch}-{config['units']}-{config['lr']:.0e}-{config['batch_size']} f'{gen}-{arity}-{lr:.0e}',# f'{arity}-batch_{BATCH_SIZE}', # f'all-{arity}-lr_{lr:.0e}-units_{units}',\n",
    "                     tags=[gen, arity, 'synthetic', 'shuffle-root', 'prefix', 'shuffle', 'batchval', 'full-root'],\n",
    "                     config=config)\n",
    "    with run:\n",
    "        run.use_artifact(artifact)\n",
    "\n",
    "        wandb.config.update(config, allow_val_change=True)\n",
    "\n",
    "        if isinstance(model, nn.Module):\n",
    "            wandb.watch(model)\n",
    "\n",
    "        fit(train=train,\n",
    "            test=test,\n",
    "            **config\n",
    "        )\n",
    "        wandb.save(f\"{model.arch}.h5\")\n",
    "\n",
    "    return model\n",
    "\n",
    "%env WANDB_MODE run\n",
    "\n",
    "# for weight_decay in [0, 7e-4]:\n",
    "for max_lr in [5e-3, 1e-2]:\n",
    "    for lr in [1e-4, 1e-3, 3e-3]:\n",
    "        config = {\n",
    "            'epochs': 1,\n",
    "            'test_size': test_size,\n",
    "            'batch_size': 128,\n",
    "            'units': 350,\n",
    "            'weight_decay': 0,\n",
    "            'dropout': 0.0,\n",
    "            'num_layers': 1,\n",
    "            'lr': lr, #  1e-3,\n",
    "            'max_lr': max_lr,\n",
    "        }\n",
    "        model = experiment(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_words(model):\n",
    "    print(predict(model, 'הבריל'))\n",
    "    print(predict(model, 'חגוו'))\n",
    "    print(predict(model, 'עגו'))\n",
    "    print(predict(model, 'צירלל'))\n",
    "    print(predict(model, \"השטקרפתי\"))\n",
    "    print(predict(model, \"ישסו\"))\n",
    "print_words(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
