{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "\n",
    "import utils\n",
    "\n",
    "os.environ['WANDB_SILENT'] = 'true'\n",
    "\n",
    "NUM_EMBEDDING = 2000\n",
    "def word2numpy(txt):\n",
    "    return np.array([ord(c) for c in txt])\n",
    "\n",
    "def wordlist2numpy(lines):\n",
    "    return utils.pad_sequences([word2numpy(line) for line in lines],\n",
    "                               maxlen=12, dtype=int, value=0)\n",
    "\n",
    "RADICALS = ['.'] + list('אבגדהוזחטיכלמנסעפצקרשת') + [\"ג'\", \"ז'\", \"צ'\", 'שׂ']\n",
    "\n",
    "BINYAN = 'פעל נפעל פיעל פועל הפעיל הופעל התפעל'.split()\n",
    "TENSE = 'עבר הווה עתיד ציווי'.split()\n",
    "VOICE = 'ראשון שני שלישי'.split()\n",
    "GENDER = 'זכר נקבה'.split()\n",
    "PLURAL = 'יחיד רבים'.split()\n",
    "\n",
    "NAMES = ['B', 'T', 'V', 'G', 'P', 'R1', 'R2', 'R3', 'R4']\n",
    "FEATURES = {\n",
    "    'B': BINYAN,\n",
    "    'T': TENSE,\n",
    "    'V': VOICE,\n",
    "    'G': GENDER,\n",
    "    'P': PLURAL,\n",
    "    'R1': RADICALS,\n",
    "    'R2': RADICALS,\n",
    "    'R3': RADICALS,\n",
    "    'R4': RADICALS,\n",
    "}\n",
    "\n",
    "def to_category(name, b):\n",
    "    return FEATURES[name].index(b)\n",
    "\n",
    "def from_category(name, index):\n",
    "    return FEATURES[name][index]\n",
    "\n",
    "def list_to_category(name, bs):\n",
    "    return np.array([to_category(name, b) for b in bs])\n",
    "\n",
    "def list_from_category(name, indexes):\n",
    "    return [from_category(name, index) for index in indexes]\n",
    "\n",
    "def list_of_lists_to_category(items):\n",
    "    return { name: list_to_category(name, item)\n",
    "             for name, item in zip(NAMES, items) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "def to_device(d):\n",
    "    if hasattr(d, 'cuda'):\n",
    "        return d.cuda()\n",
    "    return {k: v.cuda() for k, v in d.items()}\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "        self.embed = nn.Embedding(num_embeddings=NUM_EMBEDDING, embedding_dim=units)\n",
    "        self.lstm1 = nn.LSTM(input_size=units, hidden_size=units, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.binyan = nn.Linear(in_features=units, out_features=len(BINYAN))\n",
    "        self.tense = nn.Linear(in_features=units, out_features=len(TENSE))\n",
    "        self.voice = nn.Linear(in_features=units, out_features=len(VOICE))\n",
    "        self.gender = nn.Linear(in_features=units, out_features=len(GENDER))\n",
    "        self.plural = nn.Linear(in_features=units, out_features=len(PLURAL))\n",
    "\n",
    "        self.r1 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r2 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r3 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "        self.r4 = nn.Linear(in_features=units, out_features=len(RADICALS))\n",
    "\n",
    "        self.features = {\n",
    "            'B': self.binyan,\n",
    "            'T': self.tense,\n",
    "            'V': self.voice,\n",
    "            'G': self.gender,\n",
    "            'P': self.plural,\n",
    "\n",
    "            'R1': self.r1,\n",
    "            'R2': self.r2,\n",
    "            'R3': self.r3,\n",
    "            'R4': self.r4,\n",
    "        }\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embed(x)\n",
    "\n",
    "        lstm_out, (h_n, c_n) = self.lstm1(embeds)\n",
    "        left, right = torch.chunk(h_n, 2, dim=0)\n",
    "        merge = torch.squeeze(left + right)\n",
    "\n",
    "        outputs = { k: f(merge) for k, f in self.features.items() }\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def sanity():\n",
    "    model = create_model(100)\n",
    "    with torch.no_grad():\n",
    "        verbs = wordlist2numpy([\"כשאתאקלם\"])\n",
    "        verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "        tag_scores = model(verbs)\n",
    "        for k in NAMES:\n",
    "            print(k)\n",
    "            v = nn.Softmax()(tag_scores[k]).cpu().detach().numpy()\n",
    "            print(v)\n",
    "            print(f'{np.mean(v)=}')\n",
    "            print(f'{-np.log(1/len(v))=}')\n",
    "            print()\n",
    "\n",
    "# sanity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concrete\n",
    "\n",
    "def load_dataset(file_pat):\n",
    "    *features_train, verbs_train = concrete.load_dataset(f'{file_pat}_train.tsv')\n",
    "    *features_test, verbs_test = concrete.load_dataset(f'{file_pat}_test.tsv')\n",
    "    return ((wordlist2numpy(verbs_train), list_of_lists_to_category(features_train)),\n",
    "            (wordlist2numpy(verbs_test), list_of_lists_to_category(features_test)))\n",
    "\n",
    "def load_dataset_split(filename, split):\n",
    "    *features_train, verbs_train = concrete.load_dataset(filename)\n",
    "    features_test = [t[-split:] for t in features_train]\n",
    "    verbs_test = verbs_train[-split:]\n",
    "    del verbs_train[-split:]\n",
    "    for t in features_train:\n",
    "        del t[-split:]\n",
    "    return ((wordlist2numpy(verbs_train), list_of_lists_to_category(features_train)),\n",
    "            (wordlist2numpy(verbs_test), list_of_lists_to_category(features_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stats:\n",
    "    def __init__(self, runsize):\n",
    "        self.runsize = runsize\n",
    "        self.initial_validated = False\n",
    "        self.epoch = 0\n",
    "        self.zero_run()\n",
    "        \n",
    "    def zero_run(self):\n",
    "        self.running_preds = {k: [] for k in NAMES}\n",
    "        self.running_corrects = {k: 0.0 for k in NAMES}\n",
    "        self.running_divisor = 0\n",
    "        self.running_loss = []\n",
    "\n",
    "    def assert_resonable_initial(self, losses):\n",
    "        if not self.initial_validated:\n",
    "            for k in losses:\n",
    "                expected_ce_losses = -np.log(1 / len(FEATURES[k]))\n",
    "                assert abs(1 - losses[k] / expected_ce_losses) < 0.1\n",
    "            self.initial_validated = True\n",
    "    \n",
    "    def cli(self, mean_loss, accuracies):\n",
    "        print(\"{:2} {:5}/{:5}\".format(self.epoch, self.batch, self.batches_in_phase), end=' ')\n",
    "        for k, v in accuracies.items():\n",
    "            print(\"{}_acc: {:.3f}\".format(k, v), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(mean_loss), end='\\r')\n",
    "    \n",
    "    def epoch_start(self):\n",
    "        self.epoch += 1\n",
    "        \n",
    "    def epoch_end(self):\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def phase_start(self, phase, batches_in_phase):\n",
    "        self.phase = phase\n",
    "        self.batches_in_phase = batches_in_phase\n",
    "        self.zero_run()\n",
    "        self.batch = 0\n",
    "        \n",
    "    def phase_end(self):\n",
    "        if self.phase != 'train':\n",
    "            self.callback()\n",
    "            \n",
    "        print()\n",
    " \n",
    "    def batch_start(self):\n",
    "        self.batch += 1\n",
    "        \n",
    "    def batch_end(self):\n",
    "        if self.phase == 'train' and self.batch % self.runsize == 0:\n",
    "            self.callback()\n",
    "            self.zero_run()\n",
    "    \n",
    "    def wandb(self, mean_loss, accuracies):\n",
    "        pref = \"train\" if self.phase == 'train' else \"val\"\n",
    "        wandb.log({'phase': self.phase,\n",
    "                   'epoch': self.epoch,\n",
    "                   # 'batch': batch,\n",
    "                   f\"{pref}/Loss\": mean_loss,\n",
    "                   **{f\"{pref}/Accuracy_{k}\": accuracies[k] for k in accuracies}})        \n",
    "        \n",
    "    def callback(self):\n",
    "        mean_loss = np.mean(self.running_loss)\n",
    "        accuracies = {k: v / self.running_divisor\n",
    "                      for k, v in self.running_corrects.items()}\n",
    "        self.cli(mean_loss, accuracies)\n",
    "        self.wandb(mean_loss, accuracies)\n",
    "        \n",
    "    def update(self, loss, batch_size, d):\n",
    "        self.running_loss.append(loss)\n",
    "        self.running_divisor += batch_size\n",
    "        for k, (output, label) in d.items():\n",
    "            preds = torch.argmax(output, dim=1)\n",
    "            self.running_preds[k].append(preds)\n",
    "            self.running_corrects[k] += torch.sum(preds == label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def batch(a):\n",
    "    ub = a.shape[0] // BATCH_SIZE * BATCH_SIZE\n",
    "    return to_device(torch.from_numpy(a[:ub]).to(torch.int64)).split(BATCH_SIZE)\n",
    "\n",
    "def batch_all_ys(ys):\n",
    "    res = []\n",
    "    m = {k: batch(ys[k]) for k in NAMES}\n",
    "    nbatches = len(m['B'])\n",
    "    for i in range(nbatches):\n",
    "        res.append({k: m[k][i] for k in NAMES})\n",
    "    return res\n",
    "\n",
    "def fit(model, x_train, y_train, x_test, y_test, *, epochs, criterion, optimizer, runsize, train_only=False):\n",
    "    \n",
    "    data = {\n",
    "        'train': (batch(x_train), batch_all_ys(y_train)),\n",
    "        'test':  (batch(x_test ), batch_all_ys(y_test ))\n",
    "    }\n",
    "\n",
    "    stats = Stats(runsize)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        stats.epoch_start()\n",
    "        \n",
    "        for phase in ['train', 'test']:\n",
    "            if train_only and phase != 'train':\n",
    "                continue\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            stats.phase_start(phase, batches_in_phase=len(data[phase][0]))\n",
    "\n",
    "            for inputs, labels in zip(*data[phase]):\n",
    "                stats.batch_start()\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    outputs = model(inputs)\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                losses = {k: criterion(outputs[k], labels[k]) for k in outputs}\n",
    "                \n",
    "                stats.assert_resonable_initial(losses)\n",
    "                \n",
    "                loss = sum(losses.values())\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                stats.update(loss=loss.item(),\n",
    "                             batch_size=inputs.size(0),\n",
    "                             d={k: (outputs[k], labels[k].detach()) for k in outputs})\n",
    "                \n",
    "                stats.batch_end()\n",
    "            stats.phase_end()\n",
    "        stats.epoch_end()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, *verbs):\n",
    "    model.eval()\n",
    "    verbs = wordlist2numpy(verbs)\n",
    "    verbs = to_device(torch.from_numpy(verbs).to(torch.int64))\n",
    "    outputs = model(verbs)\n",
    "    res = {k: from_category(k, torch.argmax(v))\n",
    "           for k, v in outputs.items()}\n",
    "    res['R'] = ''.join(res[k] for k in ['R1', 'R2', 'R3', 'R4']).replace('.', '')\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "arity = '4'\n",
    "artifact_name = f'all_{arity}_shuffled'\n",
    "filename = f'synthetic/{artifact_name}.tsv'  # all_verbs_shuffled\n",
    "test_size = 5000\n",
    "\n",
    "artifact = wandb.Artifact(artifact_name, type='dataset')\n",
    "artifact.add_file(filename)\n",
    "\n",
    "train, test = load_dataset_split(filename, split=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/elazarg/rootem\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/elazarg/rootem/runs/2kxrph96\" target=\"_blank\">https://app.wandb.ai/elazarg/rootem/runs/2kxrph96</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'adam', 'batch_size': 32, 'epochs': 1, 'runsize': 256, 'test_size': 5000, 'units': 400, 'lr': 0.0008}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-edcbd70e3189>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m fit(model,\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;33m*\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;33m*\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-5fcd7afc1e13>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, x_train, y_train, x_test, y_test, epochs, criterion, optimizer, runsize, train_only)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_resonable_initial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-1dc3b71db308>\u001b[0m in \u001b[0;36massert_resonable_initial\u001b[1;34m(self, losses)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mexpected_ce_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[1;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mexpected_ce_losses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_validated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_MODE'] = 'run'\n",
    "\n",
    "config = {\n",
    "    'optimizer': 'adam',\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': 1,\n",
    "    'runsize': 256,\n",
    "    'test_size': test_size,\n",
    "}\n",
    "# group = f'lr_units_grid_search-{arity}-{wandb.util.generate_id()}'\n",
    "\n",
    "units = 400\n",
    "lr = 8e-4\n",
    "\n",
    "config.update({\n",
    "    'units': units,\n",
    "    'lr': lr,\n",
    "})\n",
    "\n",
    "run = wandb.init(project=\"rootem\",\n",
    "                 # group=group,\n",
    "                 name=f'all-{arity}-lr_{lr:.0e}-units_{units}',\n",
    "                 tags=['all', arity, 'synthetic', 'shuffle', 'no_prefix'],\n",
    "                 config=config)\n",
    "\n",
    "run.use_artifact(artifact)\n",
    "\n",
    "wandb.config.update(config, allow_val_change=True)\n",
    "\n",
    "model = to_device(Model(units=config['units']))\n",
    "wandb.watch(model)\n",
    "\n",
    "print(config)\n",
    "fit(model,\n",
    "    *train,\n",
    "    *test,\n",
    "    epochs=config['epochs'],\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=config['lr']),\n",
    "    runsize=config['runsize'],\n",
    "    train_only=False,\n",
    ")\n",
    "\n",
    "wandb.save(f\"simple_{arity}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'פיעל', 'T': 'ציווי', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'ס', 'R2': 'ב', 'R3': '.', 'R4': 'ס', 'R': 'סבס'}\n",
      "{'B': 'פעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'מ', 'R2': 'ק', 'R3': '.', 'R4': 'ד', 'R': 'מקד'}\n",
      "{'B': 'נפעל', 'T': 'עתיד', 'V': 'ראשון', 'G': 'זכר', 'P': 'רבים', 'R1': 'מ', 'R2': 'ז', 'R3': '.', 'R4': 'ר', 'R': 'מזר'}\n",
      "{'B': 'פעל', 'T': 'ציווי', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'כ', 'R2': 'ר', 'R3': '.', 'R4': 'ד', 'R': 'כרד'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, 'סבסו'))\n",
    "print(predict(model, 'מקדו'))\n",
    "print(predict(model, 'נמזר'))\n",
    "print(predict(model, 'כרדו'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'הפעיל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'יחיד', 'R1': 'ב', 'R2': 'ר', 'R3': '.', 'R4': 'ל', 'R': 'ברל'}\n",
      "{'B': 'פעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'ח', 'R2': 'ג', 'R3': '.', 'R4': 'י', 'R': 'חגי'}\n",
      "{'B': 'פעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'ע', 'R2': 'ו', 'R3': '.', 'R4': 'ג', 'R': 'עוג'}\n",
      "{'B': 'פיעל', 'T': 'עבר', 'V': 'שלישי', 'G': 'זכר', 'P': 'יחיד', 'R1': 'צ', 'R2': 'ל', 'R3': '.', 'R4': 'ל', 'R': 'צלל'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, 'הבריל'))\n",
    "print(predict(model, 'חגוו'))\n",
    "print(predict(model, 'עגו'))\n",
    "print(predict(model, 'צירלל'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'התפעל', 'T': 'עבר', 'V': 'ראשון', 'G': 'נקבה', 'P': 'יחיד', 'R1': 'ש', 'R2': 'ר', 'R3': '.', 'R4': 'פ', 'R': 'שרפ'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, \"השטקרפתי\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 'הפעיל', 'T': 'עתיד', 'V': 'שלישי', 'G': 'זכר', 'P': 'רבים', 'R1': 'ש', 'R2': 'ס', 'R3': '.', 'R4': 'י', 'R': 'שסי'}\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, \"ישסו\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{1e-4:.0e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit9bb923b013d04c19b7222e7ae44d4e24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
